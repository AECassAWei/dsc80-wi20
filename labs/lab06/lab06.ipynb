{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Lab 06\n",
    "\n",
    "### Due Date: Tuesday February 18th, 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding work will be developed in an accompanying `lab*.py` file, that will be imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying python file will be tested (a la DSC 20),\n",
    "2. The notebook will be graded (for graphs and free response questions).\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for working in the Notebook**:\n",
    "- The notebooks serve to present you the questions and give you a place to present your results for later review.\n",
    "- The notebook on *lab assignments* are not graded (only the `.py` file).\n",
    "- Notebooks for PAs will serve as a final report for the assignment, and contain conclusions and answers to open ended questions that are graded.\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `.py` file.\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the lab! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `lab**.py` (much like we do in the notebook).\n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code from `lab**.py`\n",
    "\n",
    "* We import our `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab**.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab**.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab**.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab**` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab06 as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic HTML tags practice\n",
    "\n",
    "**Question 1**\n",
    "\n",
    "Create a very basic `html` file that satisfies the following properties:\n",
    "\n",
    "1. Has `<head>` and `<body>` tags.\n",
    "2. Has a title\n",
    "3. Inside the body tags:\n",
    "    * At least two headers\n",
    "    * At least three images:\n",
    "        * At least one image must be a local file;\n",
    "        * At least one image must be linked to online source; \n",
    "        * At least one image has to have default text when it cannot be displayed.\n",
    "    * At least three references (hyperlinks) to different web pages;\n",
    "    * At least one table with two columns.\n",
    "    \n",
    "        \n",
    "   \n",
    "4. Save your work as `lab06_1.html` in the same directory as `lab06.py`, make sure it loads in the browser and do not forget to submit it.\n",
    "5. **Do not forget to submit all data files needed to display your page.**\n",
    "\n",
    "**Note:** You can toy with (basic) HTML in the cells of a notebook, using either a \"markdown cell\" or by using the `IPython.display.HTML` function. However, be sure to open your saved file in a browser to be sure the page displays properly!\n",
    "\n",
    "**Note:** If you work within Jupyter Notebook, you can later copy your text into a text editor and save it with the .html extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"\n",
    "<html>\n",
    "   <head>\n",
    "      <meta charset=\"utf-8\">\n",
    "      <title>Tag Practices</title>\n",
    "      <style>\n",
    "         table, th, td {\n",
    "         border: 1px solid black;\n",
    "         border-collapse: collapse;\n",
    "         }\n",
    "         th, td {\n",
    "         padding: 10px;\n",
    "         }\n",
    "         th {\n",
    "         text-align: middle;\n",
    "         }\n",
    "      </style>\n",
    "   </head>\n",
    "   <body>\n",
    "      <div id='fav show'>\n",
    "         <h1>Favorite TV Show</h1>\n",
    "         <h2>Arrow</h2>\n",
    "         <img src=\"https://www.urgeofcreativity.com/wp-content/uploads/2016/09/The-Arrow-featured-image-696x392.jpeg\" alt=\"Arrow\" width=\"696\" height=\"392\">\n",
    "         <h2>Sense8</h2>\n",
    "         <img src=\"Sense8.jpg\" alt=\"Sense8\" width=\"696\" height=\"392\">\n",
    "         <h2>Person Of Interest</h2>\n",
    "         <img src=\"https://pmcdeadline2.files.wordpress.com/2016/06/poiseason5alternative.jpg?w=681&h=383&crop=1\" alt=\"Person Of Interest\" width=\"696\" height=\"392\">\n",
    "         <h2>Supernatural</h2>\n",
    "         <img src=\"Supernatural.jpg\" alt=\"Supernatural\" width=\"696\" height=\"392\">\n",
    "      </div>\n",
    "      <div id='psyc tool'>\n",
    "         <h1>Useful Psychology Tools</h1>\n",
    "         <a href=\"https://owl.purdue.edu/owl/research_and_citation/apa_style/apa_formatting_and_style_guide/general_format.html\">APA Format Guide</a>\n",
    "         <br>\n",
    "         <a href=\"https://www.psytoolkit.org/\">Psychology Toolkit</a>\n",
    "         <br>\n",
    "         <a href=\"https://www.sciencedirect.com/\">Science Direct</a>\n",
    "         <br>\n",
    "         <a href=\"https://www.simplypsychology.org/\">Simple Psychology</a>\n",
    "         <br>\n",
    "      </div>\n",
    "      <div id='my grades'>\n",
    "         <h1>My Grades</h1>\n",
    "         <table style=\"width:20%\">\n",
    "            <tr>\n",
    "               <th>Class</th>\n",
    "               <th>Letter Grade</th>\n",
    "            </tr>\n",
    "            <tr>\n",
    "               <td>COGS 9</td>\n",
    "               <td>A</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "               <td>COGS 108</td>\n",
    "               <td>A+</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "               <td>DSC 10</td>\n",
    "               <td>A+</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "               <td>DSC 20</td>\n",
    "               <td>A+</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "               <td>DSC 30</td>\n",
    "               <td>A</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "               <td>DSC 40A</td>\n",
    "               <td>A</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "               <td>DSC 80</td>\n",
    "               <td>WIP</td>\n",
    "            </tr>\n",
    "         </table>\n",
    "      </div>\n",
    "   </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "# 1) Default text means paragraph text? Or the 'alt'?????????????????????????????????????????????????????\n",
    "# 2) Three headers mean h1? Do not have to be h1, h2, h3 in hierarchical orders?????????????????????????????????????????????????????\n",
    "# Arrow img link: https://www.urgeofcreativity.com/wp-content/uploads/2016/09/The-Arrow-featured-image-696x392.jpeg\n",
    "# POI img link: https://pmcdeadline2.files.wordpress.com/2016/06/poiseason5alternative.jpg?w=681&h=383&crop=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<html>\n",
       "   <head>\n",
       "      <meta charset=\"utf-8\">\n",
       "      <title>Tag Practices</title>\n",
       "      <style>\n",
       "         table, th, td {\n",
       "         border: 1px solid black;\n",
       "         border-collapse: collapse;\n",
       "         }\n",
       "         th, td {\n",
       "         padding: 10px;\n",
       "         }\n",
       "         th {\n",
       "         text-align: middle;\n",
       "         }\n",
       "      </style>\n",
       "   </head>\n",
       "   <body>\n",
       "      <div id='fav show'>\n",
       "         <h1>Favorite TV Show</h1>\n",
       "         <h2>Arrow</h2>\n",
       "         <img src=\"https://www.urgeofcreativity.com/wp-content/uploads/2016/09/The-Arrow-featured-image-696x392.jpeg\" alt=\"Arrow\" width=\"696\" height=\"392\">\n",
       "         <h2>Sense8</h2>\n",
       "         <img src=\"Sense8.jpg\" alt=\"Sense8\" width=\"696\" height=\"392\">\n",
       "         <h2>Person Of Interest</h2>\n",
       "         <img src=\"https://pmcdeadline2.files.wordpress.com/2016/06/poiseason5alternative.jpg?w=681&h=383&crop=1\" alt=\"Person Of Interest\" width=\"696\" height=\"392\">\n",
       "         <h2>Supernatural</h2>\n",
       "         <img src=\"Supernatural.jpg\" alt=\"Supernatural\" width=\"696\" height=\"392\">\n",
       "      </div>\n",
       "      <div id='psyc tool'>\n",
       "         <h1>Useful Psychology Tools</h1>\n",
       "         <a href=\"https://owl.purdue.edu/owl/research_and_citation/apa_style/apa_formatting_and_style_guide/general_format.html\">APA Format Guide</a>\n",
       "         <br>\n",
       "         <a href=\"https://www.psytoolkit.org/\">Psychology Toolkit</a>\n",
       "         <br>\n",
       "         <a href=\"https://www.sciencedirect.com/\">Science Direct</a>\n",
       "         <br>\n",
       "         <a href=\"https://www.simplypsychology.org/\">Simple Psychology</a>\n",
       "         <br>\n",
       "      </div>\n",
       "      <div id='my grades'>\n",
       "         <h1>My Grades</h1>\n",
       "         <table style=\"width:20%\">\n",
       "            <tr>\n",
       "               <th>Class</th>\n",
       "               <th>Letter Grade</th>\n",
       "            </tr>\n",
       "            <tr>\n",
       "               <td>COGS 9</td>\n",
       "               <td>A</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "               <td>COGS 108</td>\n",
       "               <td>A+</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "               <td>DSC 10</td>\n",
       "               <td>A+</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "               <td>DSC 20</td>\n",
       "               <td>A+</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "               <td>DSC 30</td>\n",
       "               <td>A</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "               <td>DSC 40A</td>\n",
       "               <td>A</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "               <td>DSC 80</td>\n",
       "               <td>WIP</td>\n",
       "            </tr>\n",
       "         </table>\n",
       "      </div>\n",
       "   </body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping an Online Bookstore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Browse through the following fake on-line bookstore: http://books.toscrape.com/. This website is meant for toying with scraping.\n",
    "\n",
    "Scrape the website, collecting data on all books that have **at least a four-star rating**, with a price **under £50** and belong to the book categories you want. You should collect the data in a dataframe as below (if you get an encoding error on your prices columns, like you see in the table below, don't worry about it):\n",
    "<img src=\"bookdata.png\">\n",
    "\n",
    "\n",
    "Do this using the following steps:\n",
    "1. Create a function `extract_book_links` that takes in the content of a book-listing page (a string of html), and returns a list of urls of book-detail pages that satisfy the requirements on \"*at least* a four-star rating, and prices are *under* £50\". \n",
    "\n",
    "2. Create a function `get_product_info` that takes in the content of a book-detail page (a string of html), a variable `categories` that is a list of book categories you want. If this input book is in the categories you want, returns a dictionary corresponding to a row in the dataframe in the image above (where the keys are the column names and the values are the row values); else, skip this book since this is not the book you want (ie. return None).\n",
    "\n",
    "3. Create a function `scrape_books` of a single variable `k` that scrapes the first `k` pages of the bookstore (as determined by starting at the url above and clicking on the 'next' button),a variable `categories` that is a list of book categories you want, and returns a dataframe of books as the picture above. (Note: make sure the books returned satisfy the requirements set in part 1 about rating and price).\n",
    "\n",
    "\n",
    "*Note:* Your function should take under 180 seconds to run through the entire bookstore.\n",
    "\n",
    "*Note:* Don't worry about type casting (ie changing number of reviews to an int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'products.html')\n",
    "text = open(fp, encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(text, 'lxml')\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_book_links\n",
    "def extract_book_links(text):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'products.html')\n",
    "    >>> out = extract_book_links(open(fp, encoding='utf-8').read())\n",
    "    >>> url = 'scarlet-the-lunar-chronicles-2_218/index.html'\n",
    "    >>> out[1] == url\n",
    "    True\n",
    "    \"\"\"\n",
    "    soup = bs4.BeautifulSoup(text, 'lxml')\n",
    "    urls = []\n",
    "    for book in soup.find_all('article', attrs={'class':'product_pod'}):\n",
    "        # title = book.find('h3').a.get('title') # Title of the book\n",
    "        url = book.find('h3').a.get('href') # Url of the book\n",
    "        rating = book.find('p', attrs={'class':'star-rating'}).get('class')[1] # Rating of the book\n",
    "        price = float(book.find('p', attrs={'class':'price_color'}).text.strip('Â').strip('£')) # Price of the book\n",
    "\n",
    "        if (rating in ['Four', 'Five']) and (price < 50): # Rating at least four star, price less than £50\n",
    "            urls.append(url)\n",
    "    return urls # Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_book_links(text) == (lab.extract_book_links(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'Frankenstein.html')\n",
    "text = open(fp, encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(text, 'lxml')\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Mystery', 'Business', 'Default']\n",
    "# get_product_info\n",
    "def get_product_info(text, categories):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'Frankenstein.html')\n",
    "    >>> out = get_product_info(open(fp, encoding='utf-8').read(), ['Default'])\n",
    "    >>> isinstance(out, dict)\n",
    "    True\n",
    "    >>> 'Category' in out.keys()\n",
    "    True\n",
    "    >>> out['Rating']\n",
    "    'Two'\n",
    "    \"\"\"\n",
    "    soup = bs4.BeautifulSoup(text, 'lxml')\n",
    "    headers = ['Availability', 'Category', 'Description', 'Number of reviews', 'Price (excl. tax)', 'Price (incl. tax)', 'Product Type', 'Rating', 'Tax', 'Title', 'UPC'] # Headers of the dictionary\n",
    "\n",
    "    # Type, Category and Title\n",
    "    gens = soup.find('body', attrs={'id':'default'}).find('div', attrs={'class':'container-fluid'}).find_all('li')\n",
    "    ptype, category, title = gens[1].text.strip(), gens[2].text.strip(), gens[3].text.strip() # Get product type, category, title\n",
    "    if category not in categories: # Book not what we want\n",
    "        return None\n",
    "\n",
    "    # Availability, Description, Number of reviews, Price, Tax, Rating, UPC\n",
    "    article = soup.find('article', attrs={'class':'product_page'})\n",
    "    rating = article.find('p', attrs={'class':'star-rating'}).get('class')[1].strip() # Rating of the book\n",
    "\n",
    "    desrc_head = article.find('div', attrs={'class':'sub-header', 'id':'product_description'})\n",
    "    description = desrc_head.findNext('p').text.strip() # Decription\n",
    "\n",
    "    infos = article.find('table', attrs={'class':['table', 'table-striped']})\n",
    "    infos_head = infos.find_all('th')\n",
    "    for head in infos_head: # Loop through headers\n",
    "        if head.text == 'UPC': # UPC\n",
    "            upc = head.findNext('td').text.strip()\n",
    "        elif head.text == 'Price (excl. tax)': # Price (excl. tax)\n",
    "            pri_ex_tax = head.findNext('td').text.strip()\n",
    "        elif head.text == 'Price (incl. tax)': # Price (incl. tax)\n",
    "            pri_in_tax = head.findNext('td').text.strip()\n",
    "        elif head.text == 'Tax': # Tax\n",
    "            tax = head.findNext('td').text.strip()\n",
    "        elif head.text == 'Availability': # Availability\n",
    "            avail = head.findNext('td').text.strip()\n",
    "        elif head.text == 'Number of reviews': # Number of reviews\n",
    "            no_rev = head.findNext('td').text.strip()\n",
    "\n",
    "    content = [avail, category, description, no_rev, pri_ex_tax, pri_in_tax, ptype, rating, tax, title, upc]\n",
    "    return dict(zip(headers, content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_product_info(text, categories) == (lab.get_product_info(text, categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape_books\n",
    "def scrape_books(k, categories):\n",
    "    \"\"\"\n",
    "    :param k: number of book-listing pages to scrape.\n",
    "    :returns: a dataframe of information on (certain) books\n",
    "    on the k pages (as described in the question).\n",
    "\n",
    "    :Example:\n",
    "    >>> out = scrape_books(1, ['Mystery'])\n",
    "    >>> out.shape\n",
    "    (1, 11)\n",
    "    >>> out['Rating'][0] == 'Four'\n",
    "    True\n",
    "    >>> out['Title'][0] == 'Sharp Objects'\n",
    "    True\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame() # Contain the result\n",
    "    url = 'http://books.toscrape.com/'\n",
    "    web = requests.get(url)\n",
    "    for _ in range(k):\n",
    "        # print(_)\n",
    "        url_text = web.text # Get text of page\n",
    "        book_links = extract_book_links(url_text) # Get book_links at least four star, price less than 50\n",
    "\n",
    "        if len(book_links) != 0: # If no book of four/five star, and price less than 50\n",
    "            for link in book_links: # Loop through book links\n",
    "                if link[0:10] != 'catalogue/': # Fix no found urls\n",
    "                    link = 'catalogue/' + link\n",
    "                # print(url + link)\n",
    "                book_text = requests.get(url + link).text\n",
    "                dic = get_product_info(book_text, categories)\n",
    "                df = df.append(dic, ignore_index=True) # Append met book to df\n",
    "\n",
    "        # Get next page url\n",
    "        soup = bs4.BeautifulSoup(url_text, 'html.parser')\n",
    "        nxt = soup.find('li', attrs={'class':'next'}) # Find next button section\n",
    "        if nxt == None: # Last page, no next url\n",
    "            continue\n",
    "        \n",
    "        app = nxt.find('a').get('href') # Next page url appendant\n",
    "        if app[0:10] != 'catalogue/': # Fix no found urls\n",
    "            app = 'catalogue/' + app\n",
    "        print(app)\n",
    "        web = requests.get(url + app)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catalogue/page-2.html\n",
      "catalogue/page-3.html\n",
      "catalogue/page-4.html\n",
      "catalogue/page-5.html\n",
      "catalogue/page-6.html\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = 5\n",
    "categories = ['Mystery', 'Business', 'Default']\n",
    "df = scrape_books(k, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Availability</th>\n",
       "      <th>Category</th>\n",
       "      <th>Description</th>\n",
       "      <th>Number of reviews</th>\n",
       "      <th>Price (excl. tax)</th>\n",
       "      <th>Price (incl. tax)</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Title</th>\n",
       "      <th>UPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In stock (20 available)</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>WICKED above her hipbone, GIRL across her hear...</td>\n",
       "      <td>0</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>Books</td>\n",
       "      <td>Four</td>\n",
       "      <td>Â£0.00</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>e00eb4fd7b871a48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In stock (19 available)</td>\n",
       "      <td>Business</td>\n",
       "      <td>Drawing on his extensive experience evaluating...</td>\n",
       "      <td>0</td>\n",
       "      <td>Â£33.34</td>\n",
       "      <td>Â£33.34</td>\n",
       "      <td>Books</td>\n",
       "      <td>Four</td>\n",
       "      <td>Â£0.00</td>\n",
       "      <td>The Dirty Little Secrets of Getting Your Dream...</td>\n",
       "      <td>2597b5a345f45e1b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In stock (19 available)</td>\n",
       "      <td>Default</td>\n",
       "      <td>For readers of Laura Hillenbrand's Seabiscuit ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Â£22.60</td>\n",
       "      <td>Â£22.60</td>\n",
       "      <td>Books</td>\n",
       "      <td>Four</td>\n",
       "      <td>Â£0.00</td>\n",
       "      <td>The Boys in the Boat: Nine Americans and Their...</td>\n",
       "      <td>e10e1e165dc8be4a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In stock (16 available)</td>\n",
       "      <td>Default</td>\n",
       "      <td>Slay Procrastination, Distraction, and Overwhe...</td>\n",
       "      <td>0</td>\n",
       "      <td>Â£20.59</td>\n",
       "      <td>Â£20.59</td>\n",
       "      <td>Books</td>\n",
       "      <td>Five</td>\n",
       "      <td>Â£0.00</td>\n",
       "      <td>The Inefficiency Assassin: Time Management Tac...</td>\n",
       "      <td>8c9e6bf2467d740d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Availability  Category  \\\n",
       "0  In stock (20 available)   Mystery   \n",
       "1  In stock (19 available)  Business   \n",
       "2  In stock (19 available)   Default   \n",
       "3  In stock (16 available)   Default   \n",
       "\n",
       "                                         Description Number of reviews  \\\n",
       "0  WICKED above her hipbone, GIRL across her hear...                 0   \n",
       "1  Drawing on his extensive experience evaluating...                 0   \n",
       "2  For readers of Laura Hillenbrand's Seabiscuit ...                 0   \n",
       "3  Slay Procrastination, Distraction, and Overwhe...                 0   \n",
       "\n",
       "  Price (excl. tax) Price (incl. tax) Product Type Rating     Tax  \\\n",
       "0           Â£47.82           Â£47.82        Books   Four  Â£0.00   \n",
       "1           Â£33.34           Â£33.34        Books   Four  Â£0.00   \n",
       "2           Â£22.60           Â£22.60        Books   Four  Â£0.00   \n",
       "3           Â£20.59           Â£20.59        Books   Five  Â£0.00   \n",
       "\n",
       "                                               Title               UPC  \n",
       "0                                      Sharp Objects  e00eb4fd7b871a48  \n",
       "1  The Dirty Little Secrets of Getting Your Dream...  2597b5a345f45e1b  \n",
       "2  The Boys in the Boat: Nine Americans and Their...  e10e1e165dc8be4a  \n",
       "3  The Inefficiency Assassin: Time Management Tac...  8c9e6bf2467d740d  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.equals(lab.scrape_books(k, categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = requests.get('http://books.toscrape.com/')\n",
    "url_text = web.text\n",
    "url = 'http://books.toscrape.com/'\n",
    "# Get next page\n",
    "soup = bs4.BeautifulSoup(url_text, 'html.parser')\n",
    "app = soup.find('li', attrs={'class':'next'}).find('a').get('href') # Next page url appendant\n",
    "web = requests.get(url + app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Name':[1, 2, 3]})\n",
    "df = df.append({'Name':4}, ignore_index=True)\n",
    "# df.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web = requests.get('http://books.toscrape.com/catalogue/page-50.html')\n",
    "soup = bs4.BeautifulSoup(web.text, 'html.parser')\n",
    "nxt = soup.find('li', attrs={'class':'next'}) # Find next button section\n",
    "nxt == None # Last page, no next url\n",
    "# app = nxt.find('a').get('href') # Next page url appendant\n",
    "#.find('a').get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Requests\n",
    "**Question 3**\n",
    "\n",
    "You trade stocks as a hobby. As an avid pandas coder, you figured it is best to calculate some statistics by pulling data from a public API (https://financialmodelingprep.com/developer/docs/#Stock-Historical-Price). Specifically, \"Historical price with change and volume interval\".\n",
    "\n",
    "Some definitions (these are the ones you need to know):\n",
    "- open: The opening price of a stock at the beginning of a trading day\n",
    "- close: The closing price of a stock at the end of a trading day\n",
    "- volume: The total number of shares being traded in a day\n",
    "- percent change: difference in price with respect to the original price (in percentages)\n",
    "\n",
    "\n",
    "1. Create a function `stock_history` which takes in the stock code (`ticker`) as a string, `year` and `month` as integers, and return a dataframe which has the price history for that stock in that month (include all columns).\n",
    "\n",
    "2. Create a function `stock_stats` that takes in the output dataframe from `stock_history` and output the stock price change as a percentage and a rough total transaction volume **in billion dollars** for that month. Assume that on average, shares are traded at the midpoint price of high and low for that day. Return these two values as a tuple in a readable format: reserve 2 decimal points for both values and add a plus or minus sign at the front of the percent change. \n",
    "$$ \\text{Total Transaction Volume (in dollars)} = \\text{Volume (number of shares traded)} \\times \\text{Price} $$\n",
    "\n",
    "*Example*: If \\\\$BYND opens at \\\\$80 and closes at \\\\$120 with a volume of 1 million, its percent change for the day is $(\\$120-\\$80) \\div \\$80 = +50.00\\%$. And the estimated total transaction volume is: $(\\$80+\\$120) / 2 \\times 10^6 = 0.10\\text{B}$.\n",
    "\n",
    "\n",
    "Hint: [pd.date_range](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html), \n",
    "\n",
    "*Note:* Make sure you read the API documentation if you get stuck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_endpoint = 'https://financialmodelingprep.com/api/v3/historical-price-full/AAPL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_history\n",
    "import json\n",
    "def stock_history(ticker, year, month):\n",
    "    \"\"\"\n",
    "    Given a stock code and month, return the stock price details for that month\n",
    "    as a dataframe\n",
    "\n",
    "    >>> history = stock_history('BYND', 2019, 6)\n",
    "    >>> history.shape == (20, 13)\n",
    "    True\n",
    "    >>> history.label.iloc[0]\n",
    "    'June 03, 19'\n",
    "    \"\"\"\n",
    "    url = 'https://financialmodelingprep.com/api/v3/historical-price-full/' + ticker # Is this the right way???????????\n",
    "    response = requests.get(url)\n",
    "    data = response.text\n",
    "    js = json.loads(data) # Load json data\n",
    "    \n",
    "    # Construct dataframe from js file\n",
    "    df = pd.DataFrame()\n",
    "    for day in js.get('historical'):\n",
    "        df = df.append(day, ignore_index=True)\n",
    "    # df = df.assign(year=pd.to_datetime(df['date']).dt.year)\n",
    "    # df = df.assign(month=pd.to_datetime(df['date']).dt.month)\n",
    "    return df[(pd.to_datetime(df['date']).dt.year == year) & (pd.to_datetime(df['date']).dt.month == month)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_history('AAPL', 2016, 7)\n",
    "# date_range seems more complicated?????????????????????????????????????????????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 13)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history2 = stock_history('BYND', 2019, 6)\n",
    "history2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjClose</th>\n",
       "      <th>change</th>\n",
       "      <th>changeOverTime</th>\n",
       "      <th>changePercent</th>\n",
       "      <th>close</th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>label</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>unadjustedVolume</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126.04</td>\n",
       "      <td>19.21</td>\n",
       "      <td>0.13225</td>\n",
       "      <td>13.225</td>\n",
       "      <td>126.04</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>150.00</td>\n",
       "      <td>June 11, 19</td>\n",
       "      <td>125.23</td>\n",
       "      <td>145.25</td>\n",
       "      <td>15516000.0</td>\n",
       "      <td>15516000.0</td>\n",
       "      <td>133.75667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151.48</td>\n",
       "      <td>-9.47</td>\n",
       "      <td>-0.06669</td>\n",
       "      <td>-6.669</td>\n",
       "      <td>151.48</td>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>157.90</td>\n",
       "      <td>June 14, 19</td>\n",
       "      <td>141.80</td>\n",
       "      <td>142.01</td>\n",
       "      <td>14964600.0</td>\n",
       "      <td>14964600.0</td>\n",
       "      <td>150.39333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>169.96</td>\n",
       "      <td>-6.78</td>\n",
       "      <td>-0.04155</td>\n",
       "      <td>-4.155</td>\n",
       "      <td>169.96</td>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>171.19</td>\n",
       "      <td>June 17, 19</td>\n",
       "      <td>160.61</td>\n",
       "      <td>163.18</td>\n",
       "      <td>14626700.0</td>\n",
       "      <td>14626700.0</td>\n",
       "      <td>167.25333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.41</td>\n",
       "      <td>-2.16</td>\n",
       "      <td>-0.02133</td>\n",
       "      <td>-2.133</td>\n",
       "      <td>103.41</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>103.50</td>\n",
       "      <td>June 04, 19</td>\n",
       "      <td>97.82</td>\n",
       "      <td>101.25</td>\n",
       "      <td>5484900.0</td>\n",
       "      <td>5484900.0</td>\n",
       "      <td>101.57667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162.91</td>\n",
       "      <td>-5.60</td>\n",
       "      <td>-0.03560</td>\n",
       "      <td>-3.560</td>\n",
       "      <td>162.91</td>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>164.79</td>\n",
       "      <td>June 27, 19</td>\n",
       "      <td>155.45</td>\n",
       "      <td>157.31</td>\n",
       "      <td>5731400.0</td>\n",
       "      <td>5731400.0</td>\n",
       "      <td>161.05000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>165.17</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.04526</td>\n",
       "      <td>4.526</td>\n",
       "      <td>165.17</td>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>174.00</td>\n",
       "      <td>June 20, 19</td>\n",
       "      <td>163.30</td>\n",
       "      <td>173.00</td>\n",
       "      <td>6660500.0</td>\n",
       "      <td>6660500.0</td>\n",
       "      <td>167.49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>141.39</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00092</td>\n",
       "      <td>0.092</td>\n",
       "      <td>141.39</td>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>146.45</td>\n",
       "      <td>June 13, 19</td>\n",
       "      <td>134.25</td>\n",
       "      <td>141.52</td>\n",
       "      <td>9474600.0</td>\n",
       "      <td>9474600.0</td>\n",
       "      <td>140.69667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>138.65</td>\n",
       "      <td>-8.65</td>\n",
       "      <td>-0.06654</td>\n",
       "      <td>-6.654</td>\n",
       "      <td>138.65</td>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>149.46</td>\n",
       "      <td>June 07, 19</td>\n",
       "      <td>120.76</td>\n",
       "      <td>130.00</td>\n",
       "      <td>23916700.0</td>\n",
       "      <td>23916700.0</td>\n",
       "      <td>136.29000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>102.60</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.02749</td>\n",
       "      <td>2.749</td>\n",
       "      <td>102.60</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>105.50</td>\n",
       "      <td>June 05, 19</td>\n",
       "      <td>99.64</td>\n",
       "      <td>105.50</td>\n",
       "      <td>4283500.0</td>\n",
       "      <td>4283500.0</td>\n",
       "      <td>102.58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>154.13</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-0.00384</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>154.13</td>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>161.79</td>\n",
       "      <td>June 21, 19</td>\n",
       "      <td>150.00</td>\n",
       "      <td>153.54</td>\n",
       "      <td>7474600.0</td>\n",
       "      <td>7474600.0</td>\n",
       "      <td>155.30667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>96.16</td>\n",
       "      <td>7.98</td>\n",
       "      <td>0.07663</td>\n",
       "      <td>7.663</td>\n",
       "      <td>96.16</td>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>108.67</td>\n",
       "      <td>June 03, 19</td>\n",
       "      <td>95.66</td>\n",
       "      <td>104.14</td>\n",
       "      <td>8027700.0</td>\n",
       "      <td>8027700.0</td>\n",
       "      <td>100.16333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>140.99</td>\n",
       "      <td>10.89</td>\n",
       "      <td>0.07170</td>\n",
       "      <td>7.170</td>\n",
       "      <td>140.99</td>\n",
       "      <td>2019-06-24</td>\n",
       "      <td>152.70</td>\n",
       "      <td>June 24, 19</td>\n",
       "      <td>138.00</td>\n",
       "      <td>151.88</td>\n",
       "      <td>6538500.0</td>\n",
       "      <td>6538500.0</td>\n",
       "      <td>143.89667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>169.28</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.01220</td>\n",
       "      <td>1.220</td>\n",
       "      <td>169.28</td>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>174.45</td>\n",
       "      <td>June 19, 19</td>\n",
       "      <td>162.25</td>\n",
       "      <td>171.37</td>\n",
       "      <td>9452000.0</td>\n",
       "      <td>9452000.0</td>\n",
       "      <td>168.66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>168.10</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>-0.07964</td>\n",
       "      <td>-7.964</td>\n",
       "      <td>168.10</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>186.43</td>\n",
       "      <td>June 10, 19</td>\n",
       "      <td>147.00</td>\n",
       "      <td>155.70</td>\n",
       "      <td>24986000.0</td>\n",
       "      <td>24986000.0</td>\n",
       "      <td>167.17667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>141.97</td>\n",
       "      <td>-7.98</td>\n",
       "      <td>-0.05956</td>\n",
       "      <td>-5.956</td>\n",
       "      <td>141.97</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>150.45</td>\n",
       "      <td>June 12, 19</td>\n",
       "      <td>131.56</td>\n",
       "      <td>133.99</td>\n",
       "      <td>16918600.0</td>\n",
       "      <td>16918600.0</td>\n",
       "      <td>141.32667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>169.89</td>\n",
       "      <td>30.11</td>\n",
       "      <td>0.15055</td>\n",
       "      <td>15.055</td>\n",
       "      <td>169.89</td>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>201.88</td>\n",
       "      <td>June 18, 19</td>\n",
       "      <td>160.70</td>\n",
       "      <td>200.00</td>\n",
       "      <td>23966900.0</td>\n",
       "      <td>23966900.0</td>\n",
       "      <td>177.49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>160.68</td>\n",
       "      <td>4.62</td>\n",
       "      <td>0.02795</td>\n",
       "      <td>2.795</td>\n",
       "      <td>160.68</td>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>168.80</td>\n",
       "      <td>June 28, 19</td>\n",
       "      <td>159.55</td>\n",
       "      <td>165.30</td>\n",
       "      <td>7315300.0</td>\n",
       "      <td>7315300.0</td>\n",
       "      <td>163.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>160.48</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.00237</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>160.48</td>\n",
       "      <td>2019-06-26</td>\n",
       "      <td>162.25</td>\n",
       "      <td>June 26, 19</td>\n",
       "      <td>153.02</td>\n",
       "      <td>160.10</td>\n",
       "      <td>6378600.0</td>\n",
       "      <td>6378600.0</td>\n",
       "      <td>158.58333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>150.60</td>\n",
       "      <td>-12.10</td>\n",
       "      <td>-0.08736</td>\n",
       "      <td>-8.736</td>\n",
       "      <td>150.60</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>150.69</td>\n",
       "      <td>June 25, 19</td>\n",
       "      <td>138.34</td>\n",
       "      <td>138.50</td>\n",
       "      <td>6632500.0</td>\n",
       "      <td>6632500.0</td>\n",
       "      <td>146.54333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>99.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.02451</td>\n",
       "      <td>2.451</td>\n",
       "      <td>99.50</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>102.25</td>\n",
       "      <td>June 06, 19</td>\n",
       "      <td>98.85</td>\n",
       "      <td>102.00</td>\n",
       "      <td>6484000.0</td>\n",
       "      <td>6484000.0</td>\n",
       "      <td>100.20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    adjClose  change  changeOverTime  changePercent   close        date  \\\n",
       "0     126.04   19.21         0.13225         13.225  126.04  2019-06-11   \n",
       "1     151.48   -9.47        -0.06669         -6.669  151.48  2019-06-14   \n",
       "2     169.96   -6.78        -0.04155         -4.155  169.96  2019-06-17   \n",
       "3     103.41   -2.16        -0.02133         -2.133  103.41  2019-06-04   \n",
       "4     162.91   -5.60        -0.03560         -3.560  162.91  2019-06-27   \n",
       "5     165.17    7.83         0.04526          4.526  165.17  2019-06-20   \n",
       "6     141.39    0.13         0.00092          0.092  141.39  2019-06-13   \n",
       "7     138.65   -8.65        -0.06654         -6.654  138.65  2019-06-07   \n",
       "8     102.60    2.90         0.02749          2.749  102.60  2019-06-05   \n",
       "9     154.13   -0.59        -0.00384         -0.384  154.13  2019-06-21   \n",
       "10     96.16    7.98         0.07663          7.663   96.16  2019-06-03   \n",
       "11    140.99   10.89         0.07170          7.170  140.99  2019-06-24   \n",
       "12    169.28    2.09         0.01220          1.220  169.28  2019-06-19   \n",
       "13    168.10  -12.40        -0.07964         -7.964  168.10  2019-06-10   \n",
       "14    141.97   -7.98        -0.05956         -5.956  141.97  2019-06-12   \n",
       "15    169.89   30.11         0.15055         15.055  169.89  2019-06-18   \n",
       "16    160.68    4.62         0.02795          2.795  160.68  2019-06-28   \n",
       "17    160.48   -0.38        -0.00237         -0.237  160.48  2019-06-26   \n",
       "18    150.60  -12.10        -0.08736         -8.736  150.60  2019-06-25   \n",
       "19     99.50    2.50         0.02451          2.451   99.50  2019-06-06   \n",
       "\n",
       "      high        label     low    open  unadjustedVolume      volume  \\\n",
       "0   150.00  June 11, 19  125.23  145.25        15516000.0  15516000.0   \n",
       "1   157.90  June 14, 19  141.80  142.01        14964600.0  14964600.0   \n",
       "2   171.19  June 17, 19  160.61  163.18        14626700.0  14626700.0   \n",
       "3   103.50  June 04, 19   97.82  101.25         5484900.0   5484900.0   \n",
       "4   164.79  June 27, 19  155.45  157.31         5731400.0   5731400.0   \n",
       "5   174.00  June 20, 19  163.30  173.00         6660500.0   6660500.0   \n",
       "6   146.45  June 13, 19  134.25  141.52         9474600.0   9474600.0   \n",
       "7   149.46  June 07, 19  120.76  130.00        23916700.0  23916700.0   \n",
       "8   105.50  June 05, 19   99.64  105.50         4283500.0   4283500.0   \n",
       "9   161.79  June 21, 19  150.00  153.54         7474600.0   7474600.0   \n",
       "10  108.67  June 03, 19   95.66  104.14         8027700.0   8027700.0   \n",
       "11  152.70  June 24, 19  138.00  151.88         6538500.0   6538500.0   \n",
       "12  174.45  June 19, 19  162.25  171.37         9452000.0   9452000.0   \n",
       "13  186.43  June 10, 19  147.00  155.70        24986000.0  24986000.0   \n",
       "14  150.45  June 12, 19  131.56  133.99        16918600.0  16918600.0   \n",
       "15  201.88  June 18, 19  160.70  200.00        23966900.0  23966900.0   \n",
       "16  168.80  June 28, 19  159.55  165.30         7315300.0   7315300.0   \n",
       "17  162.25  June 26, 19  153.02  160.10         6378600.0   6378600.0   \n",
       "18  150.69  June 25, 19  138.34  138.50         6632500.0   6632500.0   \n",
       "19  102.25  June 06, 19   98.85  102.00         6484000.0   6484000.0   \n",
       "\n",
       "         vwap  \n",
       "0   133.75667  \n",
       "1   150.39333  \n",
       "2   167.25333  \n",
       "3   101.57667  \n",
       "4   161.05000  \n",
       "5   167.49000  \n",
       "6   140.69667  \n",
       "7   136.29000  \n",
       "8   102.58000  \n",
       "9   155.30667  \n",
       "10  100.16333  \n",
       "11  143.89667  \n",
       "12  168.66000  \n",
       "13  167.17667  \n",
       "14  141.32667  \n",
       "15  177.49000  \n",
       "16  163.01000  \n",
       "17  158.58333  \n",
       "18  146.54333  \n",
       "19  100.20000  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = history2.sample(frac=1).reset_index(drop=True)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history2.equals(lab.stock_history('BYND', 2019, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_stats\n",
    "# What does the percentageChange has to do with the question????????????????????????????????????????????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 13 columns):\n",
      "adjClose            20 non-null float64\n",
      "change              20 non-null float64\n",
      "changeOverTime      20 non-null float64\n",
      "changePercent       20 non-null float64\n",
      "close               20 non-null float64\n",
      "date                20 non-null object\n",
      "high                20 non-null float64\n",
      "label               20 non-null object\n",
      "low                 20 non-null float64\n",
      "open                20 non-null float64\n",
      "unadjustedVolume    20 non-null float64\n",
      "volume              20 non-null float64\n",
      "vwap                20 non-null float64\n",
      "dtypes: float64(11), object(2)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "history.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54.29, 33.64, 10, 16)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_id = pd.to_datetime(history['date']).idxmin()\n",
    "close_id = pd.to_datetime(history['date']).idxmax()\n",
    "open_p = history.loc[open_id, 'open'] # Opening price for month\n",
    "close_p = history.loc[close_id, 'close'] # Close price for month\n",
    "pct_change = np.round((close_p - open_p) / open_p * 100, 2)\n",
    "\n",
    "tot_tran = np.round(((history['high'] + history['low']) / 2 * history['volume'] / 1000000000).sum(), 2)\n",
    "pct_change, tot_tran, open_id, close_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_stats(history):\n",
    "    \"\"\"\n",
    "    Given a stock's trade history, return the percent change and transactions\n",
    "    in billion dollars.\n",
    "\n",
    "    >>> history = stock_history('BYND', 2019, 6)\n",
    "    >>> stats = stock_stats(history)\n",
    "    >>> len(stats[0]), len(stats[1])\n",
    "    (7, 6)\n",
    "    >>> float(stats[0][1:-1]) > 30\n",
    "    True\n",
    "    >>> float(stats[1][:-1]) > 1\n",
    "    True\n",
    "    \"\"\"\n",
    "    open_id = pd.to_datetime(history['date']).idxmin()\n",
    "    close_id = pd.to_datetime(history['date']).idxmax()\n",
    "    open_p = history.loc[open_id, 'open'] # Opening price for month\n",
    "    close_p = history.loc[close_id, 'close'] # Close price for month\n",
    "    pct_change = (close_p - open_p) / open_p * 100\n",
    "\n",
    "    tot_tran = ((history['high'] + history['low']) / 2 * history['volume'] / 1000000000).sum()\n",
    "    \n",
    "    change = '%+.2f' % (pct_change) + '%'\n",
    "    tran = '%.2f' % (tot_tran) + 'B'\n",
    "    return (change, tran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('+54.29%', '33.64B')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = stock_stats(history)\n",
    "len(stats[0]), len(stats[1])\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+54.29%'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'%+.2f' % (54.292298828500094) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33.50B'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'%.2f' % (33.500834782999995) + 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats == (lab.stock_stats(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.6379356715"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "# pct_change = np.round((history['close'] - history['open']) / history['open'] * 100, 2)\n",
    "tot_tran_lst = (history['high'] + history['low']) / 2 * history['volume'] / 1000000000\n",
    "tot_tran_lst.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment Threads\n",
    "\n",
    "**Question 4**\n",
    "\n",
    "As a hacker, you get your daily dose of tech news on [Hacker News](https://news.ycombinator.com/). The problem now is that you don't have internet access on your phone in your morning commute to work, so you want to save the interesting stories' comments thread beforehand in a flat file source like csv. You find their API documentation ( https://github.com/HackerNews/API) and implement the following task:\n",
    "\n",
    "1. Write a function `get_comments` that takes `storyid` as a parameter and returns a dataframe of all the comments below the news story. You can ignore 'dead' comments (you will know it when you see it). **Make sure the order of the comments in your dataframe is from top to bottom just as you see on the website**. You are allowed to use loops in this function. Addtional requirement: write at least one helper method\n",
    "\n",
    "You only want these information for the comments:\n",
    "1. `id`: the unique ids\n",
    "2. `by`: the author of the comment\n",
    "3. `parent`: who (also in unique ids) they are replying to\n",
    "4. `text`: the actual comment\n",
    "5. `time`: when the comment is created (in `pd.datetime` format)\n",
    "\n",
    "Hints:\n",
    "1. Use depth-first-search when traversing the comments tree.\n",
    "2. https://docs.python.org/3/tutorial/datastructures.html#using-lists-as-stacks.\n",
    "3. Check the size of your dataframe to the story's `descendants` attribute (number of comments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_endpoint = \"https://hacker-news.firebaseio.com/v0/item/18344932.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'by': 'ScottWRobinson', 'descendants': 18, 'id': 18344932, 'kids': [18380397, 18346406, 18348601, 18346750, 18346476, 18346746, 18346388], 'score': 47, 'time': 1540987334, 'title': 'TimescaleDB 1.0 Is Production Ready', 'type': 'story', 'url': 'https://blog.timescale.com/1-0-enterprise-production-ready-time-series-database-open-source-d32395a10cbf'}\n"
     ]
    }
   ],
   "source": [
    "storyid = 18344932\n",
    "news_endpoint = 'https://hacker-news.firebaseio.com/v0/item/' + str(storyid) + '.json'\n",
    "news = json.loads(requests.get(news_endpoint).text)\n",
    "kids = news.get('kids')\n",
    "print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out(kids):\n",
    "    for kid in kids:\n",
    "        kids_endpoint = 'https://hacker-news.firebaseio.com/v0/item/' + str(kid) + '.json'\n",
    "        rq = requests.get(kids_endpoint)\n",
    "        com = json.loads(rq.text)\n",
    "        # print(com.get('text'), com.get('type'))\n",
    "        print(com)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get kids ids with recursion\n",
    "def get_kids_ids(kids, ids):\n",
    "    \"\"\"\n",
    "    Get all the kids ids within kids.\n",
    "    \n",
    "    :param kids: a list of kids ids\n",
    "    :param ids: id list to append to and return\n",
    "    :return: a list of kids ids (recursive)\n",
    "    \"\"\"\n",
    "    for kid in kids: # Loop through to check if comment\n",
    "        kids_endpoint = 'https://hacker-news.firebaseio.com/v0/item/' + str(kid) + '.json'\n",
    "        info = json.loads(requests.get(kids_endpoint).text)\n",
    "        \n",
    "        if not info.get('dead'): # Not dead comment \n",
    "            ids.append(info.get('id')) # Append to list ids\n",
    "            \n",
    "            if (info.get('kids') != None) and (info.get('type') == 'comment'): # Has kids, is comment\n",
    "                kids_ids = get_kids_ids(info.get('kids'), []) # Kids id list\n",
    "\n",
    "                if len(kids_ids) != 0: # Has kids\n",
    "                    for idx in kids_ids:\n",
    "                        ids.append(idx) # Append kids to answer\n",
    "\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(storyid):\n",
    "    \"\"\"\n",
    "    Returns a dataframe of all the comments below a news story\n",
    "    >>> out = get_comments(18344932)\n",
    "    >>> out.shape\n",
    "    (18, 5)\n",
    "    >>> out.loc[5, 'by']\n",
    "    'RobAtticus'\n",
    "    >>> out.loc[5, 'time'].day\n",
    "    31\n",
    "    \"\"\"\n",
    "    news_endpoint = 'https://hacker-news.firebaseio.com/v0/item/' + str(storyid) + '.json'\n",
    "    news = json.loads(requests.get(news_endpoint).text) # Story info\n",
    "    kids = news.get('kids') # Kids of story\n",
    "    \n",
    "    ids = get_kids_ids(kids, [])\n",
    "    df = pd.DataFrame()\n",
    "    cols = ['id', 'by', 'parent', 'text', 'time']\n",
    "    for idx in ids: \n",
    "        kids_endpoint = 'https://hacker-news.firebaseio.com/v0/item/' + str(idx) + '.json'\n",
    "        com = json.loads(requests.get(kids_endpoint).text)\n",
    "\n",
    "        by = com.get('by') # Author\n",
    "        parent = com.get('parent') # Parent id\n",
    "        text = com.get('text') # Comment text\n",
    "        time = pd.to_datetime(com.get('time'), unit='s') # Time of comment\n",
    "\n",
    "        content = [idx, by, parent, text, time] # Content list\n",
    "        comment = dict(zip(cols, content)) # Zip into dataframe\n",
    "        df = df.append(comment, ignore_index=True) # Append to answer\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>by</th>\n",
       "      <th>id</th>\n",
       "      <th>parent</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>valyala</td>\n",
       "      <td>18380397.0</td>\n",
       "      <td>18344932.0</td>\n",
       "      <td>TimescaleDB is great for storing time series c...</td>\n",
       "      <td>2018-11-05 06:53:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>msiggy</td>\n",
       "      <td>18346406.0</td>\n",
       "      <td>18344932.0</td>\n",
       "      <td>I&amp;#x27;m excited to give this database a try i...</td>\n",
       "      <td>2018-10-31 15:20:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sman393</td>\n",
       "      <td>18348601.0</td>\n",
       "      <td>18344932.0</td>\n",
       "      <td>Can this be used side by side on normal Postgr...</td>\n",
       "      <td>2018-10-31 19:29:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18348631.0</td>\n",
       "      <td>18348601.0</td>\n",
       "      <td>Yep, absolutely. Regular PostgreSQL tables coe...</td>\n",
       "      <td>2018-10-31 19:34:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sman393</td>\n",
       "      <td>18348984.0</td>\n",
       "      <td>18348631.0</td>\n",
       "      <td>Good to hear! how does the current TimescaleDB...</td>\n",
       "      <td>2018-10-31 20:23:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18349540.0</td>\n",
       "      <td>18348984.0</td>\n",
       "      <td>Not sure I follow exactly what you&amp;#x27;re ask...</td>\n",
       "      <td>2018-10-31 21:47:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sman393</td>\n",
       "      <td>18350673.0</td>\n",
       "      <td>18349540.0</td>\n",
       "      <td>Alright thanks! I thought I read that Timescal...</td>\n",
       "      <td>2018-11-01 01:11:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18351061.0</td>\n",
       "      <td>18350673.0</td>\n",
       "      <td>It does not support sharding writes across mul...</td>\n",
       "      <td>2018-11-01 02:35:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zip1234</td>\n",
       "      <td>18346750.0</td>\n",
       "      <td>18344932.0</td>\n",
       "      <td>How fast is it when it has a TB of data? I rea...</td>\n",
       "      <td>2018-10-31 15:51:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nevi-me</td>\n",
       "      <td>18347260.0</td>\n",
       "      <td>18346750.0</td>\n",
       "      <td>I spent about 8 months writing data to TSDB. I...</td>\n",
       "      <td>2018-10-31 16:47:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dominotw</td>\n",
       "      <td>18347555.0</td>\n",
       "      <td>18346750.0</td>\n",
       "      <td>They have some numbers on their blog. Its very...</td>\n",
       "      <td>2018-10-31 17:19:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dominotw</td>\n",
       "      <td>18346476.0</td>\n",
       "      <td>18344932.0</td>\n",
       "      <td>I evaluated this heavily but had to backoff be...</td>\n",
       "      <td>2018-10-31 15:27:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18346702.0</td>\n",
       "      <td>18346476.0</td>\n",
       "      <td>Sorry to hear, though I&amp;#x27;d like to mention...</td>\n",
       "      <td>2018-10-31 15:47:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>grumpydba</td>\n",
       "      <td>18347232.0</td>\n",
       "      <td>18346702.0</td>\n",
       "      <td>Hi,&lt;p&gt;are the upcoming clustering efforts deve...</td>\n",
       "      <td>2018-10-31 16:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jason_slack</td>\n",
       "      <td>18349689.0</td>\n",
       "      <td>18346476.0</td>\n",
       "      <td>What were the specs of the machine you were us...</td>\n",
       "      <td>2018-10-31 22:16:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>athenot</td>\n",
       "      <td>18346746.0</td>\n",
       "      <td>18344932.0</td>\n",
       "      <td>It would be nice if they did a quick compariso...</td>\n",
       "      <td>2018-10-31 15:51:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18346787.0</td>\n",
       "      <td>18346746.0</td>\n",
       "      <td>We do have comparisons, but judging by their M...</td>\n",
       "      <td>2018-10-31 15:56:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>athenot</td>\n",
       "      <td>18346822.0</td>\n",
       "      <td>18346787.0</td>\n",
       "      <td>Thanks a lot, this is useful for comparing.&lt;p&gt;...</td>\n",
       "      <td>2018-10-31 16:00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             by          id      parent  \\\n",
       "0       valyala  18380397.0  18344932.0   \n",
       "1        msiggy  18346406.0  18344932.0   \n",
       "2       sman393  18348601.0  18344932.0   \n",
       "3    RobAtticus  18348631.0  18348601.0   \n",
       "4       sman393  18348984.0  18348631.0   \n",
       "5    RobAtticus  18349540.0  18348984.0   \n",
       "6       sman393  18350673.0  18349540.0   \n",
       "7    RobAtticus  18351061.0  18350673.0   \n",
       "8       zip1234  18346750.0  18344932.0   \n",
       "9       nevi-me  18347260.0  18346750.0   \n",
       "10     dominotw  18347555.0  18346750.0   \n",
       "11     dominotw  18346476.0  18344932.0   \n",
       "12   RobAtticus  18346702.0  18346476.0   \n",
       "13    grumpydba  18347232.0  18346702.0   \n",
       "14  jason_slack  18349689.0  18346476.0   \n",
       "15      athenot  18346746.0  18344932.0   \n",
       "16   RobAtticus  18346787.0  18346746.0   \n",
       "17      athenot  18346822.0  18346787.0   \n",
       "\n",
       "                                                 text                time  \n",
       "0   TimescaleDB is great for storing time series c... 2018-11-05 06:53:19  \n",
       "1   I&#x27;m excited to give this database a try i... 2018-10-31 15:20:22  \n",
       "2   Can this be used side by side on normal Postgr... 2018-10-31 19:29:39  \n",
       "3   Yep, absolutely. Regular PostgreSQL tables coe... 2018-10-31 19:34:52  \n",
       "4   Good to hear! how does the current TimescaleDB... 2018-10-31 20:23:46  \n",
       "5   Not sure I follow exactly what you&#x27;re ask... 2018-10-31 21:47:20  \n",
       "6   Alright thanks! I thought I read that Timescal... 2018-11-01 01:11:59  \n",
       "7   It does not support sharding writes across mul... 2018-11-01 02:35:03  \n",
       "8   How fast is it when it has a TB of data? I rea... 2018-10-31 15:51:43  \n",
       "9   I spent about 8 months writing data to TSDB. I... 2018-10-31 16:47:34  \n",
       "10  They have some numbers on their blog. Its very... 2018-10-31 17:19:34  \n",
       "11  I evaluated this heavily but had to backoff be... 2018-10-31 15:27:29  \n",
       "12  Sorry to hear, though I&#x27;d like to mention... 2018-10-31 15:47:41  \n",
       "13  Hi,<p>are the upcoming clustering efforts deve... 2018-10-31 16:44:39  \n",
       "14  What were the specs of the machine you were us... 2018-10-31 22:16:27  \n",
       "15  It would be nice if they did a quick compariso... 2018-10-31 15:51:13  \n",
       "16  We do have comparisons, but judging by their M... 2018-10-31 15:56:39  \n",
       "17  Thanks a lot, this is useful for comparing.<p>... 2018-10-31 16:00:29  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = get_comments(18344932)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.equals(lab.get_comments(18344932))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit the lab on Gradescope"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
