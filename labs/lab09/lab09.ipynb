{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Lab 09\n",
    "\n",
    "### Due Date: Tuesday, March 10th, 11:59 pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding work will be developed in an accompanying `lab*.py` file, that will be imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying python file will be tested (a la DSC 20),\n",
    "2. The notebook will be graded (for graphs and free response questions).\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for working in the Notebook**:\n",
    "- The notebooks serve to present you the questions and give you a place to present your results for later review.\n",
    "- The notebook on *lab assignments* are not graded (only the `.py` file).\n",
    "- Notebooks for PAs will serve as a final report for the assignment, and contain conclusions and answers to open ended questions that are graded.\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `.py` file.\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the lab! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `lab**.py` (much like we do in the notebook).\n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code from `lab**.py`\n",
    "\n",
    "* We import our `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab**.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab**.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab**.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab**` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lab09 as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Acquainted with `sklearn` Pipelines\n",
    "\n",
    "The file `data/toy.csv` contains toy data that consists of 4 columns:\n",
    "```\n",
    "group: a categorical column with 3 categories\n",
    "c1: a numeric attribute\n",
    "c2: a numeric attribute\n",
    "y: the target variable (that you want to predict) \n",
    "```\n",
    "\n",
    "In the following questions, you will build ML pipelines that combine feature engineering with a simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>4.058118</td>\n",
       "      <td>5.329582</td>\n",
       "      <td>12.649035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>4.194945</td>\n",
       "      <td>3.839476</td>\n",
       "      <td>17.309083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2.246411</td>\n",
       "      <td>10.694666</td>\n",
       "      <td>15.695646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>2.510912</td>\n",
       "      <td>6.414960</td>\n",
       "      <td>11.535752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>3.194722</td>\n",
       "      <td>6.116839</td>\n",
       "      <td>14.954389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group        c1         c2          y\n",
       "0     B  4.058118   5.329582  12.649035\n",
       "1     A  4.194945   3.839476  17.309083\n",
       "2     A  2.246411  10.694666  15.695646\n",
       "3     B  2.510912   6.414960  11.535752\n",
       "4     B  3.194722   6.116839  14.954389"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'toy.csv')\n",
    "data = pd.read_csv(fp)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "First, you will train a regression model using only a *log-scaled* `c2` variable. Create a simple pipeline that:\n",
    "1. log-scales `c2`, then\n",
    "2. predicts `y` using a linear regression model (using your transformed `c2`).\n",
    "\n",
    "That is, create a function `simple_pipeline` that takes in a dataframe like `data` and returns a tuple consisting of the pipeline and the predictions your model makes on `data` (as trained on `data`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTransformer(accept_sparse=False, check_inverse=True, func=<ufunc 'log'>,\n",
       "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                    validate=False)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_func = FunctionTransformer(np.log)\n",
    "log_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.62080258, 11.33240999, 15.35709202, 13.34904182, 13.16208199,\n",
       "       12.58730638, 10.32010771,  9.97565958, 12.4341862 ,  9.97565958,\n",
       "       11.00176451, 11.72576886, 13.29324648, 13.52069629, 12.69877755,\n",
       "       16.56022602, 10.90515178, 11.59328864, 13.75185396, 10.13914047,\n",
       "       16.45741691, 12.22981832, 10.03041175, 13.6458863 , 10.40933462,\n",
       "        9.97565958, 12.6181805 , 13.2395772 , 17.80416143,  9.97565958,\n",
       "       17.31864025, 11.70631644, 10.04917783, 13.54303459, 10.23465198,\n",
       "        9.97565958,  9.97565958, 14.13802627, 15.54064641,  9.97565958,\n",
       "        9.97565958, 15.66902784,  9.97565958, 14.88720712, 10.67109288,\n",
       "       11.29811807, 13.80545472, 10.23529717, 10.40456903, 13.08402701,\n",
       "        9.97565958,  9.97565958,  9.97565958,  9.97565958, 15.10329322,\n",
       "       12.32722694, 13.95698297,  9.97565958,  9.97565958,  9.97565958,\n",
       "        9.97565958, 11.05800145,  9.97565958,  9.97565958, 13.77397551,\n",
       "       17.70287735, 10.31042233, 15.31536588, 16.33383322,  9.97565958,\n",
       "       14.97079869,  9.97565958,  9.98941903,  9.97565958,  9.97565958,\n",
       "       12.13115627, 13.08264655, 10.7803003 , 10.10361658, 12.50925298,\n",
       "       11.81374969,  9.97565958, 13.92511727, 12.32665705, 16.39950047,\n",
       "       12.03158679, 13.53876868, 10.51132597, 10.54800032,  9.97565958,\n",
       "       11.77860887, 11.85689079,  9.97565958,  9.97565958,  9.97565958,\n",
       "       15.30979672, 12.83403068,  9.97565958,  9.97565958, 12.48678172,\n",
       "       12.83662321, 17.19677166,  9.97565958, 11.07949006, 11.75638585,\n",
       "        9.97565958,  9.97565958, 15.48895222, 16.44897237, 10.22508261,\n",
       "       11.76346936, 10.65584042,  9.97565958, 13.36049064, 12.94928047,\n",
       "        9.97565958, 15.21954177,  9.97565958,  9.97565958, 13.54993378,\n",
       "       13.561096  , 14.43596118,  9.97565958, 11.55771178,  9.97565958,\n",
       "        9.97565958, 13.27936289, 10.25134273, 12.99433539, 12.24478839,\n",
       "       17.16461764, 16.16340779, 11.91935422,  9.97565958, 12.91275162,\n",
       "       12.06812144, 13.70607754, 10.93894617,  9.97565958,  9.97565958,\n",
       "       16.95568066, 14.17948161,  9.97565958, 10.09150604,  9.97565958,\n",
       "        9.97565958, 15.5245347 , 15.69166602,  9.97565958, 12.16121561,\n",
       "        9.97565958, 15.20778645,  9.97565958, 13.66935098, 12.85299909,\n",
       "       11.1169081 ,  9.97565958, 13.15247854, 13.17396895,  9.97565958,\n",
       "        9.97565958, 10.67882736,  9.97565958, 15.11138844, 11.59727103,\n",
       "       11.60776838,  9.97565958,  9.97565958, 11.37678765,  9.97565958,\n",
       "        9.97565958, 10.78401688, 16.61547736, 11.65824063, 16.61259132,\n",
       "       11.17821344, 10.22916637, 11.37745497, 11.31561077, 11.95768093,\n",
       "       12.44785701, 11.52709598, 14.51876791, 11.25801369,  9.97565958,\n",
       "       16.95047842, 15.66171267,  9.97565958,  9.97565958, 12.46368585,\n",
       "       13.33723475,  9.97565958, 11.42996096,  9.99737386, 12.35950949,\n",
       "       13.35478251, 10.19181867, 12.92463884, 16.97302338, 17.57926795,\n",
       "       11.87437159, 11.77028686, 11.8893785 , 15.99889197, 15.36768212,\n",
       "        9.97565958,  9.97565958,  9.97565958, 12.87627787, 17.09109771,\n",
       "       17.45244492, 11.61042586, 10.66161341, 15.33385765, 12.58358769,\n",
       "       12.68124667, 16.05583385, 15.22617885,  9.97565958, 11.57587922,\n",
       "        9.97565958,  9.97565958,  9.97565958,  9.97565958,  9.97565958,\n",
       "       10.01440475, 13.86781388, 12.19758444, 13.62519929,  9.97565958,\n",
       "        9.97565958, 11.22330338,  9.97565958, 13.32666444, 11.04178574,\n",
       "       11.3693541 , 17.19195619, 11.20587562, 17.01821599,  9.97565958,\n",
       "       11.88632292, 12.80093113, 15.50143365, 12.77772219,  9.97565958,\n",
       "       10.41193255,  9.97565958, 14.51204242,  9.97565958,  9.97565958,\n",
       "       10.27706103, 10.04047086,  9.97565958, 13.02676223,  9.97565958,\n",
       "        9.97565958,  9.97565958, 12.74344643,  9.97565958, 11.46221303,\n",
       "        9.97565958,  9.97565958, 10.93915291, 10.35627437,  9.97565958,\n",
       "       13.11539395,  9.97565958,  9.97565958,  9.97565958, 10.52865504,\n",
       "        9.97565958, 10.52971618, 13.22522968, 14.04751392,  9.97565958,\n",
       "        9.97565958, 17.69846674, 17.61394016,  9.97565958, 12.04230792,\n",
       "       10.75025581, 10.40807705, 10.75233232,  9.97565958, 13.38179119,\n",
       "        9.97565958, 16.96040179,  9.97565958,  9.97565958, 11.81973849,\n",
       "       16.8108996 , 15.30804614, 11.25883912,  9.97565958, 11.12233312,\n",
       "        9.97565958, 13.13982838,  9.97565958, 13.76442954, 10.46288759,\n",
       "       10.62007072,  9.97565958, 12.32083736, 10.81357597, 11.12772182,\n",
       "        9.97565958,  9.97565958, 13.41439573,  9.97565958,  9.97565958,\n",
       "       16.97055326, 11.49112927, 10.4981806 ,  9.97565958, 15.78959252,\n",
       "        9.97565958, 11.46653935,  9.97565958, 10.32845142, 13.05367366,\n",
       "       15.33809366, 10.65945241, 13.18366573,  9.97565958,  9.97565958,\n",
       "       13.71013213, 13.74644658, 11.90355806,  9.97565958, 16.47962223,\n",
       "        9.97565958, 17.82545175, 13.07417451, 14.09228198,  9.97565958,\n",
       "       11.67483493, 10.59804431, 12.63698105, 12.76283502, 10.28237809,\n",
       "       15.78219854, 13.3691373 , 10.99163155,  9.97565958, 10.10603872,\n",
       "       17.58320268, 10.43602798, 11.70814523, 10.1618998 , 10.27285872,\n",
       "       13.12108083, 12.19997426, 13.83270531,  9.97565958, 12.41565244,\n",
       "        9.97565958, 13.43423824, 10.0902715 , 16.74339555, 10.46035902,\n",
       "       12.78781094, 16.1490684 ,  9.97565958,  9.97565958,  9.97565958,\n",
       "       12.55975452, 16.07801388, 12.75242448,  9.97565958,  9.97565958,\n",
       "       14.4994008 , 17.18366433, 11.21256101, 12.40302373,  9.97565958,\n",
       "        9.97565958, 11.38528483, 11.97882261,  9.97565958,  9.97565958,\n",
       "       15.93974844,  9.97565958, 10.35542641, 10.90812587, 13.81281609,\n",
       "       15.15556833,  9.97565958, 13.37815447, 15.38691098,  9.97565958,\n",
       "        9.99971641, 17.32061718, 10.7555004 , 10.63219403, 13.48690591,\n",
       "       15.69198269,  9.97565958, 13.04596471, 13.43805111,  9.97565958,\n",
       "        9.97565958, 14.042934  ,  9.97565958, 15.92840483, 16.82167524,\n",
       "       14.22093142, 13.76276229, 17.71516554, 15.88755989, 12.9449486 ,\n",
       "       17.71546077,  9.97565958, 11.31295278, 13.70127095, 10.3780194 ,\n",
       "       11.76161729, 14.71961744,  9.97565958,  9.97565958,  9.97565958,\n",
       "        9.97565958, 17.64075363, 10.92989648, 10.91755973, 10.73117707,\n",
       "       10.15927622,  9.97565958,  9.97565958, 13.59399732, 12.9357942 ,\n",
       "       15.40366445, 10.90862295, 13.73589925, 17.70347119, 13.27571655,\n",
       "        9.97565958, 11.97818654,  9.97565958, 14.08321257, 10.75929469,\n",
       "       11.10898544,  9.97565958, 13.68355085,  9.97565958, 11.98825433,\n",
       "       12.80707139, 11.50966114,  9.97565958, 13.58303118, 10.60642725,\n",
       "        9.97565958, 16.72318793, 12.3264533 ,  9.97565958, 15.2184814 ,\n",
       "       13.29978323, 12.97034507,  9.97565958,  9.97565958, 11.98695249,\n",
       "       11.8990132 ,  9.97565958,  9.97565958, 11.91706476, 10.91155378,\n",
       "        9.97565958, 11.38215145,  9.97565958,  9.97565958,  9.97565958,\n",
       "        9.97565958,  9.97565958, 16.56691362, 10.12066751,  9.97565958,\n",
       "       11.87006024,  9.97565958, 13.09818697,  9.97565958,  9.97565958,\n",
       "        9.97565958, 13.38591582, 17.49040014,  9.97565958,  9.97565958,\n",
       "       10.22317257, 13.88312785,  9.97565958, 10.42482477, 10.94443286,\n",
       "       13.884551  ,  9.97565958,  9.97565958, 13.22976778,  9.97565958,\n",
       "       10.53971169, 16.06344627, 17.41637944, 12.64468728,  9.97565958,\n",
       "       12.25836558, 13.42098748, 13.79078882, 12.49506072, 10.78275677,\n",
       "       11.23317629, 11.53154154, 10.97546763, 15.00491495,  9.97565958,\n",
       "        9.97565958, 13.78590081,  9.97565958, 12.75410524, 12.74683941,\n",
       "       10.11983434,  9.97565958,  9.97565958, 16.86508271,  9.97565958,\n",
       "       15.25623441,  9.97565958, 16.60618568,  9.97565958,  9.97565958,\n",
       "       11.27288853,  9.97565958, 10.95352145, 11.42793026, 17.19172569,\n",
       "        9.97565958, 11.04556234, 10.3383521 , 12.7745725 , 12.26070194,\n",
       "        9.97565958, 10.70640022,  9.97565958, 11.12037546, 12.79908607,\n",
       "       10.47143541, 16.42717866,  9.97565958, 11.1482248 , 12.11315514,\n",
       "       13.03794349,  9.97565958, 11.98644183, 11.41196228, 12.51536703,\n",
       "        9.97565958, 11.94763047, 14.51746747, 10.42605268, 13.76390148,\n",
       "       14.0939867 , 10.55193634, 10.65498488, 10.65601278,  9.97565958,\n",
       "       11.31162224, 13.49656182, 13.85910957, 12.29863487,  9.97565958,\n",
       "        9.97565958, 13.19112394, 12.59473678, 13.3210707 , 13.16187343,\n",
       "       11.33364678, 15.7811    ,  9.97565958,  9.97565958, 12.95418428,\n",
       "       13.46329589, 10.89456271,  9.97565958,  9.97565958, 10.53114945,\n",
       "       12.30817737, 16.7157405 ,  9.97565958, 13.02389138,  9.97565958,\n",
       "       11.76495614, 17.2991513 ,  9.97565958, 13.26850328,  9.97565958,\n",
       "        9.97565958, 14.16123963, 11.5912912 ,  9.97565958, 12.89903369,\n",
       "       15.8310652 , 10.45267729, 13.60720075, 15.45100049, 10.17030895,\n",
       "        9.97565958,  9.97565958, 13.81906688,  9.97565958, 11.17747759,\n",
       "       12.2162966 ,  9.97565958, 10.7122958 ,  9.97565958,  9.97565958,\n",
       "       13.09701822,  9.97565958,  9.97565958,  9.97565958, 10.47265501,\n",
       "       13.6713085 , 12.73887688,  9.97565958, 12.49094396,  9.97565958,\n",
       "        9.97565958, 10.13737275, 13.84929437, 13.75757825, 17.13526349,\n",
       "       10.70989791,  9.97565958,  9.97565958,  9.97565958,  9.993585  ,\n",
       "        9.97565958, 10.97037769, 10.92666962,  9.97565958, 11.09260823,\n",
       "        9.97565958,  9.97565958,  9.97565958, 12.5012178 , 10.21479206,\n",
       "        9.97565958, 10.91382297,  9.97565958, 10.33924892,  9.97565958,\n",
       "       17.5898811 , 11.18214284, 11.23533698, 12.24799262, 15.94691672,\n",
       "       10.35165026,  9.97565958, 13.73636792, 16.3321004 ,  9.97565958,\n",
       "        9.97565958, 10.41438668, 13.01912144, 17.28711596, 16.34284274,\n",
       "        9.97565958, 11.28530007,  9.97565958, 13.71104368,  9.97565958,\n",
       "       17.56361205, 10.61696234,  9.97565958, 10.09000327, 11.65393767,\n",
       "       15.52587135, 15.60353223,  9.97565958, 12.91592323, 16.17869377,\n",
       "       14.17112878, 17.34280162,  9.97565958,  9.97565958,  9.97565958,\n",
       "       10.91997874, 11.68661681, 10.52969153,  9.97565958,  9.97565958,\n",
       "       15.39256293, 17.12227775, 13.10105484, 15.72883017, 10.7952956 ,\n",
       "       10.53799897,  9.97565958, 14.98020969,  9.97565958,  9.97565958,\n",
       "       15.49208391,  9.97565958, 12.70333373, 10.26542107, 10.32526258,\n",
       "        9.97565958,  9.97565958, 12.07488455,  9.97565958,  9.97565958,\n",
       "       13.06109593, 17.12699538, 11.42585625, 11.36102565,  9.97565958,\n",
       "       14.86195151,  9.97565958,  9.97565958,  9.97565958,  9.97565958,\n",
       "       12.8267471 ,  9.97565958, 12.4035911 ,  9.97565958, 13.76791879,\n",
       "        9.97565958, 11.19705566, 13.74229995,  9.97565958,  9.97565958,\n",
       "        9.97565958,  9.97565958,  9.97565958, 10.20054896,  9.97565958,\n",
       "       11.01740052,  9.97565958, 12.64234202, 16.32486981,  9.97565958,\n",
       "       11.76197637, 17.67828823, 13.93969331, 14.26761992, 13.49358659,\n",
       "        9.97565958, 12.2881965 , 10.59794208, 13.99770861,  9.97565958,\n",
       "       11.08845292,  9.97565958, 12.44481556, 12.06732622, 13.46990942,\n",
       "        9.97565958, 15.16895504, 10.75625872,  9.97565958,  9.97565958,\n",
       "        9.97565958, 13.55721554,  9.97565958, 15.06035577,  9.97565958,\n",
       "       12.77018624, 14.864076  , 11.19882269,  9.97565958,  9.97565958,\n",
       "        9.97565958, 12.82357501,  9.97565958, 13.79019395,  9.97565958,\n",
       "        9.97565958, 12.98661954,  9.97565958,  9.97565958, 13.58863444,\n",
       "        9.97565958,  9.97565958, 12.89918505,  9.97565958, 10.83373105,\n",
       "        9.97565958, 15.57987081,  9.97565958, 12.24942525, 13.13774433,\n",
       "       10.24701557, 11.45129553, 13.46730627, 13.21358229,  9.97565958,\n",
       "       12.93870081, 12.4956441 , 11.71425277, 10.20476395, 10.75354936,\n",
       "        9.97565958, 15.75314214,  9.97565958,  9.97565958,  9.97565958,\n",
       "        9.97565958, 11.17721913, 10.07931159, 11.76449165,  9.97565958,\n",
       "       12.68856169, 13.18923536, 14.54583991, 11.77239358, 12.51032587,\n",
       "       15.0430019 , 14.79365433, 10.30058681, 13.05513441,  9.97565958,\n",
       "       12.60210772,  9.97565958,  9.97565958, 13.99001569, 12.11639546,\n",
       "        9.97565958,  9.97565958, 15.14417906,  9.97565958, 10.62376849,\n",
       "        9.97565958, 13.56758631, 10.64252948, 11.95125538, 11.86352339,\n",
       "       13.09670436, 12.37696051,  9.97565958,  9.97565958, 11.38617054,\n",
       "       10.32501516,  9.97565958,  9.97565958,  9.97565958,  9.97565958,\n",
       "       11.52742717,  9.97565958, 13.80071516, 12.02489433, 16.00703476,\n",
       "       12.84747845, 15.75299456, 13.44286055, 13.40694364, 15.69013931,\n",
       "        9.97565958, 14.02221589, 12.96195769,  9.97565958, 10.05807227,\n",
       "       16.92958097, 14.82777417,  9.97565958,  9.97565958, 12.70900592,\n",
       "       12.25215438, 17.51853315,  9.97565958, 12.54734446, 10.08023582,\n",
       "       13.26627247,  9.97565958, 16.41547002, 14.4285397 , 11.81757478,\n",
       "       10.38831895, 11.93280492, 12.89989679, 11.26201196, 10.6228103 ,\n",
       "       15.32428304,  9.97565958, 12.40955245, 10.12724203,  9.97565958,\n",
       "        9.97565958, 16.99459092, 15.63216373, 11.76673713,  9.97565958,\n",
       "       11.97696422, 14.99058325, 14.86402971, 12.01088689,  9.97565958,\n",
       "       13.10785302,  9.97565958, 13.00188306, 11.23364152,  9.97565958,\n",
       "       16.88326227, 11.39499669,  9.97565958, 13.18284039, 12.37558032,\n",
       "       13.85286048, 17.01264007, 12.95421718, 15.31017443,  9.97565958,\n",
       "       15.40331386, 10.96171678, 10.46024776,  9.97565958,  9.97565958,\n",
       "        9.97565958, 11.29209231, 10.12395704, 15.69652679,  9.97565958,\n",
       "       12.150477  , 13.15586761, 14.94778375, 14.37110033, 10.67087349,\n",
       "       11.63765392, 17.00664773,  9.97565958,  9.97565958, 16.13419664,\n",
       "       16.89267844, 13.39314687, 13.40687981, 12.49989409, 16.18019237,\n",
       "        9.97565958, 13.85163289,  9.97565958, 10.81447183, 15.59747331,\n",
       "       16.14675954, 13.60971356, 10.4318057 ,  9.97565958,  9.97565958,\n",
       "       12.82273258, 12.17465763, 12.60014657,  9.97565958, 13.86114296,\n",
       "       10.48746387, 13.8159025 , 12.92830624, 10.44587545, 16.05306139,\n",
       "        9.97565958,  9.97565958, 10.35318988,  9.97565958, 16.89278246,\n",
       "       13.87428726,  9.97565958,  9.97565958, 13.21569808, 13.27316617,\n",
       "        9.97565958, 15.66846787, 12.31638323, 14.71867157,  9.97565958,\n",
       "       16.77067106, 12.30487956,  9.97565958, 12.58350096, 13.88246359,\n",
       "       16.82276247, 11.87434833,  9.97565958,  9.97565958, 11.54015012,\n",
       "        9.97565958, 13.07613496, 14.57507625, 12.5648947 , 16.68805304,\n",
       "        9.97565958, 13.49076308, 12.09301547, 13.65674302,  9.97565958,\n",
       "       11.52977678, 13.06336949,  9.97565958, 10.01720376, 12.21720691,\n",
       "       15.13731862, 11.04490255, 13.29734439, 13.32979283,  9.97565958,\n",
       "        9.97565958, 14.51709931, 13.80139968,  9.97565958,  9.97565958])"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_pl = Pipeline(steps=[\n",
    "        ('log', log_func), \n",
    "        ('linear_reg', LinearRegression())])\n",
    "sim_pl.fit(data[['c2']], data['y'])\n",
    "predic = sim_pl.predict(data[['c2']])\n",
    "predic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_c2 = np.array(data['c2'].apply(np.log)).reshape(1000, 1)\n",
    "regressor = LinearRegression()  \n",
    "regressor.fit(log_c2, data['y']) #training the algorithm\n",
    "# regressor.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor.predict(log_c2) == predic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_pipeline(data):\n",
    "    '''\n",
    "    simple_pipeline takes in a dataframe like data and returns a tuple \n",
    "    consisting of the pipeline and the predictions your model makes \n",
    "    on data (as trained on data).\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'toy.csv')\n",
    "    >>> data = pd.read_csv(fp)\n",
    "    >>> pl, preds = simple_pipeline(data)\n",
    "    >>> isinstance(pl, Pipeline)\n",
    "    True\n",
    "    >>> isinstance(pl.steps[-1][1], LinearRegression)\n",
    "    True\n",
    "    >>> isinstance(pl.steps[0][1], FunctionTransformer)\n",
    "    True\n",
    "    >>> preds.shape[0] == data.shape[0]\n",
    "    True\n",
    "    '''\n",
    "    log_func = FunctionTransformer(np.log)\n",
    "    sim_pl = Pipeline(steps=[\n",
    "        ('log', log_func), \n",
    "        ('linear_reg', LinearRegression())\n",
    "    ])\n",
    "    pred = sim_pl.fit(data[['c2']], data['y'])\n",
    "    predic = sim_pl.predict(data[['c2']])\n",
    "    return (sim_pl, predic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl, preds = simple_pipeline(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-530-4e7cf88c6015>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "preds.shape[0] == data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Now, you will engineer features from the other columns and use them to train a regression model.  Create a pipeline that:\n",
    "1. uses `c1` as is,\n",
    "1. log-scales `c2`,\n",
    "1. one-hot encodes `group`,\n",
    "1. predicts `y` using a linear regression model built on the three variable-classes above.\n",
    "\n",
    "Use `ColumnTransformer` to put together all the column-specific preprocessing steps into a single set of features for fitting the regression model.\n",
    "\n",
    "That is, create a function `multi_type_pipeline` that takes in a dataframe like `data` and returns a tuple consisting of the pipeline and the predictions your model makes on `data` (as trained on `data`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.18531033, 14.74441827, 15.42116947, 12.83429335, 13.03799741,\n",
       "       12.25310004, 12.43767512,  8.74186776, 14.83866743,  8.43157896,\n",
       "       14.45273363, 11.75741912, 14.93030885, 13.26345315, 15.44172887,\n",
       "       15.73687497, 11.62811781, 13.94580247, 13.31105138, 10.78091375,\n",
       "       11.7671027 ,  9.8941669 , 11.89697715, 14.75691376, 13.9173444 ,\n",
       "        8.33272857, 12.29120177, 12.75076932, 16.93692483,  9.38692656,\n",
       "       16.41488837, 14.48484395, 13.97972499, 15.37545555, 11.73064088,\n",
       "        8.51307035,  8.33440007, 15.31917206, 16.2222295 , 11.05978077,\n",
       "        8.30549967, 15.82504116,  8.53576633, 14.97654842, 11.90167448,\n",
       "       11.84565315, 10.64367785, 11.94487026, 11.77943364, 12.28160821,\n",
       "        8.2717144 ,  9.39694084,  9.37574575,  8.18938447, 16.03260617,\n",
       "       10.26170311, 16.00340929,  9.13893949,  8.68829782,  9.31903673,\n",
       "        8.22310871, 12.32226532,  8.88997857,  8.21400817, 12.83686165,\n",
       "       16.40954262, 11.23785325, 15.27415617, 16.43653785, 10.93296329,\n",
       "       15.12431287,  9.49143228, 11.08209631,  8.24193682,  9.31353805,\n",
       "       12.15382791, 12.59110382, 12.32111891, 11.7893595 , 12.15558619,\n",
       "       11.73738008, 11.10105561, 15.54540115, 12.31248341, 15.33758984,\n",
       "       12.46931485, 12.66027011, 11.54521595, 14.0015667 ,  9.10892195,\n",
       "       11.5041973 , 12.56002948,  9.29213751,  8.94283595,  8.36278755,\n",
       "       16.46262939, 12.66078586,  8.29185556,  9.2124712 , 14.3715037 ,\n",
       "       12.76514656, 16.39220462,  8.66682226, 11.51237784, 11.44538124,\n",
       "        8.88367454,  8.94014148, 15.61944071, 16.30317639, 13.28898107,\n",
       "       14.51456068, 11.63732701,  8.49012059, 12.67347879, 14.75417662,\n",
       "       12.85495414, 16.08869089,  7.86122092,  8.10558003, 15.62873131,\n",
       "       15.30609172, 15.70696258,  8.95018795, 11.98051444,  9.19657028,\n",
       "        8.60302749, 15.04155903, 13.71727441, 14.79361518, 13.37013282,\n",
       "       16.16493007, 15.27767919, 12.18392834,  8.5075196 , 15.14552681,\n",
       "       11.40289292, 15.58618929, 11.73769378,  8.60329136,  8.53472945,\n",
       "       16.11181644, 11.29230541,  8.75375335, 11.26208747,  8.53005654,\n",
       "        8.75492311, 15.57181131, 14.57087334,  8.37667743, 14.80589441,\n",
       "        8.89632078, 15.51086594,  8.67148358, 12.81743766, 14.800459  ,\n",
       "       11.65747044,  8.99466866, 12.39506247, 12.60905501,  8.96220362,\n",
       "        8.41617312, 11.58083447,  8.73685686, 15.43515837, 12.06115976,\n",
       "       12.44626129, 10.80153858,  8.89529039, 11.84431585,  8.89501844,\n",
       "        7.86743289, 11.77965879, 15.97390235, 14.1598465 , 16.29431876,\n",
       "       12.18159324, 11.12203048, 14.00032442, 11.69887821, 10.46015853,\n",
       "       13.93416517, 14.07646803, 15.05914819, 14.67019898,  9.35294611,\n",
       "       16.35826335, 15.60830669,  8.56156273,  8.90720223, 13.443261  ,\n",
       "       13.0273128 ,  8.90597237, 14.46434301, 11.57489532, 11.87527462,\n",
       "       12.03499763, 11.41051618, 14.07076799, 16.58767413, 17.1047704 ,\n",
       "       11.90323652, 14.00815427, 12.37847795, 15.88835619, 15.76678045,\n",
       "        8.79533732,  8.4047718 ,  7.64216447, 13.41567876, 16.85547664,\n",
       "       16.3077274 , 14.59708095, 12.00664589, 11.76585786, 12.05042972,\n",
       "       14.39520424, 15.69961359, 15.4034621 ,  8.51699688, 11.88243869,\n",
       "        8.23559067,  8.86646142, 13.04767599, 11.43459629,  8.46824686,\n",
       "       11.78731647, 12.56749263, 12.59293169, 12.61200289, 12.95997383,\n",
       "       10.76070021,  9.60087135,  9.15311812, 12.33728853, 11.27599988,\n",
       "       14.87129505, 16.57654423, 11.91437552, 16.22088206,  8.38866562,\n",
       "       12.59000437, 12.2826393 , 15.30380188, 15.42792525,  8.74401617,\n",
       "       11.5735807 ,  9.099614  , 15.35200453,  9.51605567,  7.79643788,\n",
       "       14.22293348, 11.22572638,  9.05996936, 12.3555144 ,  9.50141587,\n",
       "        8.19106534, 12.62877034, 10.30308635,  8.81171221,  9.67996417,\n",
       "        9.00807833,  8.71177249, 11.35091577, 14.08882437,  8.73604303,\n",
       "       12.70971279,  8.36951799,  8.75123334,  8.26847113, 10.95579146,\n",
       "        8.78693972, 12.03389324, 12.67301526, 15.09445681, 13.17980653,\n",
       "        8.63301654, 17.09516377, 16.01009363,  8.12041034, 12.17391419,\n",
       "       13.870609  , 11.73966434, 11.8338333 ,  8.59254327, 15.28915797,\n",
       "        8.69911259, 16.82870018,  8.48466188,  9.19064217, 11.80579673,\n",
       "       16.58588129, 13.61786867, 14.33512515,  8.51689106, 14.50698687,\n",
       "        8.14691267, 12.15341099,  9.26451048, 16.08899298, 13.78982825,\n",
       "       11.50474808,  8.65790533, 14.54628593, 11.59164041, 11.79738539,\n",
       "        8.46218536,  9.06376676, 14.37383461,  9.1843798 ,  8.53247932,\n",
       "       15.93128806, 13.98419665, 11.67922264,  8.31801942, 16.18406532,\n",
       "        8.87567094, 11.93892075,  8.37356438, 14.364156  , 14.67588705,\n",
       "       15.74980059, 11.5271299 , 14.59978997,  8.45582871,  9.69351613,\n",
       "       13.38574251, 14.9652951 , 12.47542493,  9.04869004, 16.27521922,\n",
       "        9.30546826, 16.79850469, 12.8482356 , 15.45334449,  8.28027448,\n",
       "       11.72345639, 11.76968366, 12.18633826, 12.48539295, 11.57237387,\n",
       "       16.3032669 , 12.58019114, 11.80180368,  9.18010378, 11.40320037,\n",
       "       16.65980554, 11.25713629, 14.79894391, 10.55361665, 11.73997974,\n",
       "       14.77916196, 14.12809114, 13.44926468,  8.2899103 , 15.364999  ,\n",
       "        8.32367777, 15.01524531, 10.51200827, 16.23838227, 11.67800935,\n",
       "       12.98969784, 15.91394299,  8.38967435,  8.3999171 , 10.58129712,\n",
       "       12.06575059, 15.62228414, 12.44884235,  8.8045582 ,  9.0032508 ,\n",
       "       15.26677333, 15.66469059, 14.60004918, 12.41008707,  9.12532031,\n",
       "        7.91465548, 11.74328074, 11.50200828,  8.75524516,  9.21912099,\n",
       "       15.86161222,  7.99292554, 13.58010878, 11.63270394, 15.30557207,\n",
       "       15.12401433,  9.31752349, 14.82532103, 15.76078396,  8.83962032,\n",
       "       14.96911278, 16.59166094, 14.46917165, 12.25216689, 14.55274569,\n",
       "       15.09036929,  8.09242662, 11.83944765, 12.63301826,  8.89683956,\n",
       "        8.65394766, 15.08880571, 10.44423279, 16.22569617, 16.2613389 ,\n",
       "       15.59390127, 13.05504998, 16.04153292, 15.68004612, 12.21463133,\n",
       "       15.84518399,  8.43698594, 12.43627458, 12.93820962, 11.30303866,\n",
       "       14.51861293, 14.97317714, 12.92542387,  9.08469663,  8.93204905,\n",
       "        8.65419876, 16.88909323, 12.09455801, 11.83171288, 13.55456145,\n",
       "       11.57351561,  9.28708604,  8.84739622, 13.0151064 , 14.87822967,\n",
       "       14.27313279, 11.96157639, 12.63965437, 16.63115969, 12.94096166,\n",
       "        8.94632481, 11.94567556,  8.57517433, 15.94864332, 11.08734888,\n",
       "       13.55994403,  8.26940896, 10.23262703,  8.31148782, 12.44636458,\n",
       "       15.08786395, 11.7303241 ,  8.1467382 , 14.61886669, 11.38220983,\n",
       "        8.47668195, 16.22942701, 12.21586604,  8.99493803, 16.0959814 ,\n",
       "       15.91292331, 13.14973747,  8.71020978,  8.17766722, 12.01470988,\n",
       "       12.39656778,  8.72461126,  8.7729374 , 11.59445413, 14.3401658 ,\n",
       "        8.67324916, 11.32910819,  8.66557076,  8.55881672,  8.30778484,\n",
       "        9.23394874,  8.65580244, 16.08934691, 11.64747452,  8.18101053,\n",
       "       12.28603286,  8.75121651, 15.06749275,  9.35893052,  8.20562329,\n",
       "        8.38798554, 12.0797865 , 16.38169511,  9.02352622,  9.238541  ,\n",
       "       13.6287461 , 15.3680564 ,  9.11702031, 11.29499833, 11.41982047,\n",
       "       12.69382659,  8.86460845,  8.18415951, 12.52504123,  9.0588716 ,\n",
       "       11.49489523, 16.43541322, 16.77287569, 14.5302961 ,  8.22059408,\n",
       "       11.87148898, 12.72618844, 13.50900517, 11.95022041, 13.92095639,\n",
       "       12.11146646, 12.1819225 , 12.03064631, 15.81743361,  9.13875989,\n",
       "        9.05238009, 12.76200526,  8.90041135, 12.48618168, 12.34937631,\n",
       "       11.94396512,  8.65937425,  8.46649209, 16.07096273,  9.02154479,\n",
       "       15.80024836,  8.69068817, 13.62698958,  8.0972348 ,  9.10847772,\n",
       "       11.48431088,  8.84996296,  9.25949345, 12.02899471, 15.92255796,\n",
       "        9.03400937, 11.74539846, 14.23403679, 12.54357267, 14.72486212,\n",
       "        8.15668819, 13.53972869,  8.85758092, 11.44889081, 13.06625406,\n",
       "       11.7535339 , 16.42902428,  9.10423061, 11.64748364, 12.02852476,\n",
       "       15.09256794,  8.79816779, 12.09323148, 11.5015536 , 10.18120767,\n",
       "        8.69470115, 14.1368787 , 15.47523139, 11.34445627, 12.25769413,\n",
       "       11.18856659, 12.51719873, 12.17717453, 13.6806179 ,  9.12139169,\n",
       "       12.15526117, 12.35123229, 15.57441369, 12.44322768,  8.27645216,\n",
       "        8.82796421, 12.52868916, 12.21543373, 12.44176797, 14.40755477,\n",
       "       12.22539791, 15.6069669 ,  8.23097888,  8.0737384 , 14.47650208,\n",
       "       10.31522923, 14.6438708 ,  8.2645855 ,  9.2288236 , 13.74832791,\n",
       "       12.65837488, 15.61327055,  8.34220347, 12.89287407,  8.52481252,\n",
       "       14.38208984, 16.45959717,  8.717192  , 12.7997059 ,  9.80093277,\n",
       "        9.29899772, 15.447747  , 14.26025861,  8.55842699, 12.37676499,\n",
       "       15.19853443, 11.04528893, 12.13010158, 15.87020597, 11.89012204,\n",
       "        8.95142589,  9.37909409, 15.30542644,  8.94237972, 11.62900843,\n",
       "       12.52353074,  8.41057342, 12.21108781,  8.49095656,  8.70277405,\n",
       "       12.65943325,  9.01431759,  8.57077016,  8.62078917, 12.20499122,\n",
       "       12.26974858, 14.70030969,  9.30791958, 11.93637538,  7.97912105,\n",
       "        9.13255756, 13.62623274, 13.49212814, 13.20145549, 16.68077793,\n",
       "       13.51571018,  8.29298368,  8.53272733,  8.89110921, 11.59747124,\n",
       "        8.63603277, 14.39753836, 14.18008496,  9.41749823, 11.85665558,\n",
       "        9.79437557,  8.99342303,  9.04736122, 11.87781358, 13.36349767,\n",
       "        9.11592663, 12.20437956,  8.06209264, 13.92288291,  8.67020648,\n",
       "       16.64634665,  9.60765114, 12.1090639 , 14.26148852, 15.67463251,\n",
       "       10.95614944,  8.98143343, 12.05353081, 15.80429605,  8.71994549,\n",
       "        8.23588337, 11.69541329, 12.62438647, 16.16853108, 15.5116485 ,\n",
       "        8.80676928, 12.79100452, 12.90555413, 12.58923348, 14.12215341,\n",
       "       15.96857859, 10.91635515,  9.29449489, 11.25386236, 12.82172692,\n",
       "       15.79006237, 16.36700664,  8.99750332, 10.33051291, 17.23275483,\n",
       "       14.4686284 , 16.626169  , 12.86290695,  8.48237032,  8.52780735,\n",
       "       13.69186209, 14.81868484, 11.82396863,  8.9958492 ,  8.08327082,\n",
       "       15.20835326, 15.77008438, 12.47156425, 14.81872025, 11.85553393,\n",
       "       11.09984473,  9.39078067, 15.34133371,  8.50745247,  8.76734743,\n",
       "       16.02209123,  8.42233806, 12.46646655, 11.67266278, 11.57194557,\n",
       "        9.66726341,  8.01446895, 12.3703077 ,  9.11582296,  8.41312886,\n",
       "       14.23950316, 15.43457051, 11.86683203, 15.30575792,  9.04088918,\n",
       "       15.58812642,  9.11136933,  8.12221277,  8.72101538,  9.25193819,\n",
       "       14.03593335,  9.34685502, 14.64846309,  9.03221978, 13.38603821,\n",
       "        9.52444292, 14.38992864, 14.6235555 ,  8.97341933,  9.45090224,\n",
       "        8.66952976, 11.78832709,  9.52583584, 11.15900554,  9.70242408,\n",
       "       11.14921781,  8.35191969, 12.10503925, 15.36112788,  8.92860541,\n",
       "       14.8356975 , 16.78631072, 15.4413865 , 15.87271642, 13.20650787,\n",
       "        8.70022523, 12.67366047, 11.4183288 , 14.9976053 , 11.13599497,\n",
       "       11.52755345,  8.5529462 , 12.81899181, 11.81419499, 12.16233312,\n",
       "        8.05048204, 15.33170575, 11.58460083,  8.55187709,  8.04560081,\n",
       "        9.15906596, 15.32873137, 11.09597575, 15.96440385,  9.36891352,\n",
       "       12.93262789, 10.84544925, 11.77936413,  8.74500215,  9.11974154,\n",
       "       12.57059285, 12.42260787,  8.82012413, 15.55156709,  9.07525097,\n",
       "        8.63889945, 14.75137666,  9.14063331, 10.87331338, 12.9699804 ,\n",
       "        9.21023034,  8.68494964, 12.31674386,  8.58958887, 12.27245111,\n",
       "        8.77208195, 16.28783796,  8.61012606, 14.6861854 , 12.64565042,\n",
       "       14.31244384, 13.82042262, 15.32978386, 12.30626115,  8.16724436,\n",
       "       12.17641795, 13.05289466, 12.44520155, 10.99688344, 12.40456004,\n",
       "        9.12399789, 15.52618576,  9.01852006,  9.06804219,  8.56297859,\n",
       "        8.79822264, 14.93131614, 12.07153002, 14.2371385 ,  9.21920144,\n",
       "       12.01328924, 13.02803669, 14.94396422, 14.36799317, 12.53680686,\n",
       "       15.55355408, 15.62020734, 11.25326614, 14.87049414,  9.02275181,\n",
       "       11.44756547,  9.03580153,  8.76245303, 15.44102457, 11.95324753,\n",
       "        8.22421166,  8.39010225, 15.86814121,  9.04815459, 14.45331915,\n",
       "        8.80090235, 14.72665075, 11.74080257, 11.5374267 , 14.15371028,\n",
       "       11.91106446, 12.40350672,  8.5491043 ,  8.21631232, 11.40709009,\n",
       "       10.94249204,  8.16800401,  9.25061617,  8.62094656,  9.36993444,\n",
       "       12.14875993,  8.67423366, 13.02138638, 12.33226532, 16.52424546,\n",
       "       12.31404327, 15.89962798, 15.33293562, 12.2847212 , 16.68448936,\n",
       "        9.28923419, 15.04623631, 13.1465683 ,  8.84179786, 11.55702768,\n",
       "       15.80622151, 11.20137648,  8.6864736 ,  8.8320998 , 14.81541656,\n",
       "       12.67936995, 16.59752678,  7.95025692, 15.11811409, 13.85061818,\n",
       "       12.21926568,  8.27398033, 16.03194083, 15.97141362, 11.99104296,\n",
       "       11.39428478, 11.7755808 , 12.14771739, 12.44612034, 11.60257254,\n",
       "       15.3079988 ,  9.05374962, 12.31097367, 14.00694103,  8.5710332 ,\n",
       "        8.56332699, 15.8443658 , 15.63490127, 11.85548513,  8.81507025,\n",
       "       14.09408554, 15.21611334, 15.41854951, 11.64017405,  8.65975835,\n",
       "       12.50884054,  8.54118799, 14.14869452, 10.8271904 ,  9.25415584,\n",
       "       16.09364693, 10.31162318,  8.88188214, 16.02897909, 10.31474869,\n",
       "       12.84429698, 12.08975196, 12.33951279, 15.32950486,  8.68919083,\n",
       "       14.20200419, 11.81110905, 11.42330814,  8.88253845,  8.04330293,\n",
       "        8.47434517, 12.46678487, 11.0658471 , 15.75968321,  8.44195758,\n",
       "       12.47016025, 12.40582732, 16.12994089, 15.56918645, 14.0820919 ,\n",
       "       14.20632857, 16.52015213,  9.16669178,  8.89760772, 13.97195078,\n",
       "       15.99987912, 10.41845878, 14.7204974 , 15.25816654, 16.40708134,\n",
       "        8.48887202, 15.26456872,  8.70465627, 11.59711747, 16.30121647,\n",
       "       15.90457021, 12.56506544, 11.886063  ,  8.60220914,  8.79783368,\n",
       "       12.35777538, 12.28758356, 12.68455233, 10.65336922, 12.74799376,\n",
       "       13.90097759, 12.30397277, 12.45827093, 14.60830409, 15.51488919,\n",
       "        8.4057284 ,  8.98971064, 11.18707131,  8.08928616, 16.45496525,\n",
       "       14.96363684,  9.78653625,  8.86735368, 10.33125266, 11.68579994,\n",
       "        8.58619532, 15.8967992 , 12.48873544, 15.40471921,  9.26592691,\n",
       "       16.61003672, 11.85877411,  8.74509309, 11.81239345, 15.28409018,\n",
       "       16.32446224, 14.47576512,  7.7709899 ,  8.35137048, 14.05741502,\n",
       "        9.23504339, 12.4579996 , 15.78414898, 12.05972424, 16.33819519,\n",
       "        8.44751295, 14.41261526, 14.1013425 , 15.26079488, 12.81440981,\n",
       "       12.1871229 , 12.39293456,  9.28942874, 11.15494183, 12.08586595,\n",
       "       15.22711473, 13.46305888, 15.08745913, 12.35067835,  8.47955491,\n",
       "        8.51958678, 15.46545611, 12.87990534,  9.14020879,  9.11238125])"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_func = FunctionTransformer(np.log)\n",
    "c2_transformer = Pipeline(steps=[\n",
    "    ('log', log_func)\n",
    "])\n",
    "\n",
    "group_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())     # output from Ordinal becomes input to OneHot\n",
    "])\n",
    "\n",
    "# preprocessing pipeline (put them together)\n",
    "preproc = ColumnTransformer(transformers=[\n",
    "    ('log', c2_transformer, ['c2']),\n",
    "    ('onehot', group_transformer, ['group'])],\n",
    "    remainder='passthrough')\n",
    "\n",
    "mul_pl = Pipeline(steps=[('preprocessor', preproc), ('regressor', LinearRegression())])\n",
    "mul_pl.fit(data.drop('y', axis=1), data['y'])\n",
    "# predic_2 = mul_pl.predict(data.drop('y', axis=1))\n",
    "predic_2 = mul_pl.predict(data.drop('y', axis=1))\n",
    "predic_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_type_pipeline(data):\n",
    "    '''\n",
    "    multi_type_pipeline that takes in a dataframe like data and \n",
    "    returns a tuple consisting of the pipeline and the predictions \n",
    "    your model makes on data (as trained on data).\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'toy.csv')\n",
    "    >>> data = pd.read_csv(fp)\n",
    "    >>> pl, preds = multi_type_pipeline(data)\n",
    "    >>> isinstance(pl, Pipeline)\n",
    "    True\n",
    "    >>> isinstance(pl.steps[-1][1], LinearRegression)\n",
    "    True\n",
    "    >>> isinstance(pl.steps[0][1], ColumnTransformer)\n",
    "    True\n",
    "    >>> data.shape[0] == preds.shape[0]\n",
    "    True\n",
    "    '''\n",
    "    log_func = FunctionTransformer(np.log)\n",
    "    c2_transformer = Pipeline(steps=[\n",
    "        ('log', log_func)\n",
    "    ])\n",
    "\n",
    "    group_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder())     # output from Ordinal becomes input to OneHot\n",
    "    ])\n",
    "\n",
    "    # preprocessing pipeline (put them together)\n",
    "    preproc = ColumnTransformer(transformers=[\n",
    "        ('log', c2_transformer, ['c2']),\n",
    "        ('onehot', group_transformer, ['group'])],\n",
    "        remainder='passthrough')\n",
    "\n",
    "    mul_pl = Pipeline(steps=[('preprocessor', preproc), ('regressor', LinearRegression())])\n",
    "    mul_pl.fit(data.drop('y', axis=1), data['y'])\n",
    "    # predic_2 = mul_pl.predict(data.drop('y', axis=1))\n",
    "    predic_2 = mul_pl.predict(data.drop('y', axis=1))\n",
    "    return (mul_pl, predic_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.436382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.725205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.121212</td>\n",
       "      <td>2.155940</td>\n",
       "      <td>17.852916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.215070</td>\n",
       "      <td>1.973772</td>\n",
       "      <td>13.864179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.002297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.826493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.932084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.611313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2        c1        c2          y\n",
       "995  0.0  0.0  1.0  0.436382  1.000000   7.725205\n",
       "996  1.0  0.0  0.0  3.121212  2.155940  17.852916\n",
       "997  0.0  1.0  0.0  2.215070  1.973772  13.864179\n",
       "998  0.0  0.0  1.0  2.002297  1.000000   7.826493\n",
       "999  0.0  0.0  1.0  1.932084  1.000000   6.611313"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = data['c1']\n",
    "c2 = data['c2'].apply(np.log)\n",
    "group_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())     # output from Ordinal becomes input to OneHot\n",
    "])\n",
    "test = pd.DataFrame(data=group_transformer.fit_transform(data[['group']]).toarray())\n",
    "test = test.assign(c1=c1, c2=c2, y=data['y'])\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())     # output from Ordinal becomes input to OneHot\n",
    "])\n",
    "group_transformer.named_steps['onehot'].fit_transform(data[['group']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.18531033, 14.74441827, 15.42116947, 12.83429335, 13.03799741,\n",
       "       12.25310004, 12.43767512,  8.74186776, 14.83866743,  8.43157896,\n",
       "       14.45273363, 11.75741912, 14.93030885, 13.26345315, 15.44172887,\n",
       "       15.73687497, 11.62811781, 13.94580247, 13.31105138, 10.78091375,\n",
       "       11.7671027 ,  9.8941669 , 11.89697715, 14.75691376, 13.9173444 ,\n",
       "        8.33272857, 12.29120177, 12.75076932, 16.93692483,  9.38692656,\n",
       "       16.41488837, 14.48484395, 13.97972499, 15.37545555, 11.73064088,\n",
       "        8.51307035,  8.33440007, 15.31917206, 16.2222295 , 11.05978077,\n",
       "        8.30549967, 15.82504116,  8.53576633, 14.97654842, 11.90167448,\n",
       "       11.84565315, 10.64367785, 11.94487026, 11.77943364, 12.28160821,\n",
       "        8.2717144 ,  9.39694084,  9.37574575,  8.18938447, 16.03260617,\n",
       "       10.26170311, 16.00340929,  9.13893949,  8.68829782,  9.31903673,\n",
       "        8.22310871, 12.32226532,  8.88997857,  8.21400817, 12.83686165,\n",
       "       16.40954262, 11.23785325, 15.27415617, 16.43653785, 10.93296329,\n",
       "       15.12431287,  9.49143228, 11.08209631,  8.24193682,  9.31353805,\n",
       "       12.15382791, 12.59110382, 12.32111891, 11.7893595 , 12.15558619,\n",
       "       11.73738008, 11.10105561, 15.54540115, 12.31248341, 15.33758984,\n",
       "       12.46931485, 12.66027011, 11.54521595, 14.0015667 ,  9.10892195,\n",
       "       11.5041973 , 12.56002948,  9.29213751,  8.94283595,  8.36278755,\n",
       "       16.46262939, 12.66078586,  8.29185556,  9.2124712 , 14.3715037 ,\n",
       "       12.76514656, 16.39220462,  8.66682226, 11.51237784, 11.44538124,\n",
       "        8.88367454,  8.94014148, 15.61944071, 16.30317639, 13.28898107,\n",
       "       14.51456068, 11.63732701,  8.49012059, 12.67347879, 14.75417662,\n",
       "       12.85495414, 16.08869089,  7.86122092,  8.10558003, 15.62873131,\n",
       "       15.30609172, 15.70696258,  8.95018795, 11.98051444,  9.19657028,\n",
       "        8.60302749, 15.04155903, 13.71727441, 14.79361518, 13.37013282,\n",
       "       16.16493007, 15.27767919, 12.18392834,  8.5075196 , 15.14552681,\n",
       "       11.40289292, 15.58618929, 11.73769378,  8.60329136,  8.53472945,\n",
       "       16.11181644, 11.29230541,  8.75375335, 11.26208747,  8.53005654,\n",
       "        8.75492311, 15.57181131, 14.57087334,  8.37667743, 14.80589441,\n",
       "        8.89632078, 15.51086594,  8.67148358, 12.81743766, 14.800459  ,\n",
       "       11.65747044,  8.99466866, 12.39506247, 12.60905501,  8.96220362,\n",
       "        8.41617312, 11.58083447,  8.73685686, 15.43515837, 12.06115976,\n",
       "       12.44626129, 10.80153858,  8.89529039, 11.84431585,  8.89501844,\n",
       "        7.86743289, 11.77965879, 15.97390235, 14.1598465 , 16.29431876,\n",
       "       12.18159324, 11.12203048, 14.00032442, 11.69887821, 10.46015853,\n",
       "       13.93416517, 14.07646803, 15.05914819, 14.67019898,  9.35294611,\n",
       "       16.35826335, 15.60830669,  8.56156273,  8.90720223, 13.443261  ,\n",
       "       13.0273128 ,  8.90597237, 14.46434301, 11.57489532, 11.87527462,\n",
       "       12.03499763, 11.41051618, 14.07076799, 16.58767413, 17.1047704 ,\n",
       "       11.90323652, 14.00815427, 12.37847795, 15.88835619, 15.76678045,\n",
       "        8.79533732,  8.4047718 ,  7.64216447, 13.41567876, 16.85547664,\n",
       "       16.3077274 , 14.59708095, 12.00664589, 11.76585786, 12.05042972,\n",
       "       14.39520424, 15.69961359, 15.4034621 ,  8.51699688, 11.88243869,\n",
       "        8.23559067,  8.86646142, 13.04767599, 11.43459629,  8.46824686,\n",
       "       11.78731647, 12.56749263, 12.59293169, 12.61200289, 12.95997383,\n",
       "       10.76070021,  9.60087135,  9.15311812, 12.33728853, 11.27599988,\n",
       "       14.87129505, 16.57654423, 11.91437552, 16.22088206,  8.38866562,\n",
       "       12.59000437, 12.2826393 , 15.30380188, 15.42792525,  8.74401617,\n",
       "       11.5735807 ,  9.099614  , 15.35200453,  9.51605567,  7.79643788,\n",
       "       14.22293348, 11.22572638,  9.05996936, 12.3555144 ,  9.50141587,\n",
       "        8.19106534, 12.62877034, 10.30308635,  8.81171221,  9.67996417,\n",
       "        9.00807833,  8.71177249, 11.35091577, 14.08882437,  8.73604303,\n",
       "       12.70971279,  8.36951799,  8.75123334,  8.26847113, 10.95579146,\n",
       "        8.78693972, 12.03389324, 12.67301526, 15.09445681, 13.17980653,\n",
       "        8.63301654, 17.09516377, 16.01009363,  8.12041034, 12.17391419,\n",
       "       13.870609  , 11.73966434, 11.8338333 ,  8.59254327, 15.28915797,\n",
       "        8.69911259, 16.82870018,  8.48466188,  9.19064217, 11.80579673,\n",
       "       16.58588129, 13.61786867, 14.33512515,  8.51689106, 14.50698687,\n",
       "        8.14691267, 12.15341099,  9.26451048, 16.08899298, 13.78982825,\n",
       "       11.50474808,  8.65790533, 14.54628593, 11.59164041, 11.79738539,\n",
       "        8.46218536,  9.06376676, 14.37383461,  9.1843798 ,  8.53247932,\n",
       "       15.93128806, 13.98419665, 11.67922264,  8.31801942, 16.18406532,\n",
       "        8.87567094, 11.93892075,  8.37356438, 14.364156  , 14.67588705,\n",
       "       15.74980059, 11.5271299 , 14.59978997,  8.45582871,  9.69351613,\n",
       "       13.38574251, 14.9652951 , 12.47542493,  9.04869004, 16.27521922,\n",
       "        9.30546826, 16.79850469, 12.8482356 , 15.45334449,  8.28027448,\n",
       "       11.72345639, 11.76968366, 12.18633826, 12.48539295, 11.57237387,\n",
       "       16.3032669 , 12.58019114, 11.80180368,  9.18010378, 11.40320037,\n",
       "       16.65980554, 11.25713629, 14.79894391, 10.55361665, 11.73997974,\n",
       "       14.77916196, 14.12809114, 13.44926468,  8.2899103 , 15.364999  ,\n",
       "        8.32367777, 15.01524531, 10.51200827, 16.23838227, 11.67800935,\n",
       "       12.98969784, 15.91394299,  8.38967435,  8.3999171 , 10.58129712,\n",
       "       12.06575059, 15.62228414, 12.44884235,  8.8045582 ,  9.0032508 ,\n",
       "       15.26677333, 15.66469059, 14.60004918, 12.41008707,  9.12532031,\n",
       "        7.91465548, 11.74328074, 11.50200828,  8.75524516,  9.21912099,\n",
       "       15.86161222,  7.99292554, 13.58010878, 11.63270394, 15.30557207,\n",
       "       15.12401433,  9.31752349, 14.82532103, 15.76078396,  8.83962032,\n",
       "       14.96911278, 16.59166094, 14.46917165, 12.25216689, 14.55274569,\n",
       "       15.09036929,  8.09242662, 11.83944765, 12.63301826,  8.89683956,\n",
       "        8.65394766, 15.08880571, 10.44423279, 16.22569617, 16.2613389 ,\n",
       "       15.59390127, 13.05504998, 16.04153292, 15.68004612, 12.21463133,\n",
       "       15.84518399,  8.43698594, 12.43627458, 12.93820962, 11.30303866,\n",
       "       14.51861293, 14.97317714, 12.92542387,  9.08469663,  8.93204905,\n",
       "        8.65419876, 16.88909323, 12.09455801, 11.83171288, 13.55456145,\n",
       "       11.57351561,  9.28708604,  8.84739622, 13.0151064 , 14.87822967,\n",
       "       14.27313279, 11.96157639, 12.63965437, 16.63115969, 12.94096166,\n",
       "        8.94632481, 11.94567556,  8.57517433, 15.94864332, 11.08734888,\n",
       "       13.55994403,  8.26940896, 10.23262703,  8.31148782, 12.44636458,\n",
       "       15.08786395, 11.7303241 ,  8.1467382 , 14.61886669, 11.38220983,\n",
       "        8.47668195, 16.22942701, 12.21586604,  8.99493803, 16.0959814 ,\n",
       "       15.91292331, 13.14973747,  8.71020978,  8.17766722, 12.01470988,\n",
       "       12.39656778,  8.72461126,  8.7729374 , 11.59445413, 14.3401658 ,\n",
       "        8.67324916, 11.32910819,  8.66557076,  8.55881672,  8.30778484,\n",
       "        9.23394874,  8.65580244, 16.08934691, 11.64747452,  8.18101053,\n",
       "       12.28603286,  8.75121651, 15.06749275,  9.35893052,  8.20562329,\n",
       "        8.38798554, 12.0797865 , 16.38169511,  9.02352622,  9.238541  ,\n",
       "       13.6287461 , 15.3680564 ,  9.11702031, 11.29499833, 11.41982047,\n",
       "       12.69382659,  8.86460845,  8.18415951, 12.52504123,  9.0588716 ,\n",
       "       11.49489523, 16.43541322, 16.77287569, 14.5302961 ,  8.22059408,\n",
       "       11.87148898, 12.72618844, 13.50900517, 11.95022041, 13.92095639,\n",
       "       12.11146646, 12.1819225 , 12.03064631, 15.81743361,  9.13875989,\n",
       "        9.05238009, 12.76200526,  8.90041135, 12.48618168, 12.34937631,\n",
       "       11.94396512,  8.65937425,  8.46649209, 16.07096273,  9.02154479,\n",
       "       15.80024836,  8.69068817, 13.62698958,  8.0972348 ,  9.10847772,\n",
       "       11.48431088,  8.84996296,  9.25949345, 12.02899471, 15.92255796,\n",
       "        9.03400937, 11.74539846, 14.23403679, 12.54357267, 14.72486212,\n",
       "        8.15668819, 13.53972869,  8.85758092, 11.44889081, 13.06625406,\n",
       "       11.7535339 , 16.42902428,  9.10423061, 11.64748364, 12.02852476,\n",
       "       15.09256794,  8.79816779, 12.09323148, 11.5015536 , 10.18120767,\n",
       "        8.69470115, 14.1368787 , 15.47523139, 11.34445627, 12.25769413,\n",
       "       11.18856659, 12.51719873, 12.17717453, 13.6806179 ,  9.12139169,\n",
       "       12.15526117, 12.35123229, 15.57441369, 12.44322768,  8.27645216,\n",
       "        8.82796421, 12.52868916, 12.21543373, 12.44176797, 14.40755477,\n",
       "       12.22539791, 15.6069669 ,  8.23097888,  8.0737384 , 14.47650208,\n",
       "       10.31522923, 14.6438708 ,  8.2645855 ,  9.2288236 , 13.74832791,\n",
       "       12.65837488, 15.61327055,  8.34220347, 12.89287407,  8.52481252,\n",
       "       14.38208984, 16.45959717,  8.717192  , 12.7997059 ,  9.80093277,\n",
       "        9.29899772, 15.447747  , 14.26025861,  8.55842699, 12.37676499,\n",
       "       15.19853443, 11.04528893, 12.13010158, 15.87020597, 11.89012204,\n",
       "        8.95142589,  9.37909409, 15.30542644,  8.94237972, 11.62900843,\n",
       "       12.52353074,  8.41057342, 12.21108781,  8.49095656,  8.70277405,\n",
       "       12.65943325,  9.01431759,  8.57077016,  8.62078917, 12.20499122,\n",
       "       12.26974858, 14.70030969,  9.30791958, 11.93637538,  7.97912105,\n",
       "        9.13255756, 13.62623274, 13.49212814, 13.20145549, 16.68077793,\n",
       "       13.51571018,  8.29298368,  8.53272733,  8.89110921, 11.59747124,\n",
       "        8.63603277, 14.39753836, 14.18008496,  9.41749823, 11.85665558,\n",
       "        9.79437557,  8.99342303,  9.04736122, 11.87781358, 13.36349767,\n",
       "        9.11592663, 12.20437956,  8.06209264, 13.92288291,  8.67020648,\n",
       "       16.64634665,  9.60765114, 12.1090639 , 14.26148852, 15.67463251,\n",
       "       10.95614944,  8.98143343, 12.05353081, 15.80429605,  8.71994549,\n",
       "        8.23588337, 11.69541329, 12.62438647, 16.16853108, 15.5116485 ,\n",
       "        8.80676928, 12.79100452, 12.90555413, 12.58923348, 14.12215341,\n",
       "       15.96857859, 10.91635515,  9.29449489, 11.25386236, 12.82172692,\n",
       "       15.79006237, 16.36700664,  8.99750332, 10.33051291, 17.23275483,\n",
       "       14.4686284 , 16.626169  , 12.86290695,  8.48237032,  8.52780735,\n",
       "       13.69186209, 14.81868484, 11.82396863,  8.9958492 ,  8.08327082,\n",
       "       15.20835326, 15.77008438, 12.47156425, 14.81872025, 11.85553393,\n",
       "       11.09984473,  9.39078067, 15.34133371,  8.50745247,  8.76734743,\n",
       "       16.02209123,  8.42233806, 12.46646655, 11.67266278, 11.57194557,\n",
       "        9.66726341,  8.01446895, 12.3703077 ,  9.11582296,  8.41312886,\n",
       "       14.23950316, 15.43457051, 11.86683203, 15.30575792,  9.04088918,\n",
       "       15.58812642,  9.11136933,  8.12221277,  8.72101538,  9.25193819,\n",
       "       14.03593335,  9.34685502, 14.64846309,  9.03221978, 13.38603821,\n",
       "        9.52444292, 14.38992864, 14.6235555 ,  8.97341933,  9.45090224,\n",
       "        8.66952976, 11.78832709,  9.52583584, 11.15900554,  9.70242408,\n",
       "       11.14921781,  8.35191969, 12.10503925, 15.36112788,  8.92860541,\n",
       "       14.8356975 , 16.78631072, 15.4413865 , 15.87271642, 13.20650787,\n",
       "        8.70022523, 12.67366047, 11.4183288 , 14.9976053 , 11.13599497,\n",
       "       11.52755345,  8.5529462 , 12.81899181, 11.81419499, 12.16233312,\n",
       "        8.05048204, 15.33170575, 11.58460083,  8.55187709,  8.04560081,\n",
       "        9.15906596, 15.32873137, 11.09597575, 15.96440385,  9.36891352,\n",
       "       12.93262789, 10.84544925, 11.77936413,  8.74500215,  9.11974154,\n",
       "       12.57059285, 12.42260787,  8.82012413, 15.55156709,  9.07525097,\n",
       "        8.63889945, 14.75137666,  9.14063331, 10.87331338, 12.9699804 ,\n",
       "        9.21023034,  8.68494964, 12.31674386,  8.58958887, 12.27245111,\n",
       "        8.77208195, 16.28783796,  8.61012606, 14.6861854 , 12.64565042,\n",
       "       14.31244384, 13.82042262, 15.32978386, 12.30626115,  8.16724436,\n",
       "       12.17641795, 13.05289466, 12.44520155, 10.99688344, 12.40456004,\n",
       "        9.12399789, 15.52618576,  9.01852006,  9.06804219,  8.56297859,\n",
       "        8.79822264, 14.93131614, 12.07153002, 14.2371385 ,  9.21920144,\n",
       "       12.01328924, 13.02803669, 14.94396422, 14.36799317, 12.53680686,\n",
       "       15.55355408, 15.62020734, 11.25326614, 14.87049414,  9.02275181,\n",
       "       11.44756547,  9.03580153,  8.76245303, 15.44102457, 11.95324753,\n",
       "        8.22421166,  8.39010225, 15.86814121,  9.04815459, 14.45331915,\n",
       "        8.80090235, 14.72665075, 11.74080257, 11.5374267 , 14.15371028,\n",
       "       11.91106446, 12.40350672,  8.5491043 ,  8.21631232, 11.40709009,\n",
       "       10.94249204,  8.16800401,  9.25061617,  8.62094656,  9.36993444,\n",
       "       12.14875993,  8.67423366, 13.02138638, 12.33226532, 16.52424546,\n",
       "       12.31404327, 15.89962798, 15.33293562, 12.2847212 , 16.68448936,\n",
       "        9.28923419, 15.04623631, 13.1465683 ,  8.84179786, 11.55702768,\n",
       "       15.80622151, 11.20137648,  8.6864736 ,  8.8320998 , 14.81541656,\n",
       "       12.67936995, 16.59752678,  7.95025692, 15.11811409, 13.85061818,\n",
       "       12.21926568,  8.27398033, 16.03194083, 15.97141362, 11.99104296,\n",
       "       11.39428478, 11.7755808 , 12.14771739, 12.44612034, 11.60257254,\n",
       "       15.3079988 ,  9.05374962, 12.31097367, 14.00694103,  8.5710332 ,\n",
       "        8.56332699, 15.8443658 , 15.63490127, 11.85548513,  8.81507025,\n",
       "       14.09408554, 15.21611334, 15.41854951, 11.64017405,  8.65975835,\n",
       "       12.50884054,  8.54118799, 14.14869452, 10.8271904 ,  9.25415584,\n",
       "       16.09364693, 10.31162318,  8.88188214, 16.02897909, 10.31474869,\n",
       "       12.84429698, 12.08975196, 12.33951279, 15.32950486,  8.68919083,\n",
       "       14.20200419, 11.81110905, 11.42330814,  8.88253845,  8.04330293,\n",
       "        8.47434517, 12.46678487, 11.0658471 , 15.75968321,  8.44195758,\n",
       "       12.47016025, 12.40582732, 16.12994089, 15.56918645, 14.0820919 ,\n",
       "       14.20632857, 16.52015213,  9.16669178,  8.89760772, 13.97195078,\n",
       "       15.99987912, 10.41845878, 14.7204974 , 15.25816654, 16.40708134,\n",
       "        8.48887202, 15.26456872,  8.70465627, 11.59711747, 16.30121647,\n",
       "       15.90457021, 12.56506544, 11.886063  ,  8.60220914,  8.79783368,\n",
       "       12.35777538, 12.28758356, 12.68455233, 10.65336922, 12.74799376,\n",
       "       13.90097759, 12.30397277, 12.45827093, 14.60830409, 15.51488919,\n",
       "        8.4057284 ,  8.98971064, 11.18707131,  8.08928616, 16.45496525,\n",
       "       14.96363684,  9.78653625,  8.86735368, 10.33125266, 11.68579994,\n",
       "        8.58619532, 15.8967992 , 12.48873544, 15.40471921,  9.26592691,\n",
       "       16.61003672, 11.85877411,  8.74509309, 11.81239345, 15.28409018,\n",
       "       16.32446224, 14.47576512,  7.7709899 ,  8.35137048, 14.05741502,\n",
       "        9.23504339, 12.4579996 , 15.78414898, 12.05972424, 16.33819519,\n",
       "        8.44751295, 14.41261526, 14.1013425 , 15.26079488, 12.81440981,\n",
       "       12.1871229 , 12.39293456,  9.28942874, 11.15494183, 12.08586595,\n",
       "       15.22711473, 13.46305888, 15.08745913, 12.35067835,  8.47955491,\n",
       "        8.51958678, 15.46545611, 12.87990534,  9.14020879,  9.11238125])"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression() # initial linear regression\n",
    "\n",
    "lr.fit(test.drop('y', axis=1), test['y']) # calculate the weights\n",
    "\n",
    "predictions = lr.predict(test.drop('y', axis=1)) # calculate predictions\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Notice that `c1` and `c2` have strong associations with the values of `group` (e.g. try `sns.scatterplot` of `c1` and `y`, with `hue='group'`). This suggests that group-wise scaling might make good features. \n",
    "\n",
    "In this question, you will `z-scale` both `c1` and `c2` *within* each group `A,B,C`. However, `sklearn` doesn't include this transformer, so it will be necessary to *create your own*. In the starter code, is a skeleton for creating your own `sklearn` transformer class; you will need to create your own `transformer` and `fit` methods.\n",
    "\n",
    "* You will create `StdScalerByGroup` that fits/transforms input data `X` whose first column contains the groups; the other columns are numeric and will be z-scaled within each group.\n",
    "* The `fit` method should determine the mean and sample standard-deviation of each group value in the input data `X` and save them in the instance variable `grps_`.\n",
    "* The `transform` method takes in data `X` and z-scales the columns using the mean/std saved in `grps_`.\n",
    "\n",
    "*Note:* You may decide on whatever structure you'd like for the `grps_` variable. This question will be graded on the correctness of the output. (Check the correctness of your work by checking the output by-hand!)\n",
    "\n",
    "*Note:* A reminder that avoid using loops over long iterable subjects!\n",
    "\n",
    "*Note:* The `group` column in the doctest is named 'g' instead of 'group'. Remember, the first column will **always** contain the groups (even if the name is different)\n",
    "\n",
    "*Note:* Do not worry about cases where the std = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1992f7cec88>"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x='c1', y='y', data=data, hue='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class StdScalerByGroup(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        :Example:\n",
    "        >>> cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 2, 2], 'c2': [3, 1, 2, 0]}\n",
    "        >>> X = pd.DataFrame(cols)\n",
    "        >>> std = StdScalerByGroup().fit(X)\n",
    "        >>> std.grps_ is not None\n",
    "        True\n",
    "        \"\"\"\n",
    "        # X may not be a pandas dataframe (e.g. a np.array)\n",
    "        X = pd.DataFrame(data=X)\n",
    "        \n",
    "        # A dictionary of means/standard-deviations for each column, for each group.\n",
    "        X = X.rename(columns={X.columns[0]:'col1'}) # Rename col name to be consistent\n",
    "        grouped = X.groupby('col1').aggregate(['mean', 'std']) # Grouped to get mean & std\n",
    "        dic = {}\n",
    "        for key in grouped.columns:\n",
    "            dic.update({key:dict(grouped[key])})\n",
    "        \n",
    "        self.grps_ = dic\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        :Example:\n",
    "        >>> cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}\n",
    "        >>> X = pd.DataFrame(cols)\n",
    "        >>> std = StdScalerByGroup().fit(X)\n",
    "        >>> out = std.transform(X)\n",
    "        >>> out.shape == (4, 2)\n",
    "        True\n",
    "        >>> np.isclose(out.abs(), 0.707107, atol=0.001).all().all()\n",
    "        True\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            getattr(self, \"grps_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must fit the transformer before tranforming the data!\")\n",
    "        \n",
    "        # Define a helper function here?\n",
    "        # Helper function to calculate z score\n",
    "        def z_score(group, col, score):\n",
    "            # print(group, col, score)\n",
    "            mean = self.grps_.get((col, 'mean')).get(group)\n",
    "            std = self.grps_.get((col, 'std')).get(group)\n",
    "            z = (score - mean) / std # Standardize\n",
    "            # print(mean, std, z)\n",
    "            return z\n",
    "        \n",
    "        # X may not be a dataframe (e.g. np.array)\n",
    "        X = pd.DataFrame(X)\n",
    "        X = X.rename(columns={X.columns[0]:'col1'})\n",
    "        for col in X.drop('col1', axis=1).columns:\n",
    "            X.loc[:,col] = X.drop('col1', axis=1).apply(lambda x: z_score(X.loc[x.name, 'col1'], col, x[col]), axis=1)\n",
    "        return X.drop('col1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('c1', 'mean'): {'A': 1.5, 'B': 3.5},\n",
       " ('c1', 'std'): {'A': 0.7071067811865476, 'B': 0.7071067811865476},\n",
       " ('c2', 'mean'): {'A': 1.5, 'B': 3.5},\n",
       " ('c2', 'std'): {'A': 0.7071067811865476, 'B': 0.7071067811865476}}"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}\n",
    "X = pd.DataFrame(cols)\n",
    "X = X.rename(columns={X.columns[0]:'col1'})\n",
    "grouped = X.groupby('col1').aggregate(['mean', 'std'])\n",
    "dic = {}\n",
    "for key in grouped.columns:\n",
    "    dic.update({key:dict(grouped[key])})\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c1        c2\n",
       "0 -0.707107 -0.707107\n",
       "1  0.707107  0.707107\n",
       "2 -0.707107 -0.707107\n",
       "3  0.707107  0.707107"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}\n",
    "X = pd.DataFrame(cols)\n",
    "X = X.rename(columns={X.columns[0]:'col1'})\n",
    "def z_score(group, col, score):\n",
    "    mean = dic.get((col, 'mean')).get(group)\n",
    "    std = dic.get((col, 'std')).get(group)\n",
    "    z = (score - mean) / std # Standardize\n",
    "    # print(group, col, score, mean, std, z)\n",
    "    return z\n",
    "# mean = X.groupby('col1').transform('mean') # aggregate([np.mean, np.std]).\n",
    "# std = X.groupby('col1').transform(np.std)\n",
    "for col in X.columns[~X.columns.isin(['col1'])]:\n",
    "    # X.loc[: col] = pd.Series(X.drop('col1', axis=1).apply(lambda x: z_score(X.loc[x.name, 'col1'], col, x.values), axis=1))\n",
    "    X.loc[:,col] = X.drop('col1', axis=1).apply(lambda x: z_score(X.loc[x.name, 'col1'], col, x[col]), axis=1)\n",
    "# X.loc[0].index\n",
    "X.drop('col1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c1        c2\n",
       "0 -0.707107 -0.707107\n",
       "1  0.707107  0.707107\n",
       "2 -0.707107 -0.707107\n",
       "3  0.707107  0.707107"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}\n",
    "X = pd.DataFrame(cols)\n",
    "# X = [['A', 1, 1], ['A', 2, 2], ['B', 3, 3], ['B', 4, 4]]\n",
    "# display(X)\n",
    "std = StdScalerByGroup().fit(X)\n",
    "out = std.transform(X)\n",
    "out\n",
    "# out.shape == (4, 2)\n",
    "# np.isclose(out.abs(), 0.707107, atol=0.001).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Pipelines are supposed to help you easily try different model configurations. Create a function `eval_toy_model` which returns a hard-coded list of tuples consisting of the (RMSE, $R^2$) of 3 different modeling pipelines (fit and evaluated on the entire input `data`). The three different models are:\n",
    "1. The pipeline in Question 1\n",
    "1. The pipeline in Question 2\n",
    "1. A pipeline consisting of a linear regression model fit on features generated by applying `StdScalerByGroup` to `c1`, log-scaling `c2`, and applying `OneHotEncoder` to `group`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This would be specfic to `data` right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>4.058118</td>\n",
       "      <td>5.329582</td>\n",
       "      <td>12.649035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>4.194945</td>\n",
       "      <td>3.839476</td>\n",
       "      <td>17.309083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2.246411</td>\n",
       "      <td>10.694666</td>\n",
       "      <td>15.695646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>2.510912</td>\n",
       "      <td>6.414960</td>\n",
       "      <td>11.535752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>3.194722</td>\n",
       "      <td>6.116839</td>\n",
       "      <td>14.954389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group        c1         c2          y\n",
       "0     B  4.058118   5.329582  12.649035\n",
       "1     A  4.194945   3.839476  17.309083\n",
       "2     A  2.246411  10.694666  15.695646\n",
       "3     B  2.510912   6.414960  11.535752\n",
       "4     B  3.194722   6.116839  14.954389"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.22293903, 14.72687659, 15.42998289, 12.84474867, 13.06053548,\n",
       "       12.24934339, 12.47768492,  8.74360323, 14.83118966,  8.44679922,\n",
       "       14.44041708, 11.74485621, 14.93010965, 13.2905168 , 15.41849859,\n",
       "       15.75001721, 11.6225798 , 13.95634168, 13.33663863, 10.74927162,\n",
       "       11.74229426,  9.88231602, 11.91721085, 14.76630781, 13.91478954,\n",
       "        8.35224475, 12.28867507, 12.75918213, 16.92719485,  9.36062854,\n",
       "       16.41576491, 14.47984443, 13.97096322, 15.36427225, 11.74020143,\n",
       "        8.52474909,  8.35384361, 15.31677869, 16.20813517, 11.0432332 ,\n",
       "        8.32619919, 15.82489663,  8.54645873, 14.99372969, 11.91209642,\n",
       "       11.84374724, 10.62476113, 11.96405183, 11.78852955, 12.27136241,\n",
       "        8.29388219,  9.37020761,  9.34993363,  8.21513022, 16.01928167,\n",
       "       10.23545643, 15.97745849,  9.12341869,  8.69236139,  9.29568912,\n",
       "        8.24738884, 12.34554289,  8.88527732,  8.2386838 , 12.84078468,\n",
       "       16.41512512, 11.22407419, 15.28707874, 16.4251041 , 10.91071438,\n",
       "       15.137856  ,  9.46059256, 11.06633672,  8.26539871,  9.29042941,\n",
       "       12.15274439, 12.59479361, 12.34868935, 11.8036098 , 12.1486667 ,\n",
       "       11.72253989, 11.08636363, 15.53341116, 12.31547411, 15.36133256,\n",
       "       12.48397236, 12.65993375, 11.54211202, 13.99801332,  9.09470568,\n",
       "       11.47942367, 12.58149823,  9.26995891,  8.93583758,  8.38099741,\n",
       "       16.43828293, 12.67149774,  8.31314804,  9.19375481, 14.379271  ,\n",
       "       12.78050962, 16.39235172,  8.67181912, 11.49890913, 11.41831107,\n",
       "        8.87924726,  8.93326022, 15.6236051 , 16.29727734, 13.30391972,\n",
       "       14.50930601, 11.63610329,  8.5027967 , 12.67652526, 14.75542801,\n",
       "       12.88053311, 16.07498388,  7.90122827,  8.13496782, 15.60970111,\n",
       "       15.29729309, 15.69594928,  8.94287007, 11.98061035,  9.17854492,\n",
       "        8.6107968 , 15.03771333, 13.71911621, 14.7941642 , 13.42195303,\n",
       "       16.17181182, 15.30050858, 12.18751152,  8.51943957, 15.13409613,\n",
       "       11.36903575, 15.57033518, 11.7365533 ,  8.61104921,  8.54546692,\n",
       "       16.11789286, 11.25125499,  8.75497229, 11.25282267,  8.54099708,\n",
       "        8.75609121, 15.57788697, 14.62275159,  8.39428365, 14.79621821,\n",
       "        8.89134391, 15.51510795,  8.67627787, 12.82212422, 14.79912432,\n",
       "       11.64993928,  8.9854177 , 12.38884637, 12.61212317,  8.95436356,\n",
       "        8.4320629 , 11.57671141,  8.7388101 , 15.44063163, 12.06426236,\n",
       "       12.46651268, 10.77338122,  8.8903583 , 11.84111909,  8.89009817,\n",
       "        7.90717027, 11.78282867, 15.98027745, 14.16445263, 16.29062966,\n",
       "       12.19666599, 11.10431556, 14.00660747, 11.69010007, 10.41930485,\n",
       "       13.95516287, 14.0821351 , 15.06939179, 14.65410185,  9.32812484,\n",
       "       16.3565637 , 15.61486027,  8.57113405,  8.90175247, 13.49494436,\n",
       "       13.04663041,  8.90057606, 14.45672091, 11.58116605, 11.85809578,\n",
       "       12.00942921, 11.40635498, 14.09312132, 16.57905945, 17.08712984,\n",
       "       11.89490435, 14.01883237, 12.39127644, 15.89012605, 15.76490016,\n",
       "        8.79474907,  8.42115707,  7.69169175, 13.45966743, 16.83987352,\n",
       "       16.31353894, 14.58743536, 12.02193533, 11.7229149 , 12.0376198 ,\n",
       "       14.40452666, 15.70796433, 15.41128347,  8.52850498, 11.87784119,\n",
       "        8.25932835,  8.8627822 , 13.06722211, 11.43489929,  8.48187358,\n",
       "       11.80287058, 12.55783762, 12.61054974, 12.60814444, 12.98226533,\n",
       "       10.73070687,  9.58547289,  9.13698114, 12.32575008, 11.25249418,\n",
       "       14.85021809, 16.57086399, 11.91700221, 16.22428303,  8.40575084,\n",
       "       12.61236026, 12.27686867, 15.31799428, 15.40605958,  8.74565828,\n",
       "       11.57330688,  9.08580225, 15.35300129,  9.48414585,  7.83926062,\n",
       "       14.20925022, 11.2156253 ,  9.04788051, 12.34948706,  9.47014228,\n",
       "        8.21673804, 12.66142963, 10.28177912,  8.81041232,  9.66499599,\n",
       "        8.99824461,  8.71481587, 11.33238368, 14.08027486,  8.73803164,\n",
       "       12.71822258,  8.38743535,  8.7525618 ,  8.29077986, 10.92591767,\n",
       "        8.78671642, 12.05247106, 12.67815694, 15.09802866, 13.19521652,\n",
       "        8.63948256, 17.07923191, 16.02712971,  8.14915362, 12.17512365,\n",
       "       13.87354409, 11.74691746, 11.83993438,  8.60076821, 15.27877147,\n",
       "        8.70270615, 16.81239147,  8.49757522,  9.17287443, 11.79393866,\n",
       "       16.57540772, 13.63290412, 14.32952672,  8.52840375, 14.49439617,\n",
       "        8.17450419, 12.13652886,  9.24353252, 16.05808867, 13.79189764,\n",
       "       11.49812361,  8.66328971, 14.54662181, 11.58589512, 11.79597521,\n",
       "        8.4760755 ,  9.05151288, 14.39248595,  9.16688422,  8.54331457,\n",
       "       15.9431913 , 13.99232729, 11.68234889,  8.33817484, 16.17410623,\n",
       "        8.87159148, 11.93857305,  8.39130589, 14.34665903, 14.68082227,\n",
       "       15.74810233, 11.52089555, 14.60864276,  8.46999511,  9.65389408,\n",
       "       13.41534035, 14.96935392, 12.49236003,  9.03709138, 16.27055736,\n",
       "        9.28271032, 16.79335921, 12.8636178 , 15.44621074,  8.30207025,\n",
       "       11.71016345, 11.77531447, 12.17880308, 12.48933349, 11.57407257,\n",
       "       16.28948905, 12.57890841, 11.80272116,  9.16279403, 11.40005223,\n",
       "       16.65614036, 11.24225914, 14.7841336 , 10.51139988, 11.74936242,\n",
       "       14.78166054, 14.1400903 , 13.47980073,  8.31128731, 15.34082635,\n",
       "        8.34358729, 15.01405271, 10.46904148, 16.23798923, 11.68167274,\n",
       "       13.01591968, 15.91668579,  8.40671573,  8.41651335, 10.54323836,\n",
       "       12.0540023 , 15.63331754, 12.45130255,  8.80356923,  8.99362687,\n",
       "       15.27028879, 15.68745652, 14.58561109, 12.41627105,  9.11039139,\n",
       "        7.95234063, 11.73540881, 11.47400405,  8.75639927,  9.2001156 ,\n",
       "       15.86352065,  8.02720916, 13.58747377, 11.62732558, 15.29976304,\n",
       "       15.1397493 ,  9.29424165, 14.82941124, 15.75931852,  8.83710758,\n",
       "       14.92879558, 16.58702725, 14.45343165, 12.27895446, 14.56665301,\n",
       "       15.11349362,  8.12238604, 11.80991909, 12.63303238,  8.89184015,\n",
       "        8.65950404, 15.09250036, 10.40001203, 16.21607354, 16.26115189,\n",
       "       15.58388722, 13.06895753, 16.05878052, 15.68702173, 12.20355022,\n",
       "       15.86858147,  8.45197122, 12.46068915, 12.94782635, 11.29113264,\n",
       "       14.51320954, 14.98848436, 12.9487969 ,  9.07153316,  8.92551947,\n",
       "        8.65974423, 16.87893036, 12.10960264, 11.83513378, 13.56716454,\n",
       "       11.57719147,  9.26512697,  8.84454555, 13.0298584 , 14.87543848,\n",
       "       14.31843377, 11.97097538, 12.63530723, 16.62981184, 12.95735958,\n",
       "        8.93917482, 11.93762722,  8.5841541 , 15.92589791, 11.05978134,\n",
       "       13.57684131,  8.29167694, 10.22960066,  8.3319271 , 12.46066821,\n",
       "       15.07699002, 11.71992392,  8.1743373 , 14.63183964, 11.37028985,\n",
       "        8.48994209, 16.2290756 , 12.2145163 ,  8.98567537, 16.08203365,\n",
       "       15.88204216, 13.18029862,  8.71332107,  8.20392219, 12.00962798,\n",
       "       12.4100288 ,  8.72709668,  8.77332263, 11.57157214, 14.33030743,\n",
       "        8.67796672, 11.30266533,  8.67062202,  8.56850738,  8.32838505,\n",
       "        9.21429896,  8.66127821, 16.09153457, 11.65507935,  8.2071202 ,\n",
       "       12.29497751,  8.75254569, 15.06069518,  9.33384918,  8.23066331,\n",
       "        8.40510032, 12.05574459, 16.38563954,  9.01302115,  9.21869164,\n",
       "       13.63302639, 15.36112192,  9.1024521 , 11.2819986 , 11.40430351,\n",
       "       12.68958933,  8.86100976,  8.21013233, 12.52345944,  9.04683046,\n",
       "       11.48908495, 16.42082086, 16.76370051, 14.53495785,  8.2449835 ,\n",
       "       11.85572226, 12.73065816, 13.54288272, 11.93429032, 13.92269934,\n",
       "       12.12252668, 12.19148252, 12.04210474, 15.80968269,  9.1232469 ,\n",
       "        9.04062106, 12.76237641,  8.89525671, 12.49029425, 12.34745218,\n",
       "       11.96491231,  8.6646948 ,  8.48019506, 16.07724787,  9.01112583,\n",
       "       15.79600399,  8.69464785, 13.62212673,  8.12698527,  9.09428076,\n",
       "       11.46655479,  8.84700075,  9.25456353, 12.03330047, 15.93734698,\n",
       "        9.02304871, 11.74293643, 14.22072993, 12.54994517, 14.71889764,\n",
       "        8.18385488, 13.55250343,  8.85428764, 11.43192829, 13.09574125,\n",
       "       11.76041936, 16.41892833,  9.09021822, 11.63901358, 12.0220896 ,\n",
       "       15.08427383,  8.79745653, 12.09168767, 11.48239701, 10.16150491,\n",
       "        8.69848643, 14.14562208, 15.47243481, 11.33366081, 12.23573714,\n",
       "       11.15064051, 12.5571569 , 12.20023412, 13.68838715,  9.1066335 ,\n",
       "       12.16706304, 12.33766281, 15.56073582, 12.45253463,  8.29841405,\n",
       "        8.82595803, 12.52787594, 12.20986748, 12.43501411, 14.42216776,\n",
       "       12.24000836, 15.61497263,  8.25491699,  8.10450999, 14.48650355,\n",
       "       10.3050475 , 14.62430474,  8.2870631 ,  9.20939655, 13.75250272,\n",
       "       12.67720492, 15.63211896,  8.36130789, 12.91104972,  8.53598096,\n",
       "       14.38099952, 16.45884396,  8.71999986, 12.80986623,  9.75664253,\n",
       "        9.27652099, 15.44160299, 14.26093069,  8.56813458, 12.37369122,\n",
       "       15.21991567, 11.02062729, 12.10485987, 15.86607228, 11.90785898,\n",
       "        8.94405422,  9.35313646, 15.2996958 ,  8.93540118, 11.61925014,\n",
       "       12.537736  ,  8.42670656, 12.23477546,  8.50359634,  8.70620849,\n",
       "       12.66597009,  9.00421272,  8.57994134,  8.62778657, 12.23215377,\n",
       "       12.24978206, 14.700762  ,  9.28505511, 11.91988726,  8.0140046 ,\n",
       "        9.11731411, 13.62957824, 13.52433168, 13.22202609, 16.67116516,\n",
       "       13.52927809,  8.31422713,  8.5435518 ,  8.88635883, 11.60481618,\n",
       "        8.64236771, 14.38657886, 14.17541621,  9.3898716 , 11.85845934,\n",
       "        9.7503703 ,  8.98422621,  9.03582031, 11.85853197, 13.37598215,\n",
       "        9.10140594, 12.22461289,  8.09337034, 13.91932682,  8.67505627,\n",
       "       16.64318166,  9.59129171, 12.1199823 , 14.26987908, 15.68247871,\n",
       "       10.92906084,  8.97275767, 12.02282599, 15.81263314,  8.72263368,\n",
       "        8.25960833, 11.70057831, 12.63056635, 16.17674706, 15.52927334,\n",
       "        8.80568421, 12.83179928, 12.92954915, 12.58300842, 14.10806475,\n",
       "       15.98631975, 10.88332693,  9.27221385, 11.2442513 , 12.85813584,\n",
       "       15.78932182, 16.34912311,  8.98812917, 10.31080588, 17.19456429,\n",
       "       14.49325094, 16.62071713, 12.88823697,  8.49538325,  8.53884564,\n",
       "       13.70239734, 14.80300228, 11.83310926,  8.98654694,  8.11362815,\n",
       "       15.22424753, 15.78882602, 12.46959192, 14.85078336, 11.86193848,\n",
       "       11.07630096,  9.36431516, 15.34819451,  8.51937536,  8.76797559,\n",
       "       16.0136883 ,  8.43795992, 12.47048706, 11.67913545, 11.57295413,\n",
       "        9.62878228,  8.04781632, 12.37983679,  9.10130679,  8.42915094,\n",
       "       14.25818635, 15.4638706 , 11.86387989, 15.27098242,  9.02962953,\n",
       "       15.5858649 ,  9.0970467 ,  8.15087772,  8.72365708,  9.23150661,\n",
       "       14.05822082,  9.32229846, 14.64657797,  9.0213369 , 13.41474532,\n",
       "        9.4921686 , 14.38188488, 14.63826295,  8.96509185,  9.42182391,\n",
       "        8.67440896, 11.80453277,  9.49350098, 11.1434006 ,  9.66241491,\n",
       "       11.12039386,  8.37060185, 12.09376525, 15.38325223,  8.92222548,\n",
       "       14.82037253, 16.77980865, 15.43282469, 15.85452601, 13.23143555,\n",
       "        8.70377044, 12.69349029, 11.40816536, 15.00362062, 11.12287376,\n",
       "       11.51462677,  8.56289198, 12.84290511, 11.79884117, 12.14068825,\n",
       "        8.08226433, 15.3410974 , 11.57943575,  8.56186933,  8.07759522,\n",
       "        9.14267049, 15.3191782 , 11.0810554 , 15.95270714,  9.34339833,\n",
       "       12.95655977, 10.83490116, 11.77603146,  8.7466014 ,  9.10505507,\n",
       "       12.60507329, 12.42277555,  8.81845867, 15.53779036,  9.06249801,\n",
       "        8.64510981, 14.75315675,  9.1250389 , 10.84838279, 12.98278757,\n",
       "        9.19161132,  8.68915871, 12.31096935,  8.5979422 , 12.2969977 ,\n",
       "        8.77250435, 16.27215319,  8.61758688, 14.68129843, 12.6509305 ,\n",
       "       14.29560371, 13.83320942, 15.31913574, 12.29509688,  8.19395229,\n",
       "       12.16371663, 13.08652836, 12.46373944, 10.97392404, 12.43630024,\n",
       "        9.10912644, 15.53638997,  9.00823256,  9.05560251,  8.57248838,\n",
       "        8.797509  , 14.90609081, 12.0988461 , 14.24058016,  9.20019256,\n",
       "       11.99716736, 13.04970217, 14.95813324, 14.36743198, 12.54700911,\n",
       "       15.55451337, 15.61613485, 11.24033386, 14.86935475,  9.01228039,\n",
       "       11.40736286,  9.02476299,  8.76329389, 15.4330685 , 11.94337744,\n",
       "        8.24844386,  8.40712504, 15.86044796,  9.0365792 , 14.43651936,\n",
       "        8.80007225, 14.73606725, 11.74443904, 11.51144604, 14.1609333 ,\n",
       "       11.8839618 , 12.4098026 ,  8.55921704,  8.24088781, 11.38409019,\n",
       "       10.91520613,  8.19467893,  9.23024204,  8.62793713,  9.34437488,\n",
       "       12.15689343,  8.67890844, 13.03318677, 12.34086619, 16.50620601,\n",
       "       12.30895626, 15.89814045, 15.32190009, 12.26956358, 16.65769056,\n",
       "        9.26718177, 15.0510188 , 13.17711818,  8.83919049, 11.56154555,\n",
       "       15.82155579, 11.17477255,  8.69061644,  8.8299139 , 14.8119128 ,\n",
       "       12.7000203 , 16.59504726,  7.98639487, 15.10322532, 13.84626475,\n",
       "       12.20336606,  8.29604964, 16.03413664, 15.95203444, 11.98754685,\n",
       "       11.38631978, 11.76059548, 12.13433283, 12.47177448, 11.6003031 ,\n",
       "       15.31996731,  9.04193107, 12.31259967, 13.9982494 ,  8.58019295,\n",
       "        8.57282164, 15.85927394, 15.64027332, 11.84669006,  8.81362443,\n",
       "       14.10451498, 15.2270165 , 15.42162088, 11.61787972,  8.6650622 ,\n",
       "       12.50843768,  8.55164477, 14.1695209 , 10.78050615,  9.23362788,\n",
       "       16.09943671, 10.26811572,  8.87753275, 15.99308367, 10.28697948,\n",
       "       12.84732019, 12.05990974, 12.33390098, 15.3406335 ,  8.69321558,\n",
       "       14.24181023, 11.81291286, 11.41552267,  8.87816055,  8.07539721,\n",
       "        8.48770686, 12.49289743, 11.04725226, 15.76190942,  8.4567268 ,\n",
       "       12.48299583, 12.40004215, 16.1117326 , 15.56171986, 14.07746919,\n",
       "       14.20923648, 16.51404828,  9.14996491,  8.89257492, 13.98998024,\n",
       "       16.00871538, 10.40265521, 14.72820825, 15.23833317, 16.39475487,\n",
       "        8.50160239, 15.26050173,  8.70800891, 11.59160439, 16.28532083,\n",
       "       15.90757913, 12.55933908, 11.89952656,  8.61001401,  8.79713694,\n",
       "       12.35504157, 12.29183275, 12.69999161, 10.6185506 , 12.74655789,\n",
       "       13.89985793, 12.28328281, 12.45840348, 14.58455147, 15.52898968,\n",
       "        8.4220721 ,  8.98067516, 11.17034018,  8.11938206, 16.449557  ,\n",
       "       14.96925763,  9.74287166,  8.86363568, 10.31636636, 11.64580946,\n",
       "        8.59469613, 15.89440179, 12.49981063, 15.40650653,  9.24488739,\n",
       "       16.59833182, 11.8417081 ,  8.7466884 , 11.7888835 , 15.27977628,\n",
       "       16.3223121 , 14.4730346 ,  7.81491858,  8.37007651, 14.06383271,\n",
       "        9.21534604, 12.45580729, 15.77236271, 12.04762461, 16.33402396,\n",
       "        8.46204073, 14.4309547 , 14.11291558, 15.25454398, 12.84125795,\n",
       "       12.19694432, 12.38801682,  9.26736786, 11.14202249, 12.08038087,\n",
       "       15.23940674, 13.48223205, 15.082389  , 12.33969292,  8.49269019,\n",
       "        8.53098232, 15.46296118, 12.88533447,  9.12463284,  9.09801465])"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_transformer = Pipeline(steps=[\n",
    "    ('std', StdScalerByGroup())\n",
    "])\n",
    "\n",
    "log_func = FunctionTransformer(np.log)\n",
    "c2_transformer = Pipeline(steps=[\n",
    "    ('log', log_func)\n",
    "])\n",
    "\n",
    "group_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())     # output from Ordinal becomes input to OneHot\n",
    "])\n",
    "\n",
    "# preprocessing pipeline (put them together)\n",
    "preproc = ColumnTransformer(transformers=[\n",
    "    ('std', c1_transformer, ['group', 'c1']),\n",
    "    ('log', c2_transformer, ['c2']),\n",
    "    ('onehot', group_transformer, ['group'])\n",
    "])\n",
    "\n",
    "new_pl = Pipeline(steps=[\n",
    "    ('preprocessor', preproc),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "new_pl.fit(data.drop('y', axis=1), data['y'])\n",
    "predic_4 = new_pl.predict(data.drop('y', axis=1))\n",
    "predic_4\n",
    "\n",
    "# Test\n",
    "# std = StdScalerByGroup()\n",
    "# std.fit(data.drop('y', axis=1)[['group','c1']], data['y'])\n",
    "# std.transform(data.drop('y', axis=1)[['group','c1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.085851</td>\n",
       "      <td>1.673273</td>\n",
       "      <td>12.649035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.202034</td>\n",
       "      <td>1.345336</td>\n",
       "      <td>17.309083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.601409</td>\n",
       "      <td>2.369745</td>\n",
       "      <td>15.695646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.541118</td>\n",
       "      <td>1.858633</td>\n",
       "      <td>11.535752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.223835</td>\n",
       "      <td>1.811045</td>\n",
       "      <td>14.954389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2        c1        c2          y\n",
       "0  0.0  1.0  0.0  2.085851  1.673273  12.649035\n",
       "1  1.0  0.0  0.0  1.202034  1.345336  17.309083\n",
       "2  1.0  0.0  0.0 -0.601409  2.369745  15.695646\n",
       "3  0.0  1.0  0.0  0.541118  1.858633  11.535752\n",
       "4  0.0  1.0  0.0  1.223835  1.811045  14.954389"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = StdScalerByGroup()\n",
    "c1 = std.fit_transform(data.drop('y', axis=1)[['group','c1']], data['y'])['c1']\n",
    "# c1 = std.transform(data.drop('y', axis=1)[['group','c1']])['c1']\n",
    "\n",
    "# c1 = data['c1']\n",
    "# c2 = data['c2'].apply(np.log)\n",
    "log_func = FunctionTransformer(np.log)\n",
    "c2 = log_func.fit_transform(data.drop('y', axis=1)[['c2']])['c2']\n",
    "\n",
    "group_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())     # output from Ordinal becomes input to OneHot\n",
    "])\n",
    "test = pd.DataFrame(data=group_transformer.fit_transform(data[['group']]).toarray())\n",
    "test = test.assign(c1=c1, c2=c2, y=data['y'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.234375, 14.6875  , 15.375   , 12.84375 , 13.078125, 12.265625,\n",
       "       12.484375,  8.765625, 14.78125 ,  8.46875 , 14.390625, 11.75    ,\n",
       "       14.890625, 13.296875, 15.375   , 15.703125, 11.625   , 13.90625 ,\n",
       "       13.34375 , 10.75    , 11.78125 ,  9.90625 , 11.9375  , 14.71875 ,\n",
       "       13.859375,  8.375   , 12.296875, 12.78125 , 16.890625,  9.390625,\n",
       "       16.359375, 14.4375  , 13.921875, 15.328125, 11.75    ,  8.546875,\n",
       "        8.375   , 15.265625, 16.171875, 11.046875,  8.34375 , 15.78125 ,\n",
       "        8.578125, 14.953125, 11.921875, 11.859375, 10.671875, 11.96875 ,\n",
       "       11.796875, 12.28125 ,  8.3125  ,  9.40625 ,  9.390625,  8.234375,\n",
       "       15.96875 , 10.28125 , 15.9375  ,  9.15625 ,  8.71875 ,  9.328125,\n",
       "        8.265625, 12.359375,  8.921875,  8.265625, 12.84375 , 16.359375,\n",
       "       11.234375, 15.234375, 16.375   , 10.90625 , 15.078125,  9.5     ,\n",
       "       11.078125,  8.28125 ,  9.328125, 12.15625 , 12.609375, 12.359375,\n",
       "       11.8125  , 12.15625 , 11.734375, 11.078125, 15.484375, 12.328125,\n",
       "       15.296875, 12.5     , 12.65625 , 11.546875, 13.953125,  9.125   ,\n",
       "       11.484375, 12.59375 ,  9.296875,  8.96875 ,  8.40625 , 16.390625,\n",
       "       12.671875,  8.34375 ,  9.21875 , 14.328125, 12.78125 , 16.34375 ,\n",
       "        8.703125, 11.5     , 11.40625 ,  8.90625 ,  8.96875 , 15.5625  ,\n",
       "       16.234375, 13.25    , 14.46875 , 11.640625,  8.53125 , 12.671875,\n",
       "       14.703125, 12.828125, 16.03125 ,  7.921875,  8.15625 , 15.578125,\n",
       "       15.25    , 15.65625 ,  8.96875 , 11.984375,  9.203125,  8.640625,\n",
       "       14.984375, 13.671875, 14.75    , 13.4375  , 16.125   , 15.25    ,\n",
       "       12.1875  ,  8.546875, 15.09375 , 11.375   , 15.515625, 11.75    ,\n",
       "        8.640625,  8.578125, 16.0625  , 11.28125 ,  8.78125 , 11.265625,\n",
       "        8.5625  ,  8.78125 , 15.53125 , 14.640625,  8.421875, 14.75    ,\n",
       "        8.921875, 15.46875 ,  8.703125, 12.828125, 14.75    , 11.65625 ,\n",
       "        9.015625, 12.40625 , 12.625   ,  8.984375,  8.453125, 11.59375 ,\n",
       "        8.765625, 15.390625, 12.078125, 12.484375, 10.765625,  8.921875,\n",
       "       11.859375,  8.921875,  7.921875, 11.796875, 15.921875, 14.109375,\n",
       "       16.234375, 12.203125, 11.109375, 13.96875 , 11.6875  , 10.453125,\n",
       "       13.890625, 14.03125 , 15.015625, 14.609375,  9.359375, 16.3125  ,\n",
       "       15.5625  ,  8.59375 ,  8.9375  , 13.515625, 13.0625  ,  8.921875,\n",
       "       14.40625 , 11.59375 , 11.859375, 12.      , 11.40625 , 14.03125 ,\n",
       "       16.53125 , 17.03125 , 11.890625, 13.96875 , 12.390625, 15.84375 ,\n",
       "       15.71875 ,  8.828125,  8.453125,  7.703125, 13.46875 , 16.796875,\n",
       "       16.265625, 14.546875, 12.03125 , 11.765625, 12.03125 , 14.359375,\n",
       "       15.65625 , 15.359375,  8.546875, 11.875   ,  8.28125 ,  8.890625,\n",
       "       13.015625, 11.4375  ,  8.5     , 11.8125  , 12.5625  , 12.625   ,\n",
       "       12.609375, 12.921875, 10.734375,  9.625   ,  9.171875, 12.328125,\n",
       "       11.25    , 14.8125  , 16.53125 , 11.921875, 16.1875  ,  8.4375  ,\n",
       "       12.625   , 12.28125 , 15.265625, 15.359375,  8.765625, 11.578125,\n",
       "        9.109375, 15.3125  ,  9.515625,  7.859375, 14.15625 , 11.21875 ,\n",
       "        9.078125, 12.359375,  9.5     ,  8.234375, 12.59375 , 10.3125  ,\n",
       "        8.84375 ,  9.703125,  9.03125 ,  8.734375, 11.34375 , 14.03125 ,\n",
       "        8.765625, 12.734375,  8.40625 ,  8.78125 ,  8.3125  , 10.921875,\n",
       "        8.8125  , 12.0625  , 12.6875  , 15.046875, 13.140625,  8.671875,\n",
       "       17.03125 , 15.96875 ,  8.171875, 12.1875  , 13.828125, 11.75    ,\n",
       "       11.84375 ,  8.625   , 15.234375,  8.734375, 16.765625,  8.515625,\n",
       "        9.203125, 11.796875, 16.53125 , 13.640625, 14.28125 ,  8.546875,\n",
       "       14.453125,  8.203125, 12.140625,  9.28125 , 16.03125 , 13.75    ,\n",
       "       11.5     ,  8.6875  , 14.5     , 11.59375 , 11.796875,  8.5     ,\n",
       "        9.078125, 14.34375 ,  9.203125,  8.5625  , 15.875   , 13.9375  ,\n",
       "       11.6875  ,  8.359375, 16.125   ,  8.90625 , 11.953125,  8.421875,\n",
       "       14.3125  , 14.625   , 15.703125, 11.53125 , 14.546875,  8.5     ,\n",
       "        9.6875  , 13.421875, 14.921875, 12.5     ,  9.0625  , 16.21875 ,\n",
       "        9.3125  , 16.734375, 12.875   , 15.390625,  8.328125, 11.71875 ,\n",
       "       11.78125 , 12.1875  , 12.5     , 11.59375 , 16.234375, 12.59375 ,\n",
       "       11.8125  ,  9.1875  , 11.40625 , 16.609375, 11.25    , 14.734375,\n",
       "       10.515625, 11.75    , 14.734375, 14.09375 , 13.484375,  8.328125,\n",
       "       15.3125  ,  8.375   , 14.96875 , 10.46875 , 16.1875  , 11.703125,\n",
       "       13.03125 , 15.875   ,  8.4375  ,  8.4375  , 10.53125 , 12.0625  ,\n",
       "       15.578125, 12.453125,  8.828125,  9.03125 , 15.234375, 15.625   ,\n",
       "       14.546875, 12.421875,  9.140625,  7.96875 , 11.75    , 11.484375,\n",
       "        8.78125 ,  9.234375, 15.8125  ,  8.046875, 13.53125 , 11.640625,\n",
       "       15.25    , 15.09375 ,  9.328125, 14.78125 , 15.703125,  8.859375,\n",
       "       14.890625, 16.546875, 14.40625 , 12.296875, 14.515625, 15.0625  ,\n",
       "        8.140625, 11.8125  , 12.640625,  8.921875,  8.6875  , 15.046875,\n",
       "       10.390625, 16.15625 , 16.203125, 15.53125 , 13.078125, 16.015625,\n",
       "       15.640625, 12.203125, 15.8125  ,  8.484375, 12.46875 , 12.953125,\n",
       "       11.296875, 14.46875 , 14.9375  , 12.890625,  9.109375,  8.953125,\n",
       "        8.6875  , 16.828125, 12.109375, 11.84375 , 13.515625, 11.59375 ,\n",
       "        9.296875,  8.875   , 13.046875, 14.828125, 14.25    , 11.984375,\n",
       "       12.640625, 16.578125, 12.953125,  8.96875 , 11.953125,  8.609375,\n",
       "       15.890625, 11.0625  , 13.53125 ,  8.3125  , 10.265625,  8.359375,\n",
       "       12.46875 , 15.03125 , 11.734375,  8.203125, 14.578125, 11.375   ,\n",
       "        8.515625, 16.1875  , 12.234375,  9.015625, 16.03125 , 15.84375 ,\n",
       "       13.1875  ,  8.734375,  8.234375, 12.015625, 12.421875,  8.75    ,\n",
       "        8.796875, 11.578125, 14.28125 ,  8.703125, 11.3125  ,  8.703125,\n",
       "        8.59375 ,  8.359375,  9.25    ,  8.6875  , 16.03125 , 11.671875,\n",
       "        8.234375, 12.296875,  8.78125 , 15.015625,  9.359375,  8.25    ,\n",
       "        8.421875, 12.0625  , 16.328125,  9.046875,  9.25    , 13.578125,\n",
       "       15.3125  ,  9.140625, 11.296875, 11.40625 , 12.6875  ,  8.890625,\n",
       "        8.234375, 12.53125 ,  9.078125, 11.484375, 16.375   , 16.71875 ,\n",
       "       14.484375,  8.265625, 11.859375, 12.734375, 13.546875, 11.9375  ,\n",
       "       13.875   , 12.125   , 12.203125, 12.046875, 15.765625,  9.15625 ,\n",
       "        9.078125, 12.765625,  8.921875, 12.484375, 12.34375 , 11.984375,\n",
       "        8.6875  ,  8.5     , 16.03125 ,  9.046875, 15.75    ,  8.71875 ,\n",
       "       13.625   ,  8.15625 ,  9.125   , 11.46875 ,  8.875   ,  9.296875,\n",
       "       12.046875, 15.890625,  9.046875, 11.75    , 14.1875  , 12.5625  ,\n",
       "       14.671875,  8.203125, 13.5     ,  8.890625, 11.4375  , 13.109375,\n",
       "       11.765625, 16.375   ,  9.125   , 11.640625, 12.03125 , 15.046875,\n",
       "        8.828125, 12.109375, 11.5     , 10.203125,  8.71875 , 14.09375 ,\n",
       "       15.421875, 11.34375 , 12.25    , 11.1875  , 12.578125, 12.21875 ,\n",
       "       13.640625,  9.140625, 12.171875, 12.328125, 15.515625, 12.46875 ,\n",
       "        8.328125,  8.859375, 12.53125 , 12.21875 , 12.4375  , 14.375   ,\n",
       "       12.25    , 15.5625  ,  8.28125 ,  8.125   , 14.4375  , 10.34375 ,\n",
       "       14.59375 ,  8.3125  ,  9.234375, 13.703125, 12.6875  , 15.578125,\n",
       "        8.390625, 12.921875,  8.5625  , 14.34375 , 16.40625 ,  8.75    ,\n",
       "       12.8125  ,  9.796875,  9.3125  , 15.390625, 14.21875 ,  8.59375 ,\n",
       "       12.390625, 15.15625 , 11.015625, 12.109375, 15.8125  , 11.921875,\n",
       "        8.96875 ,  9.390625, 15.25    ,  8.96875 , 11.625   , 12.546875,\n",
       "        8.453125, 12.25    ,  8.53125 ,  8.734375, 12.671875,  9.03125 ,\n",
       "        8.609375,  8.65625 , 12.25    , 12.265625, 14.65625 ,  9.3125  ,\n",
       "       11.921875,  8.03125 ,  9.140625, 13.578125, 13.546875, 13.234375,\n",
       "       16.625   , 13.46875 ,  8.34375 ,  8.5625  ,  8.921875, 11.625   ,\n",
       "        8.671875, 14.34375 , 14.125   ,  9.421875, 11.859375,  9.78125 ,\n",
       "        9.015625,  9.0625  , 11.875   , 13.328125,  9.125   , 12.234375,\n",
       "        8.109375, 13.875   ,  8.703125, 16.59375 ,  9.625   , 12.125   ,\n",
       "       14.21875 , 15.625   , 10.9375  ,  9.      , 12.015625, 15.765625,\n",
       "        8.75    ,  8.28125 , 11.71875 , 12.640625, 16.125   , 15.46875 ,\n",
       "        8.828125, 12.859375, 12.875   , 12.578125, 14.0625  , 15.921875,\n",
       "       10.875   ,  9.296875, 11.25    , 12.875   , 15.734375, 16.3125  ,\n",
       "        9.015625, 10.34375 , 17.15625 , 14.4375  , 16.578125, 12.828125,\n",
       "        8.515625,  8.5625  , 13.65625 , 14.765625, 11.84375 ,  9.015625,\n",
       "        8.140625, 15.171875, 15.734375, 12.46875 , 14.796875, 11.859375,\n",
       "       11.078125,  9.390625, 15.296875,  8.546875,  8.796875, 15.953125,\n",
       "        8.46875 , 12.46875 , 11.6875  , 11.578125,  9.671875,  8.0625  ,\n",
       "       12.390625,  9.125   ,  8.453125, 14.203125, 15.40625 , 11.875   ,\n",
       "       15.234375,  9.0625  , 15.53125 ,  9.125   ,  8.171875,  8.75    ,\n",
       "        9.265625, 14.      ,  9.359375, 14.59375 ,  9.046875, 13.4375  ,\n",
       "        9.53125 , 14.34375 , 14.578125,  9.      ,  9.453125,  8.703125,\n",
       "       11.8125  ,  9.53125 , 11.15625 ,  9.703125, 11.109375,  8.390625,\n",
       "       12.09375 , 15.328125,  8.953125, 14.78125 , 16.734375, 15.390625,\n",
       "       15.8125  , 13.234375,  8.734375, 12.703125, 11.421875, 14.953125,\n",
       "       11.125   , 11.515625,  8.59375 , 12.84375 , 11.8125  , 12.140625,\n",
       "        8.109375, 15.296875, 11.578125,  8.59375 ,  8.09375 ,  9.171875,\n",
       "       15.28125 , 11.078125, 15.90625 ,  9.375   , 12.96875 , 10.875   ,\n",
       "       11.796875,  8.78125 ,  9.140625, 12.546875, 12.421875,  8.84375 ,\n",
       "       15.484375,  9.09375 ,  8.671875, 14.703125,  9.15625 , 10.84375 ,\n",
       "       13.      ,  9.21875 ,  8.71875 , 12.3125  ,  8.625   , 12.3125  ,\n",
       "        8.796875, 16.21875 ,  8.640625, 14.640625, 12.65625 , 14.265625,\n",
       "       13.78125 , 15.28125 , 12.296875,  8.21875 , 12.171875, 13.09375 ,\n",
       "       12.46875 , 10.984375, 12.453125,  9.140625, 15.484375,  9.03125 ,\n",
       "        9.09375 ,  8.59375 ,  8.828125, 14.859375, 12.109375, 14.203125,\n",
       "        9.234375, 12.      , 13.046875, 14.90625 , 14.328125, 12.5625  ,\n",
       "       15.5     , 15.5625  , 11.25    , 14.8125  ,  9.046875, 11.40625 ,\n",
       "        9.0625  ,  8.796875, 15.390625, 11.953125,  8.265625,  8.4375  ,\n",
       "       15.8125  ,  9.0625  , 14.390625,  8.828125, 14.6875  , 11.75    ,\n",
       "       11.515625, 14.109375, 11.875   , 12.421875,  8.578125,  8.265625,\n",
       "       11.390625, 10.90625 ,  8.21875 ,  9.265625,  8.65625 ,  9.375   ,\n",
       "       12.15625 ,  8.703125, 13.03125 , 12.359375, 16.453125, 12.328125,\n",
       "       15.84375 , 15.265625, 12.265625, 16.609375,  9.296875, 15.      ,\n",
       "       13.1875  ,  8.875   , 11.5625  , 15.78125 , 11.203125,  8.71875 ,\n",
       "        8.859375, 14.765625, 12.71875 , 16.546875,  8.      , 15.0625  ,\n",
       "       13.796875, 12.203125,  8.3125  , 15.984375, 15.90625 , 12.      ,\n",
       "       11.390625, 11.75    , 12.140625, 12.484375, 11.609375, 15.28125 ,\n",
       "        9.078125, 12.3125  , 13.953125,  8.609375,  8.59375 , 15.796875,\n",
       "       15.59375 , 11.859375,  8.84375 , 14.0625  , 15.171875, 15.375   ,\n",
       "       11.609375,  8.6875  , 12.515625,  8.578125, 14.109375, 10.765625,\n",
       "        9.265625, 16.046875, 10.3125  ,  8.90625 , 15.953125, 10.328125,\n",
       "       12.859375, 12.09375 , 12.34375 , 15.28125 ,  8.71875 , 14.25    ,\n",
       "       11.8125  , 11.421875,  8.90625 ,  8.09375 ,  8.515625, 12.515625,\n",
       "       11.0625  , 15.703125,  8.484375, 12.5     , 12.40625 , 16.0625  ,\n",
       "       15.515625, 14.03125 , 14.171875, 16.453125,  9.1875  ,  8.921875,\n",
       "       14.      , 15.96875 , 10.4375  , 14.671875, 15.203125, 16.34375 ,\n",
       "        8.53125 , 15.21875 ,  8.734375, 11.609375, 16.25    , 15.84375 ,\n",
       "       12.5625  , 11.90625 ,  8.640625,  8.828125, 12.359375, 12.296875,\n",
       "       12.71875 , 10.609375, 12.75    , 13.84375 , 12.28125 , 12.453125,\n",
       "       14.546875, 15.46875 ,  8.453125,  9.015625, 11.171875,  8.140625,\n",
       "       16.40625 , 14.921875,  9.78125 ,  8.890625, 10.34375 , 11.640625,\n",
       "        8.625   , 15.84375 , 12.5     , 15.359375,  9.28125 , 16.546875,\n",
       "       11.84375 ,  8.78125 , 11.78125 , 15.234375, 16.265625, 14.421875,\n",
       "        7.828125,  8.390625, 14.015625,  9.25    , 12.46875 , 15.71875 ,\n",
       "       12.046875, 16.28125 ,  8.484375, 14.375   , 14.0625  , 15.203125,\n",
       "       12.78125 , 12.203125, 12.40625 ,  9.296875, 11.140625, 12.078125,\n",
       "       15.1875  , 13.4375  , 15.03125 , 12.34375 ,  8.515625,  8.5625  ,\n",
       "       15.421875, 12.90625 ,  9.15625 ,  9.125   ])"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression() # initial linear regression\n",
    "\n",
    "lr.fit(test.drop('y', axis=1), test['y']) # calculate the weights\n",
    "\n",
    "predictions = lr.predict(test.drop('y', axis=1)) # calculate predictions\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.7551086974518118\n",
      "RMSE: 2.314833616435528\n",
      "RMSE: 2.3157339477823844\n"
     ]
    }
   ],
   "source": [
    "Q1 = predic\n",
    "Q2 = predic_2\n",
    "new = predic_4\n",
    "y = data['y']\n",
    "for pred in [Q1, Q2, new]:\n",
    "    rmse = np.sqrt(np.mean((pred - y)**2))\n",
    "    print('RMSE: %s' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_toy_model():\n",
    "    \"\"\"\n",
    "    hardcoded answers to question 4\n",
    "\n",
    "    :Example:\n",
    "    >>> out = eval_toy_model()\n",
    "    >>> len(out) == 3\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    return [2.7551086974518104, 2.314833616435528, 2.3157339477823844]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting model parameters\n",
    "\n",
    "**Question 5**\n",
    "\n",
    "In this question, you will train two different prediction models on Galton's child-height dataset from lecture and explore different ways in how overfitting can appear.\n",
    "\n",
    "**Part 1: Decision Tree Regressor**\n",
    "\n",
    "* A decision tree regressor is trained similar to decision tree classifiers: the splits of the tree are created by minimizing the variance of the target values of the (training) data in the leaves given by making the split in question. \n",
    "\n",
    "* A decision tree regressor predicts the target value of a (new) observation based on the average target value of the training observations lying in the same leaf node. \n",
    "\n",
    "* One parameter of a decision tree regressor that affects model complexity is the *depth* of the tree. We will explore this parameter in this question.\n",
    "\n",
    "* Create a function `tree_reg_perf` that takes in a dataframe like `galton` and outputs a dataframe where each row contains the *RMSE* of a trained decision tree regressor on the training set and test set, indexed by the depth of the decision tree (depth=1,2,3,...,20). (i.e. you should train 20 different decision trees with varying depths and put the train/test error into a dataframe).\n",
    "\n",
    "*Note* (Optional question good for studying): How is this overfitting and why? What type of variance is causing it? What is the best choice of depth? Plot the dataframe above to help answer these questions.\n",
    "\n",
    "**Part 2: k-Nearest Neighbor Regressor**\n",
    "\n",
    "* A k-NN Regressor predicts the target value of a (new) observation by computing the average value of the k-closest observations in the training set.\n",
    "\n",
    "* One parameter of a k-NN regressor that affects model performance is the number of neighbors averaged over. We will explore this parameter in this question.\n",
    "\n",
    "* Create a function `knn_reg_perf` that takes in a dataframe like `galton` and outputs a dataframe where each row contains the *RMSE* of a trained k-NN regressor on the training set and test set, indexed by the number of neighbors (k=1,2,3,...,20).\n",
    "\n",
    "*Note* (Optional question good for studying): How is this overfitting and why? What type of variance is causing it? What is the best choice for the number of neighbors? Plot the dataframe above to help answer these questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>father</th>\n",
       "      <th>mother</th>\n",
       "      <th>children</th>\n",
       "      <th>childNum</th>\n",
       "      <th>gender</th>\n",
       "      <th>childHeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.5</td>\n",
       "      <td>66.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   father  mother  children  childNum  gender  childHeight\n",
       "0    78.5    67.0         4         1       1         73.2\n",
       "1    78.5    67.0         4         2       0         69.2\n",
       "2    78.5    67.0         4         3       0         69.0\n",
       "3    78.5    67.0         4         4       0         69.0\n",
       "4    75.5    66.5         4         1       1         73.5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galton = pd.read_csv('data/galton.csv')\n",
    "galton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_err</th>\n",
       "      <th>test_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.510857</td>\n",
       "      <td>2.453401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.341372</td>\n",
       "      <td>2.285841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.184913</td>\n",
       "      <td>2.089187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.039494</td>\n",
       "      <td>2.021854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.877799</td>\n",
       "      <td>2.286768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.730014</td>\n",
       "      <td>2.199579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.576134</td>\n",
       "      <td>2.196561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.372588</td>\n",
       "      <td>2.264139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.188021</td>\n",
       "      <td>2.345511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.964329</td>\n",
       "      <td>2.422877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.734088</td>\n",
       "      <td>2.572105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.598959</td>\n",
       "      <td>2.649326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.461005</td>\n",
       "      <td>2.755336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.384532</td>\n",
       "      <td>2.742853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.348463</td>\n",
       "      <td>2.684687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.325538</td>\n",
       "      <td>2.726374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.303500</td>\n",
       "      <td>2.648723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.289993</td>\n",
       "      <td>2.651684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.284212</td>\n",
       "      <td>2.777416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.272143</td>\n",
       "      <td>2.692120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_err  test_err\n",
       "1    2.510857  2.453401\n",
       "2    2.341372  2.285841\n",
       "3    2.184913  2.089187\n",
       "4    2.039494  2.021854\n",
       "5    1.877799  2.286768\n",
       "6    1.730014  2.199579\n",
       "7    1.576134  2.196561\n",
       "8    1.372588  2.264139\n",
       "9    1.188021  2.345511\n",
       "10   0.964329  2.422877\n",
       "11   0.734088  2.572105\n",
       "12   0.598959  2.649326\n",
       "13   0.461005  2.755336\n",
       "14   0.384532  2.742853\n",
       "15   0.348463  2.684687\n",
       "16   0.325538  2.726374\n",
       "17   0.303500  2.648723\n",
       "18   0.289993  2.651684\n",
       "19   0.284212  2.777416\n",
       "20   0.272143  2.692120"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = galton.drop('childHeight', axis=1)\n",
    "y = galton.childHeight\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "rows = []\n",
    "for k in range(1, 21):\n",
    "    reg = DecisionTreeRegressor(max_depth=k)\n",
    "    pl = Pipeline([\n",
    "       ('DT_reg', reg)\n",
    "    ])\n",
    "\n",
    "    pl.fit(X_train, y_train)\n",
    "    preds_train = pl.predict(X_train)\n",
    "    preds_test = pl.predict(X_test)\n",
    "    rmse_train = np.sqrt(np.mean((preds_train - y_train)**2))\n",
    "    rmse_test = np.sqrt(np.mean((preds_test - y_test)**2))\n",
    "    rows.append(pd.Series({'train_err':rmse_train, 'test_err':rmse_test}, name=k))\n",
    "    # print (k, \"train_err: %s\" % rmse_train + \"; test_err: %s\" % rmse_test)\n",
    "    \n",
    "    \n",
    "    # reg.fit(galton.loc[:, ~galton.columns.isin(['childHeight'])], galton.childHeight)\n",
    "    # preds = reg.predict(galton.loc[:, ~galton.columns.isin(['childHeight'])])\n",
    "    # rmse = np.sqrt(np.mean((preds - galton.childHeight)**2))\n",
    "    # print(k, rmse)\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_reg_perf(galton):\n",
    "    \"\"\"\n",
    "\n",
    "    :Example:\n",
    "    >>> galton_fp = os.path.join('data', 'galton.csv')\n",
    "    >>> galton = pd.read_csv(galton_fp)\n",
    "    >>> out = tree_reg_perf(galton)\n",
    "    >>> out.columns.tolist() == ['train_err', 'test_err']\n",
    "    True\n",
    "    >>> out['train_err'].iloc[-1] < out['test_err'].iloc[-1]\n",
    "    True\n",
    "    \"\"\"\n",
    "    X = galton.drop('childHeight', axis=1)\n",
    "    y = galton.childHeight\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    rows = []\n",
    "    for k in range(1, 21):\n",
    "        reg = DecisionTreeRegressor(max_depth=k)\n",
    "        pl = Pipeline([\n",
    "           ('DT_reg', reg)\n",
    "        ])\n",
    "\n",
    "        pl.fit(X_train, y_train)\n",
    "        preds_train = pl.predict(X_train)\n",
    "        preds_test = pl.predict(X_test)\n",
    "        rmse_train = np.sqrt(np.mean((preds_train - y_train)**2))\n",
    "        rmse_test = np.sqrt(np.mean((preds_test - y_test)**2))\n",
    "        rows.append(pd.Series({'train_err':rmse_train, 'test_err':rmse_test}, name=k))\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_err</th>\n",
       "      <th>test_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.347625</td>\n",
       "      <td>2.385614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.279854</td>\n",
       "      <td>2.064417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.540650</td>\n",
       "      <td>2.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.643024</td>\n",
       "      <td>1.983349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.759061</td>\n",
       "      <td>2.039183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.825938</td>\n",
       "      <td>2.050382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.852222</td>\n",
       "      <td>2.045436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.910254</td>\n",
       "      <td>2.084976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.952527</td>\n",
       "      <td>2.085722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.963647</td>\n",
       "      <td>2.074646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.987124</td>\n",
       "      <td>2.102588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.008118</td>\n",
       "      <td>2.082573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.042276</td>\n",
       "      <td>2.088483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.051362</td>\n",
       "      <td>2.079436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.079027</td>\n",
       "      <td>2.059277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.094334</td>\n",
       "      <td>2.072135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.109847</td>\n",
       "      <td>2.062054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.122707</td>\n",
       "      <td>2.068029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.133788</td>\n",
       "      <td>2.062947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.141595</td>\n",
       "      <td>2.068111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_err  test_err\n",
       "1    0.347625  2.385614\n",
       "2    1.279854  2.064417\n",
       "3    1.540650  2.000082\n",
       "4    1.643024  1.983349\n",
       "5    1.759061  2.039183\n",
       "6    1.825938  2.050382\n",
       "7    1.852222  2.045436\n",
       "8    1.910254  2.084976\n",
       "9    1.952527  2.085722\n",
       "10   1.963647  2.074646\n",
       "11   1.987124  2.102588\n",
       "12   2.008118  2.082573\n",
       "13   2.042276  2.088483\n",
       "14   2.051362  2.079436\n",
       "15   2.079027  2.059277\n",
       "16   2.094334  2.072135\n",
       "17   2.109847  2.062054\n",
       "18   2.122707  2.068029\n",
       "19   2.133788  2.062947\n",
       "20   2.141595  2.068111"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = galton.drop('childHeight', axis=1)\n",
    "y = galton.childHeight\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "rows = []\n",
    "for k in range(1, 21):\n",
    "    reg = KNeighborsRegressor(n_neighbors=k)\n",
    "    pl = Pipeline([\n",
    "       ('KN_reg', reg)\n",
    "    ])\n",
    "\n",
    "\n",
    "    pl.fit(X_train, y_train)\n",
    "    preds_train = pl.predict(X_train)\n",
    "    preds_test = pl.predict(X_test)\n",
    "    rmse_train = np.sqrt(np.mean((preds_train - y_train)**2))\n",
    "    rmse_test = np.sqrt(np.mean((preds_test - y_test)**2))\n",
    "    rows.append(pd.Series({'train_err':rmse_train, 'test_err':rmse_test}, name=k))\n",
    "    # print (k, \"train_err: %s\" % rmse_train + \"; test_err: %s\" % rmse_test)\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_reg_perf(galton):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> galton_fp = os.path.join('data', 'galton.csv')\n",
    "    >>> galton = pd.read_csv(galton_fp)\n",
    "    >>> out = knn_reg_perf(galton)\n",
    "    >>> out.columns.tolist() == ['train_err', 'test_err']\n",
    "    True\n",
    "    \"\"\"\n",
    "    X = galton.drop('childHeight', axis=1)\n",
    "    y = galton.childHeight\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    rows = []\n",
    "    for k in range(1, 21):\n",
    "        reg = KNeighborsRegressor(n_neighbors=k)\n",
    "        pl = Pipeline([\n",
    "           ('KN_reg', reg)\n",
    "        ])\n",
    "\n",
    "\n",
    "        pl.fit(X_train, y_train)\n",
    "        preds_train = pl.predict(X_train)\n",
    "        preds_test = pl.predict(X_test)\n",
    "        rmse_train = np.sqrt(np.mean((preds_train - y_train)**2))\n",
    "        rmse_test = np.sqrt(np.mean((preds_test - y_test)**2))\n",
    "        rows.append(pd.Series({'train_err':rmse_train, 'test_err':rmse_test}, name=k))\n",
    "        \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic: predicting survival\n",
    "\n",
    "**Question 6**\n",
    "\n",
    "Predicting survival on the titanic is a common first assignment when learning classification tasks. There is *a lot* of material out there on analyzing the Titanic data. While not necessary for this question, you are encouraged to look at examples out on the web (e.g. [on kaggle](https://www.kaggle.com/c/titanic)).\n",
    "\n",
    "Create a function `titanic_model` that takes in training data (a dataframe) and returns a pipeline object fit to the training data. You have freedom to build your own model, but it should satisfy the following requirements:\n",
    "\n",
    "* The model is built on the target column `Survived`.\n",
    "* The model uses features derived from *all* **other** columns in training.\n",
    "* You have one feature derived from the 'title' in the `Name` field ('Mr', 'Miss', 'Master', etc, not the name itself).\n",
    "* You have one feature that scales the age of a passenger to standard unit among their `Pclass`. (Use Question 3!)\n",
    "* You can use any classification algorithm, as long as your performance is above the baseline accuracy 0.78.\n",
    "* If your model (under retraining) can consistently score above 0.83, you can get 5 points extra-credit.\n",
    "    - Your model will be trained using the training data given in the lab; it will be evaluated using held out test data. This performance should generalize to *unseen* data; you should be honest about parameter-fitting on validation sets and get a score above 0.83 on an untouched *holdout*!\n",
    "\n",
    "*Note:* You will find [FunctionTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) useful for the `Name` column, as well as for the standardization of `Ages`. If you want your transformer to output a categorical feature, you will need to select `validate=False`.\n",
    "\n",
    "*Note*: When using [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer), you may find the `remainder` keyword helpful.\n",
    "\n",
    "*Note*: The function that is turned in should have the model parameters hard-coded in it. The pipeline object doesn't have to include the parameter selection process.\n",
    "\n",
    "*Hint*: If you are set out to get that extra 5 points, consider building some meaningful features before fine-tuning the parameters of your model. Do an EDA on the dataset, what kind of people are more prone to survive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr. William John Berriman</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mrs. (Beila) Moor</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.4750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Nestor Cyriel Vande Walle</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Khalil Saad</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Gerda Ulrika Dahlberg</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                           Name     Sex   Age  \\\n",
       "0         0       2      Mr. William John Berriman    male  23.0   \n",
       "1         1       3              Mrs. (Beila) Moor  female  27.0   \n",
       "2         0       3  Mr. Nestor Cyriel Vande Walle    male  28.0   \n",
       "3         0       3                Mr. Khalil Saad    male  25.0   \n",
       "4         0       3    Miss. Gerda Ulrika Dahlberg  female  22.0   \n",
       "\n",
       "   Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0                        0                        0  13.0000  \n",
       "1                        0                        1  12.4750  \n",
       "2                        0                        0   9.5000  \n",
       "3                        0                        0   7.2250  \n",
       "4                        0                        0  10.5167  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv('data/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    108\n",
       "3     97\n",
       "2     68\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survive = titanic[titanic['Survived']==1]\n",
    "survive['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Miss.      105\n",
       "Mrs.        79\n",
       "Mr.         63\n",
       "Master.     16\n",
       "Dr.          3\n",
       "Mlle.        2\n",
       "Lady.        1\n",
       "Major.       1\n",
       "Mme.         1\n",
       "Ms.          1\n",
       "Sir.         1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def strip_call(name):\n",
    "    return name.split(' ')[0]\n",
    "title = survive['Name'].apply(strip_call)\n",
    "survive = survive.assign(Title=title)\n",
    "surv = survive['Title'].value_counts()\n",
    "surv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    190\n",
       "male       83\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survive['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.00    17\n",
       "22.00    14\n",
       "27.00    11\n",
       "36.00    10\n",
       "28.00    10\n",
       "         ..\n",
       "54.00     1\n",
       "56.00     1\n",
       "80.00     1\n",
       "55.00     1\n",
       "0.67      1\n",
       "Name: Age, Length: 63, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survive['Age'].value_counts()#.iloc[10:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    170\n",
       "1     84\n",
       "2     12\n",
       "3      4\n",
       "4      3\n",
       "Name: Siblings/Spouses Aboard, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survive['Siblings/Spouses Aboard'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    189\n",
       "1     50\n",
       "2     31\n",
       "3      3\n",
       "Name: Parents/Children Aboard, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survive['Parents/Children Aboard'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0000    12\n",
       "26.0000    11\n",
       "7.7500     10\n",
       "26.5500     7\n",
       "10.5000     7\n",
       "           ..\n",
       "7.1417      1\n",
       "16.7000     1\n",
       "37.0042     1\n",
       "78.2667     1\n",
       "14.4542     1\n",
       "Name: Fare, Length: 139, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survive['Fare'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title transformation (proportion) [Replaced by general proportion transformation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Capt.': 0.0,\n",
       " 'Col.': 0.0,\n",
       " 'Don.': 0.0,\n",
       " 'Dr.': 0.42857142857142855,\n",
       " 'Lady.': 1.0,\n",
       " 'Major.': 1.0,\n",
       " 'Master.': 0.5517241379310345,\n",
       " 'Miss.': 0.695364238410596,\n",
       " 'Mlle.': 1.0,\n",
       " 'Mme.': 1.0,\n",
       " 'Mr.': 0.15403422982885084,\n",
       " 'Mrs.': 0.8061224489795918,\n",
       " 'Ms.': 1.0,\n",
       " 'Rev.': 0.0,\n",
       " 'Sir.': 1.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = (['Mr.', 'Mrs.', 'Miss.', 'Master.', 'Mlle.', 'Dr.', 'Mme.', 'Rev.',\n",
    "       'Sir.', 'Col.', 'Lady.', 'Major.', 'Ms.', 'Don.', 'Capt.'])\n",
    "# title_surv_rate = {'Sir.':1, 'Major.':1, 'Mme.':1, 'Lady.':1, 'Ms.':1, 'Mlle.':1, # All survive\n",
    "                   # 'Miss.':105/151, 'Mrs.':79/98, 'Mr.':63/409, 'Master.':16/29, 'Dr.':3/7, # Some survive\n",
    "                   # 'Rev.':0, 'Capt.':0, 'Col.':0, 'Don.':0} # None survive\n",
    "title_tot = cleaned.Title.value_counts()\n",
    "title_surv = cleaned[cleaned['Survived']==1]['Title'].value_counts()\n",
    "title_surv_rate = dict((title_surv / title_tot).replace(np.nan, 0))\n",
    "title_surv_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Proportion Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original function\n",
    "def prop_func(col):\n",
    "    tot = cleaned[col].value_counts()\n",
    "    surv = cleaned[cleaned['Survived']==1][col].value_counts()\n",
    "    surv_rate = dict((surv / tot).replace(np.nan, 0))\n",
    "    return cleaned[col].replace(surv_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = titanic.copy()\n",
    "title = cleaned['Name'].apply(strip_call)\n",
    "cleaned = cleaned.assign(Title=title) # Assign a title column\n",
    "surv, col = cleaned['Survived'], cleaned['Title']\n",
    "# Proportion Transformation\n",
    "def prop_func(surv, col):\n",
    "    tot = col.value_counts()\n",
    "    surv = col[surv==1].value_counts()\n",
    "    surv_rate = dict((surv / tot).replace(np.nan, 0))\n",
    "    return col.replace(surv_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.154034\n",
       "1      0.806122\n",
       "2      0.154034\n",
       "3      0.154034\n",
       "4      0.695364\n",
       "         ...   \n",
       "705    0.154034\n",
       "706    0.154034\n",
       "707    0.806122\n",
       "708    0.154034\n",
       "709    0.806122\n",
       "Name: Title, Length: 710, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_func(surv, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prop by survival (not supposed to do this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class PropByColumn(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        # try:\n",
    "            # getattr(self, \"grps_\")\n",
    "        # except AttributeError:\n",
    "            # raise RuntimeError(\"You must fit the transformer before tranforming the data!\")\n",
    "\n",
    "        # print(X.columns)\n",
    "        def prop_func(col):\n",
    "            tot = X[col].value_counts()\n",
    "            surv = X[X['Survived']==1][col].value_counts()\n",
    "            surv_rate = dict((surv / tot).replace(np.nan, 0))\n",
    "            return X[col].replace(surv_rate)\n",
    "        \n",
    "        cols = []\n",
    "        for col in X.drop('Survived', axis=1).columns:\n",
    "            cols.append(prop_func(col))\n",
    "        return pd.DataFrame(cols).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prop by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class PropByColumn(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        # try:\n",
    "            # getattr(self, \"grps_\")\n",
    "        # except AttributeError:\n",
    "            # raise RuntimeError(\"You must fit the transformer before tranforming the data!\")\n",
    "\n",
    "        # print(X.columns)\n",
    "        X = pd.DataFrame(X)\n",
    "        \n",
    "        X = X.rename(columns={X.columns[0]:'col1'}) # Rename col name to be consistent\n",
    "        props = []\n",
    "        for col in X.drop('col1', axis=1).columns:\n",
    "            rate = X[col].value_counts(normalize=True)\n",
    "            surv_rate = dict(rate.replace(np.nan, 0))\n",
    "            prop = X[col].replace(surv_rate)#(X[col] / X.groupby('col1')[col].transform('count'))\n",
    "            props.append(prop)\n",
    "        return pd.DataFrame(data=props).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.209859</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.640845</td>\n",
       "      <td>0.026761</td>\n",
       "      <td>0.671831</td>\n",
       "      <td>0.764789</td>\n",
       "      <td>0.047887</td>\n",
       "      <td>0.576056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.359155</td>\n",
       "      <td>0.032394</td>\n",
       "      <td>0.671831</td>\n",
       "      <td>0.130986</td>\n",
       "      <td>0.005634</td>\n",
       "      <td>0.138028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.640845</td>\n",
       "      <td>0.039437</td>\n",
       "      <td>0.671831</td>\n",
       "      <td>0.764789</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>0.576056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.640845</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.671831</td>\n",
       "      <td>0.764789</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.576056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.359155</td>\n",
       "      <td>0.047887</td>\n",
       "      <td>0.671831</td>\n",
       "      <td>0.764789</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.212676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.640845</td>\n",
       "      <td>0.038028</td>\n",
       "      <td>0.671831</td>\n",
       "      <td>0.764789</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.576056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>0.209859</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.640845</td>\n",
       "      <td>0.011268</td>\n",
       "      <td>0.240845</td>\n",
       "      <td>0.764789</td>\n",
       "      <td>0.032394</td>\n",
       "      <td>0.576056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>0.209859</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.359155</td>\n",
       "      <td>0.040845</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>0.005634</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.138028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.640845</td>\n",
       "      <td>0.039437</td>\n",
       "      <td>0.671831</td>\n",
       "      <td>0.764789</td>\n",
       "      <td>0.019718</td>\n",
       "      <td>0.576056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.240845</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.359155</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>0.240845</td>\n",
       "      <td>0.764789</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.138028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>710 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pclass      Name       Sex       Age  Siblings/Spouses Aboard  \\\n",
       "0    0.209859  0.001408  0.640845  0.026761                 0.671831   \n",
       "1    0.549296  0.001408  0.359155  0.032394                 0.671831   \n",
       "2    0.549296  0.001408  0.640845  0.039437                 0.671831   \n",
       "3    0.549296  0.001408  0.640845  0.028169                 0.671831   \n",
       "4    0.549296  0.001408  0.359155  0.047887                 0.671831   \n",
       "..        ...       ...       ...       ...                      ...   \n",
       "705  0.549296  0.001408  0.640845  0.038028                 0.671831   \n",
       "706  0.209859  0.001408  0.640845  0.011268                 0.240845   \n",
       "707  0.209859  0.001408  0.359155  0.040845                 0.035211   \n",
       "708  0.549296  0.001408  0.640845  0.039437                 0.671831   \n",
       "709  0.240845  0.001408  0.359155  0.021127                 0.240845   \n",
       "\n",
       "     Parents/Children Aboard      Fare     Title  \n",
       "0                   0.764789  0.047887  0.576056  \n",
       "1                   0.130986  0.005634  0.138028  \n",
       "2                   0.764789  0.008451  0.576056  \n",
       "3                   0.764789  0.014085  0.576056  \n",
       "4                   0.764789  0.001408  0.212676  \n",
       "..                       ...       ...       ...  \n",
       "705                 0.764789  0.016901  0.576056  \n",
       "706                 0.764789  0.032394  0.576056  \n",
       "707                 0.005634  0.001408  0.138028  \n",
       "708                 0.764789  0.019718  0.576056  \n",
       "709                 0.764789  0.002817  0.138028  \n",
       "\n",
       "[710 rows x 8 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cleaned.copy()\n",
    "std = PropByColumn().fit(X)\n",
    "out = std.transform(X)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score # \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# poly = PolynomialFeatures(interaction_only=True, include_bias=False) # create\n",
    "# features = pd.DataFrame(poly.fit_transform(regdata), columns=poly.get_feature_names(regdata.columns))\n",
    "# sklearn_answer = features.loc[:,~features.columns.isin(['carat', 'x', 'y', 'z', 'depth', 'table'])]\n",
    "# sklearn_answer.sample(5)\n",
    "#cleaned = titanic.copy()\n",
    "# title = cleaned['Name'].apply(strip_call)\n",
    "# cleaned = cleaned.assign(Title=title).drop(columns='Name')\n",
    "# cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.34"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class PropByColumn(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        # try:\n",
    "            # getattr(self, \"grps_\")\n",
    "        # except AttributeError:\n",
    "            # raise RuntimeError(\"You must fit the transformer before tranforming the data!\")\n",
    "\n",
    "        # print(X.columns)\n",
    "        X = pd.DataFrame(X)\n",
    "        \n",
    "        X = X.rename(columns={X.columns[0]:'col1'}) # Rename col name to be consistent\n",
    "        props = []\n",
    "        for col in X.drop('col1', axis=1).columns:\n",
    "            rate = X[col].value_counts(normalize=True)\n",
    "            surv_rate = dict(rate.replace(np.nan, 0))\n",
    "            prop = X[col].replace(surv_rate)#(X[col] / X.groupby('col1')[col].transform('count'))\n",
    "            props.append(prop)\n",
    "        return pd.DataFrame(data=props).T\n",
    "\n",
    "def strip_call(df):\n",
    "    name = df['Name'].apply(lambda x: x.split('.'))[0]\n",
    "    name = name.replace(['Lady', 'Sir'], 'Royal')\n",
    "    name = name.replace(['Mlle', 'Ms'], 'Miss')\n",
    "    name = name.replace(['Mme'], 'Miss')\n",
    "    return name\n",
    "\n",
    "def ffare(fare):\n",
    "    df_fare = pd.DataFrame(fare)\n",
    "    series = pd.qcut(df_fare.iloc[:,0], 5, labels = [1, 2, 3, 4, 5])\n",
    "    return np.array(series.to_frame())\n",
    "\n",
    "def aage(age):\n",
    "    df_age = pd.DataFrame(age)\n",
    "    bins = [0, 6, 12, 18, 25, 40, 60, np.inf]\n",
    "    lbs = [0, 1, 2, 3, 4, 5, 6]\n",
    "    series = pd.cut(df_age.iloc[:,0], bins, labels=lbs)\n",
    "    return np.array(series.to_frame())\n",
    "\n",
    "# Data Cleaning\n",
    "# cleaned = titanic.copy()\n",
    "# title = cleaned['Name'].apply(strip_call)\n",
    "# cleaned = cleaned.assign(Title=title) # Assign a title column\n",
    "\n",
    "# Train/Test set\n",
    "X = titanic.drop(['Survived'], axis=1)\n",
    "y = titanic.Survived\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Imputation\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# Proportion Transformation\n",
    "prop_trans = Pipeline(steps=[\n",
    "    ('prop', PropByColumn())\n",
    "])\n",
    "\n",
    "# Title Transformation\n",
    "name_func = FunctionTransformer(strip_call, validate=False)\n",
    "name_trans = Pipeline(steps=[\n",
    "    ('title', name_func),\n",
    "    ('prop', PropByColumn())\n",
    "])\n",
    "\n",
    "# Name ordinal encoder\n",
    "name_ordtrans = Pipeline(steps=[\n",
    "    ('title', name_func),\n",
    "    ('ordinal', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "# Fare transformation\n",
    "fare_func = FunctionTransformer(ffare, validate=False)\n",
    "fare_trans = Pipeline(steps=[\n",
    "    ('imputation', imp),\n",
    "    ('fare', fare_func)\n",
    "])\n",
    "\n",
    "# Age transformation\n",
    "age_func = FunctionTransformer(aage, validate=False)\n",
    "age_trans = Pipeline(steps=[\n",
    "    ('imputation', imp),\n",
    "    ('age', age_func)\n",
    "])\n",
    "\n",
    "# Log transformation\n",
    "log_func = FunctionTransformer(np.log)\n",
    "log_trans = Pipeline(steps=[\n",
    "    ('imputation', imp),\n",
    "    ('log', log_func)\n",
    "])\n",
    "\n",
    "# Standardization Transformation\n",
    "std_trans = Pipeline(steps=[\n",
    "    ('imputation', imp),\n",
    "    ('std', StdScalerByGroup())\n",
    "])\n",
    "\n",
    "# Polynomial Transformation\n",
    "poly_trans = Pipeline(steps=[\n",
    "    ('imputation', imp),\n",
    "    ('poly', PolynomialFeatures(interaction_only=True, include_bias=False))\n",
    "])\n",
    "\n",
    "# Proportion Polynomial Transformation\n",
    "prop_poly_trans = Pipeline(steps=[\n",
    "    ('imputation', imp),\n",
    "    ('prop', PropByColumn()), \n",
    "    ('poly', PolynomialFeatures(interaction_only=True, include_bias=False))\n",
    "])\n",
    "\n",
    "# Categorical transformation\n",
    "group_trans = Pipeline(steps=[\n",
    "    ('ordinal', OrdinalEncoder()),  \n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "# preprocessing pipeline (put them together)\n",
    "preproc = (ColumnTransformer(transformers=[\n",
    "    # ('prop_title', name_ordtrans, ['Name']),\n",
    "    ('prop_cont_class', prop_trans, ['Pclass', 'Age', 'Fare']),\n",
    "    ('prop_cat_class', prop_trans, ['Pclass', 'Sex', 'Siblings/Spouses Aboard', 'Parents/Children Aboard']),\n",
    "    ('prop_cont_sex', prop_trans, ['Sex', 'Age', 'Fare']),\n",
    "    ('prop_cat_sex', prop_trans, ['Sex', 'Pclass', 'Siblings/Spouses Aboard', 'Parents/Children Aboard']),\n",
    "    ('std_age_class', std_trans, ['Pclass', 'Age']),\n",
    "    # ('std_age_survive', std_trans, ['Survived', 'Age']),\n",
    "    # ('std_age_sibs', std_trans, ['Siblings/Spouses Aboard', 'Age']),\n",
    "    # ('std_age_chil', std_trans, ['Parents/Children Aboard', 'Age']),\n",
    "    # ('std_sibs', std_trans, ['Pclass', 'Siblings/Spouses Aboard']),\n",
    "    # ('std_chil', std_trans, ['Pclass', 'Parents/Children Aboard']),\n",
    "    ('std_fare_class', std_trans, ['Pclass', 'Fare']),\n",
    "    # ('std_fare_survive', std_trans, ['Survived', 'Fare']),\n",
    "    # ('std_fare_sibs', std_trans, ['Siblings/Spouses Aboard', 'Fare']),\n",
    "    # ('std_fare_chil', std_trans, ['Parents/Children Aboard', 'Fare']),\n",
    "    # ('poly', poly_trans, ['Pclass', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare']),\n",
    "    ('fare', fare_trans, ['Fare']),\n",
    "    ('age', age_trans, ['Age']),\n",
    "    ('poly', poly_trans, ['Age', 'Fare']),\n",
    "    ('log', log_trans, ['Age']),\n",
    "    ('prop_poly', prop_poly_trans, ['Pclass', 'Age', 'Fare']),\n",
    "    ('onehot', group_trans, ['Sex'])], remainder='drop'))\n",
    "\n",
    "pl = Pipeline(steps=[('preprocessor', preproc), ('regressor', GradientBoostingClassifier())])\n",
    "# pl = Pipeline(steps=[('regressor', LinearRegression())])\n",
    "pl.fit(X_train, y_train)\n",
    "# predic_4 = new_pl.predict(data.loc[:, ~data.columns.isin(['y'])])\n",
    "# scores_train = cross_val_score(pl, X, y, cv=5)\n",
    "# scores_train  # R^2\n",
    "y_pred = pl.predict(X_test)\n",
    "round(accuracy_score(y_pred, y_test) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regres(func, N):\n",
    "    scores = []\n",
    "    for _ in range(N):\n",
    "        class PropByColumn(BaseEstimator, TransformerMixin):\n",
    "\n",
    "            def __init__(self):\n",
    "                pass\n",
    "\n",
    "            def fit(self, X, y=None):\n",
    "\n",
    "                return self\n",
    "\n",
    "            def transform(self, X, y=None):\n",
    "\n",
    "                # try:\n",
    "                    # getattr(self, \"grps_\")\n",
    "                # except AttributeError:\n",
    "                    # raise RuntimeError(\"You must fit the transformer before tranforming the data!\")\n",
    "\n",
    "                # print(X.columns)\n",
    "                X = pd.DataFrame(X)\n",
    "\n",
    "                X = X.rename(columns={X.columns[0]:'col1'}) # Rename col name to be consistent\n",
    "                props = []\n",
    "                for col in X.drop('col1', axis=1).columns:\n",
    "                    rate = X[col].value_counts(normalize=True)\n",
    "                    surv_rate = dict(rate.replace(np.nan, 0))\n",
    "                    prop = X[col].replace(surv_rate)#(X[col] / X.groupby('col1')[col].transform('count'))\n",
    "                    props.append(prop)\n",
    "                return pd.DataFrame(data=props).T\n",
    "\n",
    "        def strip_call(df):\n",
    "            name = list(df['Name'].apply(lambda x: x.split('.')).values)\n",
    "            df_name = pd.DataFrame(name)\n",
    "            name = df_name.iloc[:,0]\n",
    "            name = name.replace(['Lady', 'Sir'], 'Royal')\n",
    "            name = name.replace(['Mlle', 'Ms'], 'Miss')\n",
    "            name = name.replace(['Mme'], 'Miss')\n",
    "            return np.array(name.to_frame())\n",
    "\n",
    "        def ffare(fare):\n",
    "            df_fare = pd.DataFrame(fare)\n",
    "            series = pd.qcut(df_fare.iloc[:,0], 5, labels = [1, 2, 3, 4, 5])\n",
    "            return np.array(series.to_frame())\n",
    "\n",
    "        def aage(age):\n",
    "            df_age = pd.DataFrame(age)\n",
    "            bins = [0, 6, 12, 18, 25, 40, 60, np.inf]\n",
    "            lbs = [0, 1, 2, 3, 4, 5, 6]\n",
    "            series = pd.cut(df_age.iloc[:,0], bins, labels=lbs)\n",
    "            return np.array(series.to_frame())\n",
    "\n",
    "        # Data Cleaning\n",
    "        # cleaned = titanic.copy()\n",
    "        # title = cleaned['Name'].apply(strip_call)\n",
    "        # cleaned = cleaned.assign(Title=title) # Assign a title column\n",
    "\n",
    "        # Train/Test set\n",
    "        X = titanic.drop(['Survived'], axis=1)\n",
    "        y = titanic.Survived\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "        # Imputation\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "        # Proportion Transformation\n",
    "        prop_trans = Pipeline(steps=[\n",
    "            ('prop', PropByColumn())\n",
    "        ])\n",
    "\n",
    "        # Name ordinal encoder\n",
    "        name_func = FunctionTransformer(strip_call, validate=False)\n",
    "        name_ordtrans = Pipeline(steps=[\n",
    "            ('title', name_func),\n",
    "            ('ordinal', OrdinalEncoder()), \n",
    "            ('onehot', OneHotEncoder(handle_unknown ='ignore'))\n",
    "        ])\n",
    "\n",
    "        # Fare transformation\n",
    "        fare_func = FunctionTransformer(ffare, validate=False)\n",
    "        fare_trans = Pipeline(steps=[\n",
    "            ('imputation', imp),\n",
    "            ('fare', fare_func)\n",
    "        ])\n",
    "\n",
    "        # Age transformation\n",
    "        age_func = FunctionTransformer(aage, validate=False)\n",
    "        age_trans = Pipeline(steps=[\n",
    "            ('imputation', imp),\n",
    "            ('age', age_func)\n",
    "        ])\n",
    "\n",
    "        # Log transformation\n",
    "        log_func = FunctionTransformer(np.log)\n",
    "        log_trans = Pipeline(steps=[\n",
    "            ('imputation', imp),\n",
    "            ('log', log_func)\n",
    "        ])\n",
    "\n",
    "        # Standardization Transformation\n",
    "        std_trans = Pipeline(steps=[\n",
    "            ('imputation', imp),\n",
    "            ('std', StdScalerByGroup())\n",
    "        ])\n",
    "\n",
    "        # Polynomial Transformation\n",
    "        poly_trans = Pipeline(steps=[\n",
    "            ('imputation', imp),\n",
    "            ('poly', PolynomialFeatures(interaction_only=True, include_bias=False))\n",
    "        ])\n",
    "\n",
    "        # Proportion Polynomial Transformation\n",
    "        prop_poly_trans = Pipeline(steps=[\n",
    "            ('imputation', imp),\n",
    "            ('prop', PropByColumn()), \n",
    "            ('poly', PolynomialFeatures(interaction_only=True, include_bias=False))\n",
    "        ])\n",
    "\n",
    "        # Categorical transformation\n",
    "        group_trans = Pipeline(steps=[\n",
    "            ('ordinal', OrdinalEncoder()),  \n",
    "            ('onehot', OneHotEncoder(handle_unknown ='ignore'))\n",
    "        ])\n",
    "\n",
    "\n",
    "        # preprocessing pipeline (put them together)\n",
    "        preproc = (ColumnTransformer(transformers=[\n",
    "            ('prop_title', name_ordtrans, ['Name']),\n",
    "            ('prop_cont_class', prop_trans, ['Pclass', 'Age', 'Fare']),\n",
    "            ('prop_cat_class', prop_trans, ['Pclass', 'Sex', 'Siblings/Spouses Aboard', 'Parents/Children Aboard']),\n",
    "            ('prop_cont_sex', prop_trans, ['Sex', 'Age', 'Fare']),\n",
    "            ('prop_cat_sex', prop_trans, ['Sex', 'Pclass', 'Siblings/Spouses Aboard', 'Parents/Children Aboard']),\n",
    "            ('std_age_class', std_trans, ['Pclass', 'Age']),\n",
    "            ('std_fare_class', std_trans, ['Pclass', 'Fare']),\n",
    "            ('fare', fare_trans, ['Fare']),\n",
    "            ('age', age_trans, ['Age']),\n",
    "            ('poly', poly_trans, ['Age', 'Fare']),\n",
    "            ('log', log_trans, ['Age']),\n",
    "            ('prop_poly', prop_poly_trans, ['Pclass', 'Age', 'Fare']),\n",
    "            ('onehot', group_trans, ['Sex'])], remainder='drop'))\n",
    "        \n",
    "        pl = Pipeline(steps=[('preprocessor', preproc), ('regressor', func)])\n",
    "        pl.fit(X_train, y_train)\n",
    "        y_pred = pl.predict(X_test)\n",
    "        score = round(accuracy_score(y_pred, y_test) * 100, 2)\n",
    "        scores.append(score)\n",
    "    return scores, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['Royal'] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-496-7d4ee87b7b31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mregres\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregres\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-495-99c6869caea8>\u001b[0m in \u001b[0;36mregres\u001b[1;34m(func, N)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;31m# scores_train = cross_val_score(pl, X, y, cv=5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# scores_train  # R^2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_feature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mXs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[1;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[0;32m    455\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[0;32m    456\u001b[0m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[1;32m--> 457\u001b[1;33m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[0m\u001b[0;32m    458\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"Expected 2D array, got 1D array instead\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m     \u001b[1;31m# if we have a weight for this transformer, multiply output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    645\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m         \"\"\"\n\u001b[1;32m--> 647\u001b[1;33m         \u001b[0mX_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX_int\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m    122\u001b[0m                     msg = (\"Found unknown categories {0} in column {1}\"\n\u001b[0;32m    123\u001b[0m                            \" during transform\".format(diff, i))\n\u001b[1;32m--> 124\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;31m# Set the problematic rows to an acceptable value and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found unknown categories ['Royal'] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "N=10\n",
    "\n",
    "regres(GradientBoostingClassifier(), N), regres(RandomForestClassifier(), N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_model(titanic):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'titanic.csv')\n",
    "    >>> data = pd.read_csv(fp)\n",
    "    >>> pl = titanic_model(data)\n",
    "    >>> isinstance(pl, Pipeline)\n",
    "    True\n",
    "    >>> from sklearn.base import BaseEstimator\n",
    "    >>> isinstance(pl.steps[-1][-1], BaseEstimator)\n",
    "    True\n",
    "    >>> preds = pl.predict(data.drop('Survived', axis=1))\n",
    "    >>> ((preds == 0)|(preds == 1)).all()\n",
    "    True\n",
    "    \"\"\"\n",
    "    class PropByColumn(BaseEstimator, TransformerMixin):\n",
    "\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "\n",
    "            return self\n",
    "\n",
    "        def transform(self, X, y=None):\n",
    "\n",
    "            # try:\n",
    "                # getattr(self, \"grps_\")\n",
    "            # except AttributeError:\n",
    "                # raise RuntimeError(\"You must fit the transformer before tranforming the data!\")\n",
    "\n",
    "            # print(X.columns)\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "            X = X.rename(columns={X.columns[0]:'col1'}) # Rename col name to be consistent\n",
    "            props = []\n",
    "            for col in X.drop('col1', axis=1).columns:\n",
    "                rate = X[col].value_counts(normalize=True)\n",
    "                surv_rate = dict(rate.replace(np.nan, 0))\n",
    "                prop = X[col].replace(surv_rate)#(X[col] / X.groupby('col1')[col].transform('count'))\n",
    "                props.append(prop)\n",
    "            return pd.DataFrame(data=props).T\n",
    "\n",
    "    def strip_call(df):\n",
    "        name = list(df['Name'].apply(lambda x: x.split('.')).values)\n",
    "        df_name = pd.DataFrame(name)\n",
    "        name = df_name.iloc[:,0]\n",
    "        name = name.replace(['Lady', 'Sir'], 'Royal')\n",
    "        name = name.replace(['Mlle', 'Ms'], 'Miss')\n",
    "        name = name.replace(['Mme'], 'Miss')\n",
    "        return np.array(name.to_frame())\n",
    "\n",
    "    def ffare(fare):\n",
    "        df_fare = pd.DataFrame(fare)\n",
    "        series = pd.qcut(df_fare.iloc[:,0], 5, labels = [1, 2, 3, 4, 5])\n",
    "        return np.array(series.to_frame())\n",
    "\n",
    "    def aage(age):\n",
    "        df_age = pd.DataFrame(age)\n",
    "        bins = [0, 6, 12, 18, 25, 40, 60, np.inf]\n",
    "        lbs = [0, 1, 2, 3, 4, 5, 6]\n",
    "        series = pd.cut(df_age.iloc[:,0], bins, labels=lbs)\n",
    "        return np.array(series.to_frame())\n",
    "\n",
    "    # Data Cleaning\n",
    "    # cleaned = titanic.copy()\n",
    "    # title = cleaned['Name'].apply(strip_call)\n",
    "    # cleaned = cleaned.assign(Title=title) # Assign a title column\n",
    "\n",
    "    # Train/Test set\n",
    "    X = titanic.drop(['Survived'], axis=1)\n",
    "    y = titanic.Survived\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    # Imputation\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "    # Proportion Transformation\n",
    "    prop_trans = Pipeline(steps=[\n",
    "        ('prop', PropByColumn())\n",
    "    ])\n",
    "\n",
    "    # Name ordinal encoder\n",
    "    name_func = FunctionTransformer(strip_call, validate=False)\n",
    "    name_ordtrans = Pipeline(steps=[\n",
    "        ('title', name_func),\n",
    "        ('ordinal', OrdinalEncoder()), \n",
    "        ('onehot', OneHotEncoder(handle_unknown ='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Fare transformation\n",
    "    fare_func = FunctionTransformer(ffare, validate=False)\n",
    "    fare_trans = Pipeline(steps=[\n",
    "        ('imputation', imp),\n",
    "        ('fare', fare_func)\n",
    "    ])\n",
    "\n",
    "    # Age transformation\n",
    "    age_func = FunctionTransformer(aage, validate=False)\n",
    "    age_trans = Pipeline(steps=[\n",
    "        ('imputation', imp),\n",
    "        ('age', age_func)\n",
    "    ])\n",
    "\n",
    "    # Log transformation\n",
    "    log_func = FunctionTransformer(np.log)\n",
    "    log_trans = Pipeline(steps=[\n",
    "        ('imputation', imp),\n",
    "        ('log', log_func)\n",
    "    ])\n",
    "\n",
    "    # Standardization Transformation\n",
    "    std_trans = Pipeline(steps=[\n",
    "        ('imputation', imp),\n",
    "        ('std', StdScalerByGroup())\n",
    "    ])\n",
    "\n",
    "    # Polynomial Transformation\n",
    "    poly_trans = Pipeline(steps=[\n",
    "        ('imputation', imp),\n",
    "        ('poly', PolynomialFeatures(interaction_only=True, include_bias=False))\n",
    "    ])\n",
    "\n",
    "    # Proportion Polynomial Transformation\n",
    "    prop_poly_trans = Pipeline(steps=[\n",
    "        ('imputation', imp),\n",
    "        ('prop', PropByColumn()), \n",
    "        ('poly', PolynomialFeatures(interaction_only=True, include_bias=False))\n",
    "    ])\n",
    "\n",
    "    # Categorical transformation\n",
    "    group_trans = Pipeline(steps=[\n",
    "        ('ordinal', OrdinalEncoder()),  \n",
    "        ('onehot', OneHotEncoder(handle_unknown ='ignore'))\n",
    "    ])\n",
    "\n",
    "\n",
    "    # preprocessing pipeline (put them together)\n",
    "    preproc = (ColumnTransformer(transformers=[\n",
    "        # ('prop_title', name_ordtrans, ['Name']),\n",
    "        ('prop_cont_class', prop_trans, ['Pclass', 'Age', 'Fare']),\n",
    "        ('prop_cat_class', prop_trans, ['Pclass', 'Sex', 'Siblings/Spouses Aboard', 'Parents/Children Aboard']),\n",
    "        ('prop_cont_sex', prop_trans, ['Sex', 'Age', 'Fare']),\n",
    "        ('prop_cat_sex', prop_trans, ['Sex', 'Pclass', 'Siblings/Spouses Aboard', 'Parents/Children Aboard']),\n",
    "        ('std_age_class', std_trans, ['Pclass', 'Age']),\n",
    "        ('std_fare_class', std_trans, ['Pclass', 'Fare']),\n",
    "        ('fare', fare_trans, ['Fare']),\n",
    "        ('age', age_trans, ['Age']),\n",
    "        ('poly', poly_trans, ['Age', 'Fare']),\n",
    "        ('log', log_trans, ['Age']),\n",
    "        ('prop_poly', prop_poly_trans, ['Pclass', 'Age', 'Fare']),\n",
    "        ('onehot', group_trans, ['Sex'])], remainder='drop'))\n",
    "    \n",
    "    pl = Pipeline(steps=[('preprocessor', preproc), ('regressor', GradientBoostingClassifier())])\n",
    "    # pl = Pipeline(steps=[('regressor', LinearRegression())])\n",
    "    pl.fit(X_train, y_train)\n",
    "    pl.fit(X, y)\n",
    "    # predic_4 = new_pl.predict(data.loc[:, ~data.columns.isin(['y'])])\n",
    "    # scores_train = cross_val_score(pl, X, y, cv=5)\n",
    "    # scores_train  # R^2\n",
    "    # y_pred = pl.predict(X_test)\n",
    "    # round(accuracy_score(y_pred, y_test) * 100, 2)\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'titanic.csv')\n",
    "data = pd.read_csv(fp)\n",
    "pl = titanic_model(data)\n",
    "isinstance(pl, Pipeline)\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "isinstance(pl.steps[-1][-1], BaseEstimator)\n",
    "preds = pl.predict(data.drop('Survived', axis=1))\n",
    "((preds == 0)|(preds == 1)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complicated version ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "cleaned = titanic.copy()\n",
    "title = cleaned['Name'].apply(strip_call)\n",
    "cleaned = cleaned.assign(Title=title) # Assign a title column\n",
    "\n",
    "# Find proportion dictionary\n",
    "def find_prop(col):\n",
    "    tot = cleaned[col].value_counts()\n",
    "    surv = cleaned[cleaned['Survived']==1][col].value_counts()\n",
    "    surv_rate = dict((surv / tot).replace(np.nan, 0))\n",
    "    return surv_rate\n",
    "title_surv_rate = find_prop('Title')\n",
    "pclass_surv_rate = find_prop('Pclass')\n",
    "sex_surv_rate = find_prop('Sex')\n",
    "age_surv_rate = find_prop('Age')\n",
    "sibs_surv_rate = find_prop('Siblings/Spouses Aboard')\n",
    "chil_surv_rate = find_prop('Parents/Children Aboard')\n",
    "fare_surv_rate = find_prop('Fare')\n",
    "\n",
    "# Train/Test set\n",
    "X = cleaned.drop(['Name'], axis=1)\n",
    "y = cleaned.Survived\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Title transformation\n",
    "# title_surv_rate = {'Sir.':1, 'Major.':1, 'Mme.':1, 'Lady.':1, 'Ms.':1, 'Mlle.':1, # All survive\n",
    "                   # 'Miss.':105/151, 'Mrs.':79/98, 'Mr.':63/409, 'Master.':16/29, 'Dr.':3/7, # Some survive\n",
    "                   # 'Rev.':0, 'Capt.':0, 'Col.':0, 'Don.':0} # None survive\n",
    "# title_tot = cleaned.Title.value_counts()\n",
    "# title_surv = cleaned[cleaned['Survived']==1]['Title'].value_counts()\n",
    "# title_surv_rate = dict((title_surv / title_tot).replace(np.nan, 0))\n",
    "# def title_func(resp): # Function to replace title with proportion\n",
    "    # return resp.replace(title_surv_rate)\n",
    "\n",
    "# Proportion Transformation\n",
    "# def prop_func(survival, col):\n",
    "    # tot = col.value_counts()\n",
    "    # surv = col[survival==1].value_counts()\n",
    "    # surv_rate = dict((surv / tot).replace(np.nan, 0))\n",
    "    # return col.replace(surv_rate)\n",
    "def prop_func(survival, col):\n",
    "    tot = col.value_counts()\n",
    "    surv = pd.Series(col[survival==1]).value_counts()\n",
    "    surv_rate = dict((surv / tot).replace(np.nan, 0))\n",
    "    return col.replace(surv_rate)\n",
    "prop_function = FunctionTransformer(prop_func)\n",
    "prop_trans = Pipeline(steps=[\n",
    "    ('prop', PropByColumn())\n",
    "])\n",
    "\n",
    "# PropByColumn\n",
    "    \n",
    "def title_func(col): # Function to replace title with proportion\n",
    "    # if col == 'Title':\n",
    "        # surv_rate = title_surv_rate\n",
    "    return col.replace(title_surv_rate)\n",
    "title_function = FunctionTransformer(title_func)\n",
    "title_trans = Pipeline(steps=[\n",
    "    ('prop', title_function)\n",
    "])\n",
    "\n",
    "def pclass_func(col): # Function to replace title with proportion\n",
    "    # if col == 'Title':\n",
    "        # surv_rate = title_surv_rate\n",
    "    return col.replace(pclass_surv_rate)\n",
    "pclass_function = FunctionTransformer(pclass_func)\n",
    "pclass_trans = Pipeline(steps=[\n",
    "    ('prop', pclass_function)\n",
    "])\n",
    "\n",
    "def sex_func(col): # Function to replace title with proportion\n",
    "    # if col == 'Title':\n",
    "        # surv_rate = title_surv_rate\n",
    "    return col.replace(sex_surv_rate)\n",
    "sex_function = FunctionTransformer(sex_func)\n",
    "sex_trans = Pipeline(steps=[\n",
    "    ('prop', sex_function)\n",
    "])\n",
    "\n",
    "def age_func(col): # Function to replace title with proportion\n",
    "    # if col == 'Title':\n",
    "        # surv_rate = title_surv_rate\n",
    "    return col.replace(age_surv_rate)\n",
    "age_function = FunctionTransformer(age_func)\n",
    "age_trans = Pipeline(steps=[\n",
    "    ('prop', age_function)\n",
    "])\n",
    "\n",
    "def sibs_func(col): # Function to replace title with proportion\n",
    "    # if col == 'Title':\n",
    "        # surv_rate = title_surv_rate\n",
    "    return col.replace(sibs_surv_rate)\n",
    "sibs_function = FunctionTransformer(sibs_func)\n",
    "sibs_trans = Pipeline(steps=[\n",
    "    ('prop', sibs_function)\n",
    "])\n",
    "\n",
    "def chil_func(col): # Function to replace title with proportion\n",
    "    # if col == 'Title':\n",
    "        # surv_rate = title_surv_rate\n",
    "    return col.replace(chil_surv_rate)\n",
    "chil_function = FunctionTransformer(chil_func)\n",
    "chil_trans = Pipeline(steps=[\n",
    "    ('prop', chil_function)\n",
    "])\n",
    "\n",
    "def fare_func(col): # Function to replace title with proportion\n",
    "    # if col == 'Title':\n",
    "        # surv_rate = title_surv_rate\n",
    "    return col.replace(fare_surv_rate)\n",
    "fare_function = FunctionTransformer(fare_func)\n",
    "fare_trans = Pipeline(steps=[\n",
    "    ('prop', fare_function)\n",
    "])\n",
    "\n",
    "# Log transformation\n",
    "log_func = FunctionTransformer(np.log)\n",
    "log_trans = Pipeline(steps=[\n",
    "    ('log', log_func)\n",
    "])\n",
    "\n",
    "# Standardization Transformation\n",
    "std_trans = Pipeline(steps=[\n",
    "    ('std', StdScalerByGroup())\n",
    "])\n",
    "\n",
    "# Polynomial Transformation\n",
    "poly_trans = Pipeline(steps=[\n",
    "    ('poly', PolynomialFeatures(interaction_only=True, include_bias=False))\n",
    "])\n",
    "\n",
    "# Proportion Polynomial Transformation\n",
    "prop_poly_trans = Pipeline(steps=[\n",
    "    ('prop', PropByColumn()), \n",
    "    ('poly', PolynomialFeatures(interaction_only=True, include_bias=False))\n",
    "])\n",
    "\n",
    "# Categorical transformation\n",
    "group_trans = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# preprocessing pipeline (put them together)\n",
    "preproc = (ColumnTransformer(transformers=[\n",
    "    #('prop_title', prop_trans, ['Title']),\n",
    "    #('prop_pclass', prop_trans, ['Survived', 'Pclass', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare']),\n",
    "    # ('prop_sex', sex_trans, ['Sex']),\n",
    "    # ('prop_age', age_trans, ['Age']),\n",
    "    # ('prop_sibs', sibs_trans, ['Siblings/Spouses Aboard']),\n",
    "    # ('prop_chil', chil_trans, ['Parents/Children Aboard']),\n",
    "    # ('prop_fare', fare_trans, ['Fare']),\n",
    "    ('std_age', std_trans, ['Pclass', 'Age']),\n",
    "    ('std_sibs', std_trans, ['Pclass', 'Siblings/Spouses Aboard']),\n",
    "    ('std_chil', std_trans, ['Pclass', 'Parents/Children Aboard']),\n",
    "    ('std_fare', std_trans, ['Pclass', 'Fare']),\n",
    "    ('poly', poly_trans, ['Pclass', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare']),\n",
    "    ('log', log_trans, ['Age']),\n",
    "    # ('prop_poly', prop_poly_trans, ['Title', 'Pclass', 'Sex', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare']),\n",
    "    ('onehot', group_trans, ['Sex'])], remainder='drop'))\n",
    "\n",
    "pl = Pipeline(steps=[('preprocessor', preproc), ('regressor', LinearRegression())])\n",
    "# pl = Pipeline(steps=[('regressor', LinearRegression())])\n",
    "# new_pl.fit(data.loc[:, ~data.columns.isin(['y'])], data['y'])\n",
    "# predic_4 = new_pl.predict(data.loc[:, ~data.columns.isin(['y'])])\n",
    "scores_train = cross_val_score(pl, X, y, cv=5)\n",
    "scores_train  # R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Amazon Review Rating Classification\n",
    "#### You won't be graded on this problem, but it is a good practice! \n",
    "\n",
    "\n",
    "One of the problems that we often solve in NLP is a classification problem: given a set of documents and their labels (spam/not spam, positive/negative etc), one needs to build a model that can predicts the correct label on a new document. In order to apply classifiers (like random forest or Naive Bayes) we need to transform the text into a (set of) feature vector(s). We already know one of the ways it can be done: using a `bag of words`. In short, you take the available words in a text and keep count when they appear. \n",
    "\n",
    "### Bigrams and Trigrams\n",
    "\n",
    "In this question, you will build features out of bigrams/trigrams in text-documents, and use these for prediction. You will develop a general approach to a text classification problem and then use different settings (text preprocessing, different classification algorithms etc) to improve the learning rates.\n",
    "\n",
    "* You are given a data file (`reviews.json`) that you will use to classify Amazon reviews. First you need to extract the text and the rating for each review; Also you need to clean each review before building a model: (convert everything to a lower-case and replace everything but letters, numbers and spaces with a space. In order to do that write a function `json_reader` that takes a file and the number of lines you want to read from the file. It returns two lists: one with cleaned reviews and another one with corresponding ratings (labels). \n",
    "\n",
    "* Now write a function `create_classifier_multi` that takes reviews and labels and returns a fit pipeline. You should reserve 20% of you training data for testing. Then set up a classifier using a Pipeline object such that it gives you the highest possible accuracy. Here is a trick: the accuracy is not known beforehand and you should try different classifiers and change their parameters, different pre-processing steps (for example: ngrams, stop words etc) in order to maximize the classifier's score. What is the highest value that you got? \n",
    "\n",
    "Do not be discouraged if you can't get a very high accuracy. Think why might it be the case? What if we do not use any algorithms and just assign labels to a new review randomly. What is the chance that you guessed the label correctly? Your accuracy does not seem that bad anymore, right? (If it is below a random assignment then change your code NOW).\n",
    "\n",
    "In general, a multi-class classification problem is not an easy task. \n",
    "\n",
    "* Next you will convert the multi-class classification to the binary classification problem. In order to do that you need to write a method `to_binary` that takes in a list of labels and replaces all 1, 2, 3 reviews with a 0 and 4, 5 reviews with the 1. Build the model again by using different classifiers and pre-processing steps, by writing `create_classifier_binary` method and returning a pipeline that maximized the accuracy. Do you see the improvement? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'reviews.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit the lab on Gradescope"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
