{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Project 01\n",
    "\n",
    "### Checkpoint Due Date: Thursday Jan 16, 11:59:59 PM (Questions 1-4)\n",
    "### Due Date: Thursday, Jan 23, 11:59:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Instructions\n",
    "\n",
    "This Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems.  \n",
    "* Like the lab, your coding work will be developed in the accompanying `project01.py` file, that will be imported into the current notebook. This code will be autograded.\n",
    "* **For the checkpoint, turn in questions 1-4**\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are **encouraged to write your own additional functions** to solve the questions! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `project01.py` -- however, be sure to upload these to gradescope as well!\n",
    "- Always document your code!\n",
    "\n",
    "**Tips for testing the correctness of your answers!**\n",
    "Once you have your work saved in the .py file, you should import the `project01` to test your function out in the notebook. In the notebook you should inspect/analyze the output to assess its correctness!\n",
    "* Run your functions on the main dataset (`grades`) and ask yourself if the output *looks correct.*\n",
    "* Run your functions on very small datasets (e.g. 1-5 row table), calculate the expected response by hand, and see if the function output matches (this *is* unit-testing your code with data).\n",
    "* Run your functions on (large and small) samples of the dataset `grades` (with and without replacement). Does your code break? Or does it still run as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project01 as proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Other Side of Gradescope\n",
    "\n",
    "The file contains the grade-book from a fictional data science course with 535 students. \n",
    "\n",
    "**Note: this dataset is synthetically generated; it does not contain real student grades.**\n",
    "\n",
    "In this project, you will:\n",
    "1. clean and process the data to compute total course grades according to a fictional syllabus (below),\n",
    "2. qualitatively understand how students did in the course,\n",
    "3. understand how student grades vary with small changes in performance on each assignment.\n",
    "\n",
    "---\n",
    "\n",
    "The course syllabus is as follows:\n",
    "\n",
    "* Lab assignments \n",
    "    - Each are worth the same amount, regardless of each lab's raw point total.\n",
    "    - The lowest lab is dropped.\n",
    "    - Each lab may be revised for one week after submission for a 10% penalty, for two weeks after submission for a 20% penalty, and beyond that for a 50% penalty. Such revisions are reflected in the `Lateness` columns in the gradebook.\n",
    "    - Labs are 20% of the total grade.\n",
    "* Projects \n",
    "    - Each project consists of an autograded portion, and *possibly* a free response portion.\n",
    "    - The total points for a single project consist of the sum of the raw score of the two portions.\n",
    "    - Each are worth the same amount, regardless of each project's raw point total.\n",
    "    - Projects are 30% of the total grade.\n",
    "* Checkpoints\n",
    "    - Project checkpoints are worth 2.5% of the total grade.\n",
    "* Discussion\n",
    "    - Discussion notebooks are worth 2.5% of the total grade.\n",
    "* Exams\n",
    "    - The midterm is worth 15% of the total grade.\n",
    "    - The final is worth 30% of the total grade.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on generalization\n",
    "\n",
    "You may assume that your code will only need to work on a gradebook for a class with the syllabus given above. That is, you may assume that the dataframe `grades` looks like the given one in `data/grades.csv`.\n",
    "\n",
    "However, such a class:\n",
    "1. may have a different numbers of labs, projects, discussions, and project checkpoints.\n",
    "2. may have a different number of students.\n",
    "\n",
    "You may assume the course components and the naming conventions are as given in the data file.\n",
    "\n",
    "The dataset was generated by Gradescope; you must attempt to reason about the data as given using what you know as a student who uses Gradescope.\n",
    "\n",
    "### A note on 'putting everything together'\n",
    "\n",
    "The goal of this project is to create and assess final grades for a fictional course; if anything, the process is broken down into functions for your convenience and guidance. Here are a few remarks and tips for approaching the projects:\n",
    "1. If you are having trouble figuring out what a question is asking you to do, look at the big picture and try to understand what the current step is doing to contribute to this big picture. This may clarify what's being asked!\n",
    "1. These questions intentionally build off of each other and the final result matters! In fact, you can 'get a question correct', but only receive partial credit on it because a previous answer was wrong.\n",
    "    - Credit for a question will typically receive partial credit based on *how close* your answer is to correct (as well as some credit for a solution in the correct form). \n",
    "    - You should try to assess your answer to each question based on what you understand of the data. This might involve writing extensive code (that isn't turned in) just to check your work! Suggestions on checking your work are given in the assignment, but you should also think of your own ways of checking your work.\n",
    "    - As you do this project, think about the data from the perspective of the student (which should be easy to do!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>College</th>\n",
       "      <th>Level</th>\n",
       "      <th>lab01</th>\n",
       "      <th>lab01 - Max Points</th>\n",
       "      <th>lab01 - Lateness (H:M:S)</th>\n",
       "      <th>lab02</th>\n",
       "      <th>lab02 - Max Points</th>\n",
       "      <th>lab02 - Lateness (H:M:S)</th>\n",
       "      <th>project01</th>\n",
       "      <th>...</th>\n",
       "      <th>discussion07 - Lateness (H:M:S)</th>\n",
       "      <th>discussion08</th>\n",
       "      <th>discussion08 - Max Points</th>\n",
       "      <th>discussion08 - Lateness (H:M:S)</th>\n",
       "      <th>discussion09</th>\n",
       "      <th>discussion09 - Max Points</th>\n",
       "      <th>discussion09 - Lateness (H:M:S)</th>\n",
       "      <th>discussion10</th>\n",
       "      <th>discussion10 - Max Points</th>\n",
       "      <th>discussion10 - Lateness (H:M:S)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A14721419</td>\n",
       "      <td>SI</td>\n",
       "      <td>JR</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>780:01:28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A14883274</td>\n",
       "      <td>TH</td>\n",
       "      <td>JR</td>\n",
       "      <td>98.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>669:12:21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14164800</td>\n",
       "      <td>SI</td>\n",
       "      <td>SR</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:04:51</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A14847419</td>\n",
       "      <td>TH</td>\n",
       "      <td>JR</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A14162943</td>\n",
       "      <td>SI</td>\n",
       "      <td>JR</td>\n",
       "      <td>66.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID College Level  lab01  lab01 - Max Points  \\\n",
       "0  A14721419      SI    JR   99.0               100.0   \n",
       "1  A14883274      TH    JR   98.0               100.0   \n",
       "2  A14164800      SI    SR   86.0               100.0   \n",
       "3  A14847419      TH    JR  100.0               100.0   \n",
       "4  A14162943      SI    JR   66.0               100.0   \n",
       "\n",
       "  lab01 - Lateness (H:M:S)  lab02  lab02 - Max Points  \\\n",
       "0                 00:00:00   86.0               100.0   \n",
       "1                 00:00:00   52.0               100.0   \n",
       "2                 00:00:00   45.0               100.0   \n",
       "3                 00:00:00  100.0               100.0   \n",
       "4                 00:00:00   33.0               100.0   \n",
       "\n",
       "  lab02 - Lateness (H:M:S)  project01               ...                 \\\n",
       "0                 00:00:00       75.0               ...                  \n",
       "1                 00:00:00       53.0               ...                  \n",
       "2                 00:00:00       44.0               ...                  \n",
       "3                 00:00:00       78.0               ...                  \n",
       "4                 00:00:00       42.0               ...                  \n",
       "\n",
       "   discussion07 - Lateness (H:M:S) discussion08  discussion08 - Max Points  \\\n",
       "0                         00:00:00         10.0                         10   \n",
       "1                        669:12:21          7.0                         10   \n",
       "2                         00:00:00          6.0                         10   \n",
       "3                         00:00:00         10.0                         10   \n",
       "4                         00:00:00          5.0                         10   \n",
       "\n",
       "   discussion08 - Lateness (H:M:S) discussion09  discussion09 - Max Points  \\\n",
       "0                         00:00:00         10.0                         10   \n",
       "1                         00:00:00          7.0                         10   \n",
       "2                         00:04:51          6.0                         10   \n",
       "3                         00:00:00         10.0                         10   \n",
       "4                         00:00:00          5.0                         10   \n",
       "\n",
       "   discussion09 - Lateness (H:M:S) discussion10  discussion10 - Max Points  \\\n",
       "0                        780:01:28         10.0                         10   \n",
       "1                         00:00:00          8.0                         10   \n",
       "2                         00:00:00          7.0                         10   \n",
       "3                         00:00:00         10.0                         10   \n",
       "4                         00:00:00          6.0                         10   \n",
       "\n",
       "   discussion10 - Lateness (H:M:S)  \n",
       "0                         00:00:00  \n",
       "1                         00:00:00  \n",
       "2                         00:00:00  \n",
       "3                         00:00:00  \n",
       "4                         00:00:00  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_fp = os.path.join('data', 'grades.csv')\n",
    "grades = pd.read_csv(grades_fp)\n",
    "grades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started: enumerating the assignments\n",
    "\n",
    "First, you will list all the 'assignment names' and what part of the syllabus to which they belong.\n",
    "\n",
    "**Question 1:**\n",
    "\n",
    "Create a function `get_assignment_names` that takes in a dataframe like `grades` and returns a dictionary with the following structure:\n",
    "- The keys are the general areas of the syllabus: `lab, project, midterm, final, disc, checkpoint`\n",
    "- The values are lists that contain the assignment names of that type. For example the lab assignments all have names of the form `labXX` where `XX` is a zero-padded two digit number. See the doctests for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract corresponding values from df\n",
    "def extract_values(df, pat):\n",
    "    \"\"\"\n",
    "    Extracts pat from df keys, and returns\n",
    "    a list of strings corresponding to pat\n",
    "    \n",
    "    :param df: dataframe to extract keys from\n",
    "    :param pat: pattern to fit\n",
    "    :return: a list of values corresponding to pat\n",
    "    \"\"\"\n",
    "    return list(df.columns[df.columns.str.contains(pat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lab': ['lab01', 'lab02', 'lab03', 'lab04', 'lab05', 'lab06', 'lab07', 'lab08', 'lab09'], 'project': ['project01', 'project02', 'project03', 'project04', 'project05'], 'midterm': ['Midterm'], 'final': ['Final'], 'disc': ['discussion01', 'discussion02', 'discussion03', 'discussion04', 'discussion05', 'discussion06', 'discussion07', 'discussion08', 'discussion09', 'discussion10'], 'checkpoint': ['project02_checkpoint01', 'project02_checkpoint02', 'project03_checkpoint01']}\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "try:\n",
    "    lab = extract_values(grades, '^lab[0-9]{2}$')\n",
    "    dic.update({'lab':lab})\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    project = extract_values(grades, '^project[0-9]{2}$')\n",
    "    dic.update({'project':project})\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    midterm = extract_values(grades, '^Midterm$')\n",
    "    dic.update({'midterm':midterm})\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    final = extract_values(grades, '^Final$')\n",
    "    dic.update({'final':final})\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    disc = extract_values(grades, '^discussion[0-9]{2}$')\n",
    "    dic.update({'disc':disc})\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    checkpoint = extract_values(grades, '^project[0-9]{2}_checkpoint[0-9]{2}$')\n",
    "    dic.update({'checkpoint':checkpoint})\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# print(lab, '\\n', project, '\\n', midterm, '\\n', final, '\\n', disc, '\\n', checkpoint)\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lab': ['lab01', 'lab02', 'lab03', 'lab04', 'lab05', 'lab06', 'lab07', 'lab08', 'lab09'], 'project': ['project01', 'project02', 'project03', 'project04', 'project05'], 'midterm': ['Midterm'], 'final': ['Final'], 'disc': ['discussion01', 'discussion02', 'discussion03', 'discussion04', 'discussion05', 'discussion06', 'discussion07', 'discussion08', 'discussion09', 'discussion10'], 'checkpoint': ['project02_checkpoint01', 'project02_checkpoint02', 'project03_checkpoint01']}\n"
     ]
    }
   ],
   "source": [
    "print(proj.get_assignment_names(grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing project grades\n",
    "\n",
    "**Question 2**\n",
    "\n",
    "Compute the total score for the project portion of the course according to the syllabus. Create a function `projects_total` that takes in `grades` and computes the total project grade for the quarter according to the syllabus. The output Series should contain values between 0 and 1.\n",
    "\n",
    "*Note*: Don't forget to properly handle students who didn't turn in assignments! (Use your experience and common sense).\n",
    "\n",
    "*Note:* To check your work, try (1) calculating the score for a few types of students by hand, and (2) calculate the statistics for the class performance on each individual course project, making sure they look reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grades.dtypes\n",
    "# grades['project05 - Lateness (H:M:S)'].unique()\n",
    "# grades.loc[514]\n",
    "# sample = grades\n",
    "# sample['project05_free_response'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grades[extract_values(grades, '^project[0-9]{2}')].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_mod = grades.fillna(0) # Fill NaN with 0, deep copy\n",
    "projects = extract_values(grades, '^project[0-9]{2}$') # Project scores\n",
    "# proj_max = extract_values(grades, '^project[0-9]{2} - Max Points$') # Project max points\n",
    "free_resp = extract_values(grades, '^project[0-9]{2}_free_response$') # Free response scores\n",
    "# free_resp_max = extract_values(grades, '^project[0-9]{2}_free_response - Max Points$') # Free response max points\n",
    "\n",
    "total = []\n",
    "for project in projects: # Loop through each project\n",
    "    if (project + '_free_response') in free_resp: # If project has free response\n",
    "        total.append((grades_mod[project] + grades_mod[project + '_free_response'])\n",
    "                     / (grades_mod[project + ' - Max Points'] + grades_mod[project + '_free_response - Max Points']))\n",
    "    else: # If does not have free response\n",
    "        total.append(grades_mod[project] / grades_mod[project + ' - Max Points'])\n",
    "\n",
    "tot_proj = pd.Series(np.sum(np.array(total) / len(projects), axis=0)) # Calculate total project score\n",
    "# tot_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.projects_total(grades).equals(tot_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = extract_values(grades, '^project[0-9]{2}$') # Project scores\n",
    "proj_max = extract_values(grades, '^project[0-9]{2} - Max Points$') # Project max points\n",
    "free_resp = extract_values(grades, '^project[0-9]{2}_free_response$') # Free response scores\n",
    "free_resp_max = extract_values(grades, '^project[0-9]{2}_free_response - Max Points$') # Free response max points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project01</th>\n",
       "      <th>project02</th>\n",
       "      <th>project03</th>\n",
       "      <th>project04</th>\n",
       "      <th>project05</th>\n",
       "      <th>project01 - Max Points</th>\n",
       "      <th>project02 - Max Points</th>\n",
       "      <th>project03 - Max Points</th>\n",
       "      <th>project04 - Max Points</th>\n",
       "      <th>project05 - Max Points</th>\n",
       "      <th>project01_free_response</th>\n",
       "      <th>project02_free_response</th>\n",
       "      <th>project05_free_response</th>\n",
       "      <th>project01_free_response - Max Points</th>\n",
       "      <th>project02_free_response - Max Points</th>\n",
       "      <th>project05_free_response - Max Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>53.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     project01  project02  project03  project04  project05  \\\n",
       "170       53.0       68.0       88.0       48.0       54.0   \n",
       "\n",
       "     project01 - Max Points  project02 - Max Points  project03 - Max Points  \\\n",
       "170                    85.0                    75.0                   100.0   \n",
       "\n",
       "     project04 - Max Points  project05 - Max Points  project01_free_response  \\\n",
       "170                      75                      75                      7.0   \n",
       "\n",
       "     project02_free_response  project05_free_response  \\\n",
       "170                     14.0                     13.0   \n",
       "\n",
       "     project01_free_response - Max Points  \\\n",
       "170                                  15.0   \n",
       "\n",
       "     project02_free_response - Max Points  \\\n",
       "170                                  25.0   \n",
       "\n",
       "     project05_free_response - Max Points  \n",
       "170                                    25  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades[projects + proj_max + free_resp + free_resp_max].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5753333333333333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_proj[449]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing lab grades\n",
    "\n",
    "Now, you will clean and process the lab grades, which is a little more complicated. To do this, you will develop functions that:\n",
    "- 'normalize' the grades, \n",
    "- adjust for late submissions, \n",
    "- drop the lowest lab grade, and \n",
    "- creates a total lab score for each student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Unfortunately, Gradescope sometimes experiences a delay in registering when an assignment is submitted during \"periods of heavy usage\" (i.e. near a submission deadline). You need to assess when a student's assignment was actually turned in on time, even if Gradescope did not process it in time. To do this, it is helpful to know:\n",
    "* Every late submission has to be submitted by a TA (late submissions are turned off).\n",
    "* TAs never submitted a late assignment \"just after\" the deadline. \n",
    "* The deadlines were at midnight and students had to come to staff hours to late-submit their assignment.\n",
    "\n",
    "Create a function `last_minute_submissions` that takes in the dataframe `grades` and outputs the number of submissions on each assignment that were turned in on time by the student, yet marked 'late' by Gradescope. See the doctest for more details.\n",
    "\n",
    "*Note:* You have to figure out what truly is a late submission by looking at the data and understanding the facts about the data generating process above. There is some ambiguity in finding which submissions are truly late; you will *make a best guess for a threshold* by looking at this dataset. This question is about 'cleaning' a messy 'data recording process'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab01 - Lateness (H:M:S)</th>\n",
       "      <th>lab02 - Lateness (H:M:S)</th>\n",
       "      <th>lab03 - Lateness (H:M:S)</th>\n",
       "      <th>lab04 - Lateness (H:M:S)</th>\n",
       "      <th>lab05 - Lateness (H:M:S)</th>\n",
       "      <th>lab06 - Lateness (H:M:S)</th>\n",
       "      <th>lab07 - Lateness (H:M:S)</th>\n",
       "      <th>lab08 - Lateness (H:M:S)</th>\n",
       "      <th>lab09 - Lateness (H:M:S)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>252:56:22</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>382:51:44</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>645:24:50</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>764:40:45</td>\n",
       "      <td>00:04:51</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>47:42:33</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lab01 - Lateness (H:M:S) lab02 - Lateness (H:M:S) lab03 - Lateness (H:M:S)  \\\n",
       "0                 00:00:00                 00:00:00                252:56:22   \n",
       "1                 00:00:00                 00:00:00                 00:00:00   \n",
       "2                 00:00:00                 00:00:00                 00:00:00   \n",
       "3                 00:00:00                 00:00:00                 00:00:00   \n",
       "4                 00:00:00                 00:00:00                 00:00:00   \n",
       "\n",
       "  lab04 - Lateness (H:M:S) lab05 - Lateness (H:M:S) lab06 - Lateness (H:M:S)  \\\n",
       "0                 00:00:00                 00:00:00                 00:00:00   \n",
       "1                 00:00:00                 00:00:00                645:24:50   \n",
       "2                 00:00:00                 00:00:00                764:40:45   \n",
       "3                 00:00:00                 00:00:00                 00:00:00   \n",
       "4                 47:42:33                 00:00:00                 00:00:00   \n",
       "\n",
       "  lab07 - Lateness (H:M:S) lab08 - Lateness (H:M:S) lab09 - Lateness (H:M:S)  \n",
       "0                382:51:44                 00:00:00                 00:00:00  \n",
       "1                 00:00:00                 00:00:00                 00:00:00  \n",
       "2                 00:04:51                 00:00:00                 00:00:00  \n",
       "3                 00:00:00                 00:00:00                 00:00:00  \n",
       "4                 00:00:00                 00:00:00                 00:00:00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades[extract_values(grades, '^lab[0-9]{2} - Lateness')].head() #.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract seconds from string\n",
    "def string_to_seconds(series):\n",
    "    \"\"\"\n",
    "    Converts string to seconds\n",
    "    \n",
    "    :param series: string to split by '：'\n",
    "    :return: seeconds corresponds to the string\n",
    "    \"\"\"\n",
    "    \n",
    "    lst = np.array(series.str.split(':')) # Split hour, minute, second by ':'\n",
    "    return np.array([int(elem[0]) * 3600 + int(elem[1]) * 60 + int(elem[2]) for elem in lst]) # Return seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string_to_seconds(grades['lab03 - Lateness (H:M:S)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lab01     2\n",
       "lab02     0\n",
       "lab03     2\n",
       "lab04    12\n",
       "lab05     7\n",
       "lab06     8\n",
       "lab07    16\n",
       "lab08    11\n",
       "lab09    26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 8 * 60 * 60 # 8 hrs\n",
    "lab_late = extract_values(grades, '^lab[0-9]{2} - Lateness') # Lab lateness columns\n",
    "grades_mod = grades[lab_late] # Dataframe containing lab lateness columns\n",
    "grades_mod = grades_mod.apply(string_to_seconds) # Submission later than threshold\n",
    "counts = np.sum(grades_mod[grades_mod > 0] < threshold, axis=0) # Number of late submission\n",
    "counts.index = counts.index.str.slice(0,5)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab = 'lab06'\n",
    "# np.count_nonzero(grades_mod[grades_mod[lab + ' - Lateness (H:M:S)'] != 0][lab + ' - Lateness (H:M:S)'] < 8 * 60 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.last_minute_submissions(grades).equals(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(counts, pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(counts.index == ['lab0%d' % d for d in range(1,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(counts > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Now you need to adjust the lab grades for late submissions -- however, you need to take into account your investigation in the previous question, since students shouldn't be penalized by a bug in Gradescope!\n",
    "\n",
    "Create a function `lateness_penalty` that takes in a 'Lateness' column and returns a column of penalties (represented by the values `1.0,0.9,0.8,0.5` according to the syllabus). Only *truly* late submissions should be counted as late.\n",
    "\n",
    "*Note*: For the purpose of this project, we will only be calculating lateness for labs. There is no penalty for lateness for projects, discussions, nor checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = grades['lab01 - Lateness (H:M:S)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty(late):\n",
    "    \"\"\"\n",
    "    Calculate penalty of true lateness\n",
    "    \n",
    "    :param late: time of lateness\n",
    "    :return: corresponding penalty\n",
    "    \"\"\"\n",
    "\n",
    "    threshold = 8 * 60 * 60 # 8 hrs\n",
    "    one_week = 7 * 24 * 60 * 60 # One week = 0.9\n",
    "    two_weeks = 14 * 24 * 60 * 60 # Two weeks = 0.8, Beyond = 0.5\n",
    "    \n",
    "    if late < threshold: # Submitted on time\n",
    "        return 1.0\n",
    "    elif late < one_week: # Within one week, 10%\n",
    "        return 0.9\n",
    "    elif late < two_weeks: # Within two weeks, 20%\n",
    "        return 0.8\n",
    "    else: # Two weeks and beyond, 50%\n",
    "        return 0.5\n",
    "\n",
    "penalty_v = np.vectorize(penalty)\n",
    "# penalty_v(string_to_seconds(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen = proj.lateness_penalty(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(pen, pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pen.unique()) <= {1.0, 0.9, 0.8, 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "Create a function `process_labs` that takes in a dataframe like `grades` and returns a dataframe of processed lab scores. The output should:\n",
    "* share the same index as `grades`,\n",
    "* have columns given by the lab assignment names (e.g. `lab01,...lab10`)\n",
    "* have values representing the lab grades for each assignment, adjusted for Lateness and scaled to a score between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediate works\n",
    "# Works, but some warnings provided\n",
    "# grades_mod[grades_mod < threshold] = 0 # Set fake lateness as submitted\n",
    "\n",
    "# Works, but redundant\n",
    "# grades_mod[lab_late] = grades_mod[lab_late].applymap(lambda val: val if pd.isnull(val) else (0 if val < threshold else val)) # Set fake lateness as submitted on time\n",
    "\n",
    "# Works, but some warnings provided\n",
    "# for lab in lab_score: # Loop through each lab\n",
    "    # grades_mod[lab + ' - Penalty'] = grades_mod[lab + ' - Lateness (H:M:S)'].apply(penalty)\n",
    "\n",
    "# Works, but too long\n",
    "# grades_mod[lab_late].applymap(lambda val: 1.0 if val < threshold else (0.9 if val < one_week else (0.8 if val < two_weeks else 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty(late):\n",
    "    \"\"\"\n",
    "    Calculate penalty of true lateness\n",
    "    \n",
    "    :param late: time of lateness\n",
    "    :return: corresponding penalty\n",
    "    \"\"\"\n",
    "\n",
    "    threshold = 8 * 60 * 60 # 8 hrs\n",
    "    one_week = 7 * 24 * 60 * 60 # One week = 0.9\n",
    "    two_weeks = 14 * 24 * 60 * 60 # Two weeks = 0.8, Beyond = 0.5\n",
    "    \n",
    "    if late < threshold: # Submitted on time\n",
    "        return 1.0\n",
    "    elif late < one_week: # Within one week, 10%\n",
    "        return 0.9\n",
    "    elif late < two_weeks: # Within two weeks, 20%\n",
    "        return 0.8\n",
    "    else: # Two weeks and beyond, 50%\n",
    "        return 0.5\n",
    "\n",
    "all_labs = extract_values(grades, '^lab[0-9]{2}') # All labs columns\n",
    "labs = extract_values(grades, '^lab[0-9]{2}$') # Labs columns\n",
    "lab_late = extract_values(grades, '^lab[0-9]{2} - Lateness') # Lab lateness columns\n",
    "grades_mod = grades[all_labs].fillna(0) # Fill NaN with 0, deep copy\n",
    "# grades_mod[lab_late] = grades_mod[lab_late].apply(string_to_seconds) # String to seconds\n",
    "# penalty = grades_mod[lab_late].applymap(penalty).rename(columns=lambda col: col[0:5] + ' - Penalty') # Create penalty columns\n",
    "\n",
    "penalty = grades_mod[lab_late].apply(proj.lateness_penalty).rename(columns=lambda col: col[0:5] + ' - Penalty') # Create penalty columns\n",
    "grades_mod = pd.concat([grades_mod, penalty], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab01</th>\n",
       "      <th>lab02</th>\n",
       "      <th>lab03</th>\n",
       "      <th>lab04</th>\n",
       "      <th>lab05</th>\n",
       "      <th>lab06</th>\n",
       "      <th>lab07</th>\n",
       "      <th>lab08</th>\n",
       "      <th>lab09</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.429412</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lab01  lab02  lab03  lab04     lab05     lab06  lab07  lab08  lab09\n",
       "0   0.99   0.86   0.72  0.980  1.000000  0.976471  0.485   0.88   0.86\n",
       "1   0.98   0.52   0.73  0.770  1.000000  0.500000  0.890   0.94   0.86\n",
       "2   0.86   0.45   0.40  0.730  0.900000  0.429412  0.720   0.71   0.76\n",
       "3   1.00   1.00   0.92  0.910  0.885714  0.670588  1.000   0.95   0.78\n",
       "4   0.66   0.33   0.69  0.729  0.642857  0.741176  0.600   0.36   1.00"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for lab in labs: # Loop through each lab\n",
    "    df[lab] = grades_mod[lab] * grades_mod[lab + ' - Penalty'] / grades_mod[lab + ' - Max Points']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab01</th>\n",
       "      <th>lab02</th>\n",
       "      <th>lab03</th>\n",
       "      <th>lab04</th>\n",
       "      <th>lab05</th>\n",
       "      <th>lab06</th>\n",
       "      <th>lab07</th>\n",
       "      <th>lab08</th>\n",
       "      <th>lab09</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.429412</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lab01  lab02  lab03  lab04     lab05     lab06  lab07  lab08  lab09\n",
       "0   0.99   0.86   0.72  0.980  1.000000  0.976471  0.485   0.88   0.86\n",
       "1   0.98   0.52   0.73  0.770  1.000000  0.500000  0.890   0.94   0.86\n",
       "2   0.86   0.45   0.40  0.730  0.900000  0.429412  0.720   0.71   0.76\n",
       "3   1.00   1.00   0.92  0.910  0.885714  0.670588  1.000   0.95   0.78\n",
       "4   0.66   0.33   0.69  0.729  0.642857  0.741176  0.600   0.36   1.00"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = proj.process_labs(grades)\n",
    "score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.equals(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.columns.tolist() == ['lab%02d' % x for x in range(1,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all((0.65 <= score.mean()) & (score.mean() <= 0.90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**\n",
    "\n",
    "Create a function `lab_total` that takes in dataframe of processed assignments (like the output of Question 5) and computes the total lab grade for each student according to the syllabus (returning a Series). Your answers should be proportions between 0 and 1. For example, if there are only 3 labs, and a student received scores of {80%,90%,100%}, then the total score would be 0.95.\n",
    "\n",
    "*Note*: Don't forget to properly handle students who didn't turn in assignments! (Use your experience and common sense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = score.copy()\n",
    "min_score = processed.min(axis=1)\n",
    "tot_lab = (np.sum(processed, axis=1) - min_score) / (len(processed.columns) - 1) # Calculate total lab score\n",
    "# tot_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.lab_total(score).equals(tot_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lab01</th>\n",
       "      <th>lab02</th>\n",
       "      <th>lab03</th>\n",
       "      <th>lab04</th>\n",
       "      <th>lab05</th>\n",
       "      <th>lab06</th>\n",
       "      <th>lab07</th>\n",
       "      <th>lab08</th>\n",
       "      <th>lab09</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lab01  lab02  lab03  lab04     lab05     lab06  lab07  lab08  lab09\n",
       "160   0.90   0.96   1.00  0.950  0.742857  0.941176   0.83  0.776   0.84\n",
       "278   0.99   1.00   0.85  0.819  0.985714  0.988235   0.94  0.960   0.96"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8035000000000001"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_lab[327]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it together\n",
    "\n",
    "**Question 7**\n",
    "\n",
    "Finally, you need to create the final course grades. To do this, you will add up the total of each course component according to the weights given in the syllabus. \n",
    "\n",
    "* Create a function `total_points` that takes in `grades` and returns the final course grades according to the syllabus. Course grades should be proportions between zero and one.\n",
    "* Create a function `final_grades` that takes in the final course grades as above and returns a Series of letter grades given by the standard cutoffs (`A >= .90`, `.90 > B >= .80`, `.80 > C >= .70`, `.70 > D >= .60`, `.60 > F`). You should not use rounding to determining the letter grades.\n",
    "* Create a function `letter_proportions` which takes in the dataframe `grades` and outputs a Series that contains the proportion of the class that received each grade. (This question requires you to put everything together).\n",
    "* The indices should be ordered by the proportion of the class that receives that grade, from largest to smallest.\n",
    "\n",
    "*Note 1*: Don't repeat yourself when computing the checkpoint and discussion portions of the course.\n",
    "\n",
    "*Note 2*: Only the lab portion of the course accounts for late assignments; you may assume all assignments in other portions are turned in without penalty.\n",
    "\n",
    "*Note 3*: These values should add up to exactly 1.0. If you are getting something close such as 0.99999, that means there is a slight issue with your code from above. \n",
    "\n",
    "To check your work, verify the course grade distribution and relevant statistics! Do the work by hand for a few students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - total_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab assignments 20%; Projects 30%; Checkpoints 2.5%; Discussion 2.5%; Midterm 15%; Final 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to calculate disc, checkpoint & exams scores\n",
    "def other_total(grades, name):\n",
    "    \"\"\"\n",
    "    Given the dataframe and the area name, calculate\n",
    "    the total grades for that area.\n",
    "    \n",
    "    :param grades: dataframe to process\n",
    "    :param name: area to process grades\n",
    "    :return: a Series of total area grades\n",
    "    \"\"\"\n",
    "    grades_mod = grades.fillna(0) # Fill NaN with 0, deep copy\n",
    "    names = proj.get_assignment_names(grades) # Get names\n",
    "    area = names.get(name) # Get cols of name\n",
    "    # max_pts = [ar + ' - Max Points' for ar in area] # Get cols of Max Points\n",
    "    # grades_mod = grades[area + max_pts] # Combined name & Max Points\n",
    "    df = pd.DataFrame()\n",
    "    for ar in area: # Loop through each name\n",
    "        df[ar] = grades[ar] / grades[ar + ' - Max Points']\n",
    "    total = (np.sum(df, axis=1)) / (len(df.columns)) # Calculate total score\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_tot = proj.lab_total(proj.process_labs(grades)) # Labs total\n",
    "proj_tot = proj.projects_total(grades) # Projects total\n",
    "chpt_tot = other_total(grades, 'checkpoint') # Checkpoints total\n",
    "disc_tot = other_total(grades, 'disc') # Discussions total\n",
    "mid = other_total(grades, 'midterm') # Midterm\n",
    "fin = other_total(grades, 'final') # Final\n",
    "total = lab_tot * 0.2 + proj_tot * 0.3 + chpt_tot * 0.025 + disc_tot * 0.025 + mid * 0.15 + fin * 0.3\n",
    "# total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.total_points(grades).equals(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all((0 <= total) & (total <= 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7 < total.mean() < 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - final_grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert scores to letter grades\n",
    "def score_to_grades(score):\n",
    "    \"\"\"\n",
    "    Given the total score of a student, calculate the \n",
    "    corresponding letter grade.\n",
    "    \n",
    "    :param score: total score to convert\n",
    "    :return: convert total score to letter grade\n",
    "    \"\"\"\n",
    "    \n",
    "    if score >= 0.90:\n",
    "        return 'A'\n",
    "    elif score >= 0.80:\n",
    "        return 'B'\n",
    "    elif score >= 0.70:\n",
    "        return 'C'\n",
    "    elif score >= 0.60:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.apply(score_to_grades).equals(proj.final_grades(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = proj.final_grades(pd.Series([0.92, 0.81, 0.41]))\n",
    "np.all(out == ['A', 'B', 'F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - letter_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    0.528972\n",
       "C    0.248598\n",
       "A    0.140187\n",
       "D    0.048598\n",
       "F    0.033645\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = proj.total_points(grades) # Calculate total scores\n",
    "letter = proj.final_grades(total) # Convert scores to grades\n",
    "result = letter.value_counts() / len(letter)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.equals(proj.letter_proportions(grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(result.index == ['B', 'C', 'A', 'D', 'F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sum() == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Sophomores get better grades?\n",
    "\n",
    "**Question 8**\n",
    "\n",
    "You notice that students who are sophomores on average did better in the class (if you can't verify this, you should go back and check your work!). Is this difference significant, or just due to noise?\n",
    "\n",
    "Perform a hypothesis test, assessing likelihood of the null hypothesis: \n",
    "> \"sophomores earn grades that are roughly equal on average to the rest of the class.\"\n",
    "\n",
    "\n",
    "Create a function `simulate_pval` which takes in the number of simulations `N` and `grades` and returns the the likelihood that the grade of sophomores was no better on average than the class as a whole (i.e. calculate the p-value).\n",
    "\n",
    "*Note:* To check your work, plot the sampling distribution and the observation. Do these values look reasonable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to ask!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if sophomores get higher average grades\n",
    "# total = proj.total_points(grades).rename('Score')\n",
    "# info_all = pd.concat([grades['Level'], total], axis=1)\n",
    "# info_m = info_all.groupby('Level').mean()\n",
    "# info_c = info_all.groupby('Level').count()\n",
    "# info_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutation single trial (Wrong way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = proj.total_points(grades).rename('Score') # Calculate total score\n",
    "# score = pd.concat([grades['Level'], total], axis=1) # Combine score and level\n",
    "# sopho_avg = np.mean(score['Score'][score['Level'] == 'SO']) # Sophomore average score\n",
    "# means = score.groupby(score['Level'].apply(lambda x: 'SO' == x)).mean()\n",
    "# means.index = means.index.map({False: 'Others', True:'SO'})\n",
    "# obs_diff = means.loc['SO', 'Score'] - means.loc['Others', 'Score']\n",
    "# means, obs_diff\n",
    "\n",
    "# shuffled = score.copy() # Deep copy of table\n",
    "# shuffled['Shuffled_score'] = np.random.permutation(score['Score']) # Put shuffled score in a table\n",
    "# group_means = shuffled.groupby(score['Level'].apply(lambda x: 'SO' == x)).mean()\n",
    "# group_means.index = group_means.index.map({False: 'Others', True:'SO'})\n",
    "# difference = group_means.loc['SO', 'Shuffled_score'] - group_means.loc['Others', 'Shuffled_score']\n",
    "\n",
    "# N = 1000\n",
    "\n",
    "# differences = []\n",
    "# for i in range(N):\n",
    "    # shuffled = score.copy() # Deep copy of table\n",
    "    # shuffled['Shuffled_score'] = np.random.permutation(score['Score']) # Put shuffled score in a table\n",
    "    # group_means = shuffled.groupby(score['Level'].apply(lambda x: 'SO' == x)).mean()\n",
    "    # group_means.index = group_means.index.map({False: 'Others', True:'SO'})\n",
    "    # difference = group_means.loc['SO', 'Shuffled_score'] - group_means.loc['Others', 'Shuffled_score']\n",
    "    # differences.append(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [0, 1] testing (Wrong way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs = info_m.loc['SO', 'Score']\n",
    "# num = info_c.loc['SO', 'Score']\n",
    "# prop = info_c.loc['SO', 'Score'] / info_all.shape[0]\n",
    "# obs, num, prop\n",
    "\n",
    "# N = 100000\n",
    "# simulations = []\n",
    "# for i in range(N):\n",
    "    # simulation = np.random.choice([0, 1], p=[1-prop, prop], size=num) # 0 is other (476), 1 is SO (59)\n",
    "    # sim_good = (simulation == 1).sum() / num\n",
    "    # simulations.append(sim_good)\n",
    "# pd.Series(simulations)\n",
    "\n",
    "# np.count_nonzero(simulations >= obs) / N\n",
    "\n",
    "# pd.Series(simulations).hist(bins = 10, alpha = 0.5)\n",
    "# plt.scatter(obs, 0, s=25, c='r', zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis Testing (Slow way) - 0.007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8441736462989888, 59, 0.1102803738317757)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obs = info_m.loc['SO', 'Score']\n",
    "# num = info_c.loc['SO', 'Score']\n",
    "# prop = info_c.loc['SO', 'Score'] / info_all.shape[0]\n",
    "# obs, num, prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 56.6 ms, total: 1min\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = 100000\n",
    "total = proj.total_points(grades).rename('Score')\n",
    "info_all = pd.concat([grades['Level'], total], axis=1)\n",
    "num = info_all['Level'].value_counts()['SO']\n",
    "\n",
    "simulations = []\n",
    "for i in range(N):\n",
    "    simulation = info_all.sample(num, replace=False)\n",
    "    sim = np.mean(simulation['Score'])\n",
    "    simulations.append(sim)\n",
    "# pd.Series(simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0757"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(simulations >= obs) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5ed5e50be0>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(simulations).hist(bins = 10, alpha = 0.5)\n",
    "plt.scatter(obs, 0, s=25, c='r', zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis Testing (Fast way) - 0.007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 14.6 ms, total: 15.2 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = proj.total_points(grades).rename('Score') # Final grade\n",
    "info_all = pd.concat([grades['Level'], total], axis=1) # Dataframe with grade & level\n",
    "num = info_all['Level'].value_counts()['SO'] # Number of Sophomore students\n",
    "obs = info_all.groupby('Level').mean().loc['SO', 'Score'] # Score of Sophomore students\n",
    "\n",
    "samps = []\n",
    "prop_distr = info_all['Score'].value_counts(normalize=True) # Construct simulation\n",
    "for i in range(N):\n",
    "    samp = np.random.choice(prop_distr.index, p=prop_distr, size=num, replace=False)\n",
    "    samps.append(samp.mean())\n",
    "\n",
    "# avgs = np.array(np.mean(samps)) # Calculate average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00715"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(samps >= obs) / N # Return p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5ecbde17b8>"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(samps).hist(bins = 10, alpha = 0.5)\n",
    "plt.scatter(obs, 0, s=25, c='r', zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis Testing (Fastest way) - 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 179 ms, sys: 3.02 ms, total: 182 ms\n",
      "Wall time: 178 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N=10000\n",
    "total = proj.total_points(grades).rename('Score')\n",
    "info_all = pd.concat([grades['Level'], total], axis=1)\n",
    "num = info_all['Level'].value_counts()['SO']\n",
    "obs = info_all.groupby('Level').mean().loc['SO', 'Score'] # Score of Sophomore students\n",
    "\n",
    "prop_distr = info_all['Score'].value_counts(normalize=True)\n",
    "samps = np.random.choice(\n",
    "    prop_distr.index, \n",
    "    p=prop_distr, \n",
    "    size=(N, num),\n",
    ")\n",
    "#samps.shape\n",
    "averages = samps.mean(axis=1)\n",
    "np.count_nonzero(averages >= obs) / N # Return p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5ed68f73c8>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(samps).hist(bins = 10, alpha = 0.5)\n",
    "plt.scatter(obs, 0, s=25, c='r', zorder=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "many = pd.concat([grades, grades, grades, grades], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.3 s, sys: 3.76 ms, total: 23.3 s\n",
      "Wall time: 23.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time proj.simulate_pval(many, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the true distribution of grades?\n",
    "\n",
    "The gradebook for this class only reflects one particular instance of each student's performance, subject to the effects of all the little events and hiccups that occurred throughout the quarter. Might you have done better on the midterm had your roommate kept you up all night with their coughing? Wasn't it lucky that the example you were studying just before the final happened to appear on the exam?\n",
    "\n",
    "**Question 9**\n",
    "\n",
    "This question will simulate these '(un)lucky, random events' by adding or subtracting random amounts to each assignment before calculating the final grades. These 'random amounts' will be drawn from a Gaussian distribution of mean 0 and a std deviation 0.02:\n",
    "```\n",
    "np.random.normal(0, 0.02, size=(num_rows, num_cols))\n",
    "```\n",
    "Intuitively, such a model says that random events may bump up or down a given grade (given as a proportion):\n",
    "- which on average has no effect on the class as a whole (mean 0),\n",
    "- which not uncommonly might perturb a grade by 2% (std dev 0.02).\n",
    "\n",
    "Create a function `total_points_with_noise` that takes in a dataframe like `grades`, adds noise to the assignments as described above, and returns the final scores using *the same procedure* as questions 1-7.\n",
    "\n",
    "*Note:* You should be able to reuse (or minorly change) the code from previous problems. Try to be DRY (don't repeat yourself)!\n",
    "\n",
    "*Note 1:* Once adding the noise to the assignment scores, use the `np.clip` function to be sure each assignment retains a score between 0% and 100%.\n",
    "\n",
    "*Note 2:* To check your work -- what would you expect the difference between the actual scores and noisy scores to be, on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slightly Wrong way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clip(name): # I am not using this actually, I am using np.clip!!!!!!!!!!!!!!!!!!!!\n",
    "    # a_max = grades_mod.loc[0, name + ' - Max Points']\n",
    "    # return np.clip(grades_mod[name], 0, a_max)\n",
    "\n",
    "# free_resp = extract_values(grades, '^project[0-9]{2}_free_response$') # Free response scores\n",
    "# names = list(proj.get_assignment_names(grades).values()) # Get usual cols of assignments\n",
    "# names.append(free_resp) # Combine the free response\n",
    "# names_flat = [elem for sub in names for elem in sub] # Flatten nested list to list\n",
    "# names_max = [elem + ' - Max Points' for elem in names_flat] # Max Points cols\n",
    "\n",
    "# grades_mod = grades.copy() # Deep copy\n",
    "# nrows, ncols = grades_mod[names_flat].shape[0], grades[names_flat].shape[1] # Get number of rows and cols\n",
    "# random_events = np.random.normal(0, 0.02, size=(nrows, ncols)) # Generate random event values\n",
    "# grades_mod[names_flat] = (grades_mod[names_flat] + random_events).clip(0, list(grades_mod.loc[0, names_max]), axis=1) # Calculate noisy score\n",
    "# grades_mod[names_flat] = np.clip((grades_mod[names_flat] + random_events), 0, list(grades_mod.loc[0, names_max])) # Calculate noisy score\n",
    "\n",
    "# proj.total_points(grades_mod).head()\n",
    "# rand_points = proj.total_points(grades_mod)\n",
    "# total_points = proj.total_points(grades)\n",
    "# (total_points - rand_points).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to ask!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project grades\n",
    "grades_mod = grades.fillna(0) # Fill NaN with 0, deep copy\n",
    "projects = extract_values(grades, '^project[0-9]{2}$') # Project scores\n",
    "free_resp = extract_values(grades, '^project[0-9]{2}_free_response$') # Free response scores\n",
    "\n",
    "# proj_total = []\n",
    "proj_tb = pd.DataFrame()\n",
    "for project in projects: # Loop through each project\n",
    "    if (project + '_free_response') in free_resp: # If project has free response\n",
    "        proj_tb[project] = pd.Series((grades_mod[project] + grades_mod[project + '_free_response'])\n",
    "                     / (grades_mod[project + ' - Max Points'] + grades_mod[project + '_free_response - Max Points']))\n",
    "    else: # If does not have free response\n",
    "        proj_tb[project] = pd.Series(grades_mod[project] / grades_mod[project + ' - Max Points'])\n",
    "\n",
    "# tot_proj = pd.Series(np.sum(np.array(proj_total) / len(projects), axis=0)) # Calculate total project score\n",
    "# tot_proj\n",
    "proj_f = np.clip(proj_tb + np.random.normal(0, 0.02, size=(proj_tb.shape[0], proj_tb.shape[1])), 0, 1)\n",
    "tot_proj = pd.Series(np.sum(proj_f, axis=1) / len(projects)) # Calculate total project score\n",
    "# tot_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab grades\n",
    "lab_tb = proj.process_labs(grades_mod)\n",
    "lab = np.clip(lab_tb + np.random.normal(0, 0.02, size=(lab_tb.shape[0], lab_tb.shape[1])), 0, 1)\n",
    "tot_lab = proj.lab_total(lab)\n",
    "# tot_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to calculate disc, checkpoint & exams scores\n",
    "def other_total_ran(grades, name):\n",
    "    \"\"\"\n",
    "    Given the dataframe and the area name, calculate\n",
    "    the total grades for that area.\n",
    "    \n",
    "    :param grades: dataframe to process\n",
    "    :param name: area to process grades\n",
    "    :return: a Series of total area grades\n",
    "    \"\"\"\n",
    "    names = proj.get_assignment_names(grades) # Get names\n",
    "    area = names.get(name) # Get cols of name\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for ar in area: # Loop through each name\n",
    "        df[ar] = grades[ar] / grades[ar + ' - Max Points']\n",
    "    \n",
    "    df_fin = np.clip(df + np.random.normal(0, 0.02, size=(df.shape[0], df.shape[1])), 0, 1)\n",
    "    \n",
    "    total = (np.sum(df_fin, axis=1)) / (len(df_fin.columns)) # Calculate total score\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab_tot = proj.lab_total(proj.process_labs(grades)) # Labs total\n",
    "# proj_tot = proj.projects_total(grades) # Projects total\n",
    "chpt_tot = other_total_ran(grades, 'checkpoint') # Checkpoints total\n",
    "disc_tot = other_total_ran(grades, 'disc') # Discussions total\n",
    "mid = other_total_ran(grades, 'midterm') # Midterm\n",
    "fin = other_total_ran(grades, 'final') # Final\n",
    "noise = tot_lab * 0.2 + tot_proj * 0.3 + chpt_tot * 0.025 + disc_tot * 0.025 + mid * 0.15 + fin * 0.3\n",
    "# noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.axes._subplots.AxesSubplot at 0x7f5ed3b05160>,\n",
       " 0.001869158878504673)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = proj.total_points(grades) - noise\n",
    "mean = ((temp >= 0.02) | (temp <= -0.02)).mean()\n",
    "temp.hist(), mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006859639075952756"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_p = proj.total_points_with_noise(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all((0 <= noise_p) & (noise_p <= 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7 < noise_p.mean() < 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short-answer questions (hard-coded)\n",
    "\n",
    "Use your functions from above to understanding the data and answer the following questions. The function below should return **hard-coded values**. It should not compute anything!\n",
    "\n",
    "**Question 10**\n",
    "\n",
    "Create a function `short_answer` of zero variables that returns (hard-coded) answers to the following question in a list:\n",
    "0. For the class on average, what is the difference between students' scores (`total_points`) and their scores with noise (`total_points_with_noise`)? (Remark: plot the distribution of differences; does this align with what you know about binomial distributions?)\n",
    "1. What percentage of the class only sees their grade change at most (but not including) $\\pm 0.01$?\n",
    "2. What is the 95% confidence interval for the statistic above? (see [DSC10](https://www.inferentialthinking.com/chapters/13/3/Confidence_Intervals.html) and use `np.percentile`)\n",
    "3. What proportion of the class sees a change in their letter grade?\n",
    "4. The assumption behind the model in Question 9 is that:\n",
    "    - The (observed) gradebook well represents the true population of students,\n",
    "    - The noisy scores represent other possible observations drawn from the true population of students.\n",
    "    - Answer `True` or `False`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to ask!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = proj.total_points(grades)\n",
    "# noise = proj.total_points_with_noise(grades)\n",
    "# noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_answer = [\n",
    "# Q0\n",
    "'The average difference between total_points and total_points_with_noise is 0.0037, which is close to 0.',\n",
    "\n",
    "# Q1\n",
    "85.42, \n",
    "\n",
    "# Q2\n",
    "[80.18691589, 86.1682243 ], \n",
    "\n",
    "# Q3\n",
    "36, \n",
    "\n",
    "# Q4\n",
    "True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5ed3c7ccc0>"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAV1klEQVR4nO3dbYxc51XA8f9J4jiQNTjF8WK5oZuqTlUriKZZFSMkmG0aZCpU50OwEqnFlQxWC0VQ+EBEJcSrFEA0KiISrGioi6CbUNrGilqhELIEqjrFbtK8qkmahODWylLVDt6gGIccPswlnTi7njuzM3N3nvn/JGvvvfM8M+fMHZ999rkvE5mJJGn8ndd0AJKkwbCgS1IhLOiSVAgLuiQVwoIuSYW4YJQvtmXLlpyZmem534svvsjFF188+IDGgLlPZu4w2fmb+2tzP3r06Lcz89JufUda0GdmZjhy5EjP/RYXF2m1WoMPaAyYe6vpMBozyfmbe+s12yLi3+v0dcpFkgphQZekQljQJakQI51Dl6T14pa7n3h1+SPXXtFgJIPjCF2SCmFBl6RCOOUiqWidUyt12ozz9IsjdEkqRNeCHhEXRcRXIuJrEfFoRPxOtf3yiLg/Ip6MiNsj4sLhhytJWk2dEfpp4F2Z+SPA24HdEbEL+EPglszcAZwA9g8vTElSN10LerYtV6sbqn8JvAv4TLX9IHDdUCKUJNVSaw49Is6PiAeBJeBu4BvAycx8uWpyDNg+nBAlSXVEL98pGhGbgc8BvwX8VWa+pdp+GfCFzPzhFfocAA4ATE9PX72wsNBzkMvLy0xNTfXcrwTmPpm5w2TnP8jcl06d7qn91k0bB/K6/Vop97m5uaOZOdutb0+nLWbmyYhYBHYBmyPigmqU/kbgW6v0mQfmAWZnZ7OfO6h557VW02E0YpJzh8nOf5C51zltsdPeVrOnLa4l9zpnuVxajcyJiO8B3g08DtwLXF812wfc2VcEkqSBqDNC3wYcjIjzaf8CuCMz74qIx4CFiPh94AHgE0OMU5LURdeCnpkPAVetsP1p4J3DCEqS1Dsv/Ze0LpVyOf4oeem/JBXCgi5JhXDKRdLYclrmtRyhS1IhLOiSVAinXCSpwzhP4zhCl6RCWNAlqRBOuUgqTq835CqFI3RJKoQFXZIKYUGXpEJY0CWpEBZ0SSqEZ7lIWvcm9ayVXjlCl6RCWNAlqRAWdEkqhAVdkgrR9aBoRFwGfAr4QeAVYD4zPx4RbwBuB2aAZ4G9mXlieKFK0uo8cFpvhP4y8OuZ+TZgF/BLEbETuAm4JzN3APdU65KkhnQt6Jl5PDO/Wi2fAh4HtgN7gINVs4PAdcMKUpLUXWRm/cYRM8B9wJXAc5m5ueOxE5l5yQp9DgAHAKanp69eWFjoOcjl5WWmpqZ67lcCc5/M3GEy8186dRqADa+c5sx5GxuOBrZuGn0MK+33ubm5o5k5261v7QuLImIK+HvgVzPzvyKiVr/MnAfmAWZnZ7PVatV9yVctLi7ST78SmHur6TAaM4n5//88+PaXnuGbF13ecDSwtzX6byxay36vdZZLRGygXcz/JjM/W21+PiK2VY9vA5b6ikCSNBBdC3q0h+KfAB7PzI91PHQI2Fct7wPuHHx4kqS66ky5/DjwfuDhiHiw2vabwM3AHRGxH3gO+NnhhChJqqNrQc/MfwVWmzC/ZrDhSJL65d0WJY1c50VAH7l29AceS+Wl/5JUCAu6JBXCKRdJWsW4TQ05QpekQljQJakQTrlIapS3vR0cR+iSVAhH6JJ61uvBQkfho+EIXZIKYUGXpEJY0CWpEBZ0SSqEBV2SCuFZLpJUwzjcBsARuiQVwoIuSYWwoEtSISzoklQIC7okFaLrWS4RcRvwM8BSZl5ZbXsDcDswAzwL7M3ME8MLU9KorOU+LZ3tvX/L6NUZoX8S2H3WtpuAezJzB3BPtS5JalDXgp6Z9wHfOWvzHuBgtXwQuG7AcUmSehSZ2b1RxAxwV8eUy8nM3Nzx+InMvGSVvgeAAwDT09NXLyws9Bzk8vIyU1NTPfcrgblPZu7QXP5Lp06/urx108aubTp1tl+tTR0bXjnNmfNWfu31YLX3ZRBW2u9zc3NHM3O2W9+hXymamfPAPMDs7Gy2Wq2en2NxcZF++pXA3FtNh9GYpvLvnPve21p5Dn21+fHO9muZQ9/+0jN886LL++4/bKu9L4Owlv3e71kuz0fENoDq51KfzyNJGpB+R+iHgH3AzdXPOwcWkaR1w28mGi9dR+gR8Wngy8BbI+JYROynXcivjYgngWurdUlSg7qO0DPzxlUeumbAsZzTONzpTJKa5JWiklQIC7okFcIvuJAmlNOY/Vvt4G/T76MjdEkqhAVdkgrhlIukWuePe475+ucIXZIKYUGXpEI45SJNEKdNyuYIXZIKYUGXpEI45SJJA9L0xVqO0CWpEBZ0SSqEUy5S4TyzZXI4QpekQjhCl/rQz8Gv1fo0fSBNw9HEfnWELkmFsKBLUiHWNOUSEbuBjwPnA3+ZmX5ZtNadYf/pe67nX+2A5FoOVNbp69TNZOp7hB4R5wO3Aj8N7ARujIidgwpMktSbtUy5vBN4KjOfzsz/ARaAPYMJS5LUq8jM/jpGXA/szsyfr9bfD/xoZn74rHYHgAPV6luBr/fxcluAb/cV6Pgz98k1yfmb+2u9KTMv7dZxLXPoscK21/12yMx5YH4Nr0NEHMnM2bU8x7gy98nMHSY7f3PvL/e1TLkcAy7rWH8j8K01PJ8kaQ3WUtD/DdgREZdHxIXADcChwYQlSepV31MumflyRHwY+Afapy3elpmPDiyy11rTlM2YM/fJNcn5m3sf+j4oKklaX7xSVJIKYUGXpEKsq4IeEbsj4usR8VRE3LTC4xsj4vbq8fsjYmb0UQ5Hjdx/LSIei4iHIuKeiHhTE3EOQ7fcO9pdHxEZEcWczlYn94jYW+37RyPib0cd47DU+Mz/UETcGxEPVJ/79zQR5zBExG0RsRQRj6zyeETEn1bvzUMR8Y5aT5yZ6+If7QOr3wDeDFwIfA3YeVabXwT+vFq+Abi96bhHmPsc8L3V8ocmKfeq3SbgPuAwMNt03CPc7zuAB4BLqvWtTcc9wtzngQ9VyzuBZ5uOe4D5/wTwDuCRVR5/D/BF2tf77ALur/O862mEXudWAnuAg9XyZ4BrImKlC5zGTdfcM/PezPzvavUw7fP+S1D3FhK/B/wR8NIogxuyOrn/AnBrZp4AyMylEcc4LHVyT+D7quXvp6DrXDLzPuA752iyB/hUth0GNkfEtm7Pu54K+nbgPzrWj1XbVmyTmS8DLwA/MJLohqtO7p320/7tXYKuuUfEVcBlmXnXKAMbgTr7/Qrgioj4UkQcru5wWoI6uf828L6IOAZ8Afjl0YS2LvRaE4D19Y1FdW4lUOt2A2Oodl4R8T5gFvjJoUY0OufMPSLOA24BPjCqgEaozn6/gPa0S4v2X2X/EhFXZubJIcc2bHVyvxH4ZGb+SUT8GPDXVe6vDD+8xvVV69bTCL3OrQRebRMRF9D+M+xcf7aMi1q3UYiIdwMfBd6bmadHFNuwdct9E3AlsBgRz9KeTzxUyIHRup/5OzPzTGY+Q/vmdjtGFN8w1cl9P3AHQGZ+GbiI9o2rJkFft1ZZTwW9zq0EDgH7quXrgX/K6gjCmOuaezXt8Be0i3kp86jQJffMfCEzt2TmTGbO0D5+8N7MPNJMuANV5zP/edoHxImILbSnYJ4eaZTDUSf354BrACLibbQL+n+ONMrmHAJ+rjrbZRfwQmYe79qr6aO9KxzZfYL20e+PVtt+l/Z/YGjv0L8DngK+Ary56ZhHmPs/As8DD1b/DjUd86hyP6vtIoWc5VJzvwfwMeAx4GHghqZjHmHuO4Ev0T4D5kHgp5qOeYC5fxo4DpyhPRrfD3wQ+GDHfr+1em8ervuZ99J/SSrEeppykSStgQVdkgphQZekQoz0PPQtW7bkzMxMX31ffPFFLr744sEGNCbM3dwnjbm/NvejR49+O4f8naI9m5mZ4ciR/s42W1xcpNVqDTagMWHurabDaIS5t5oOoxEr5R4R/16nr1MuklQIC7okFcKCLkmFWE8355Kkkbnl7ideXf7ItVc0GMngOEKXpEI4Qpc08UoZrTtCl6RCWNAlqRAWdEkqhAVdkgphQZekQljQJakQFnRJKoQFXZIKYUGXpEJ0LegRcVFEfCUivhYRj0bE71TbL4+I+yPiyYi4PSIuHH64kqTV1BmhnwbelZk/Arwd2B0Ru4A/BG7JzB3ACWD/8MKUJHXTtaBn23K1uqH6l8C7gM9U2w8C1w0lQklSLZGZ3RtFnA8cBd4C3Ar8MXA4M99SPX4Z8MXMvHKFvgeAAwDT09NXLyws9BXo8vIyU1NTffUdd+Zu7pPmXLkvnTr96vLWTRsH0qbTau1HZaXc5+bmjmbmbLe+te62mJn/C7w9IjYDnwPetlKzVfrOA/MAs7Oz2e/3BPodg62mw2iEubeaDqMR58q9886Ie1sr3xmx1zadVms/KmvZ7z2d5ZKZJ4FFYBewOSL+/xfCG4Fv9RWBJGkguo7QI+JS4ExmnoyI7wHeTfuA6L3A9cACsA+4c5iBSlI/SrnXeR11ply2AQerefTzgDsy866IeAxYiIjfBx4APjHEOCVJXXQt6Jn5EHDVCtufBt45jKAkSb3zK+gkTYzVDoSWwkv/JakQFnRJKoQFXZIKYUGXpEJ4UFSSOozzeeuO0CWpEBZ0SSqEBV2SCmFBl6RCWNAlqRAWdEkqhAVdkgphQZekQljQJakQXikqad0r/ba3g+IIXZIK0bWgR8RlEXFvRDweEY9GxK9U298QEXdHxJPVz0uGH64kaTV1plxeBn49M78aEZuAoxFxN/AB4J7MvDkibgJuAn5jeKFKmiS9TrM4LVNjhJ6ZxzPzq9XyKeBxYDuwBzhYNTsIXDesICVJ3fU0hx4RM7S/MPp+YDozj0O76ANbBx2cJKm+yMx6DSOmgH8G/iAzPxsRJzNzc8fjJzLzdfPoEXEAOAAwPT199cLCQl+BLi8vMzU11VffcWfu5l6ypVOnX7dtwyunOXPexq59t276bpuVnmetOp9/VFba73Nzc0czc7Zb31qnLUbEBuDvgb/JzM9Wm5+PiG2ZeTwitgFLK/XNzHlgHmB2djZbrVadl3ydxcVF+u077sy91XQYjZiU3Fea+97+0jN886LLu/bd2/ruF1AMYw698/lHZS37vWtBj4gAPgE8npkf63joELAPuLn6eWdfEUhSnzwQ+lp1Rug/DrwfeDgiHqy2/SbtQn5HROwHngN+djghSpLq6FrQM/NfgVjl4WsGG44kqV9e+i9Jqxi3L4z20n9JKoQFXZIKYUGXpEJY0CWpEB4UlaQaxuEAqSN0SSqEBV2SCuGUi6Se9Tr94CX6o+EIXZIKYUGXpEJY0CWpEBZ0SSqEBV2SCmFBl6RCWNAlqRAWdEkqRNeCHhG3RcRSRDzSse0NEXF3RDxZ/bxkuGFKkrqpc6XoJ4E/Az7Vse0m4J7MvDkibqrWf2Pw4UkatbVcBdrZ3qtDR6/rCD0z7wO+c9bmPcDBavkgcN2A45Ik9ajfOfTpzDwOUP3cOriQJEn9iMzs3ihiBrgrM6+s1k9m5uaOx09k5orz6BFxADgAMD09ffXCwkJfgS4vLzM1NdVX33Fn7uY+SkunTq+4feumjV3bDMqGV05z5ryN3Rs2pPO9GLSV9vvc3NzRzJzt1rffuy0+HxHbMvN4RGwDllZrmJnzwDzA7Oxstlqtvl5wcXGRfvuOO3NvNR1GI5rKfbW5772t0c2Pb3/pGb550eVDfY216HwvBm0t+73fgn4I2AfcXP28s8/nkbQOeACzDHVOW/w08GXgrRFxLCL20y7k10bEk8C11bokqUFdR+iZeeMqD10z4FgkSWswNleKLp06zS13P+GfhpK0irEp6JKkc/M7RSXV4l/H37Xae1HnytphcoQuSYWwoEtSISzoklQIC7okFcKCLkmF8CwXaUJ51kp5HKFLUiEcoUvSEPT6zU+D4AhdkgphQZekQljQJakQFnRJKoQFXZIK4VkuUk39nLXQxJkO54pBw9X0e+0IXZIKsaYRekTsBj4OnA/8ZWb63aJad0Y5Sj7XCK3X0dtVG7o/T2c+TY8O1by+R+gRcT5wK/DTwE7gxojYOajAJEm9WcuUyzuBpzLz6cz8H2AB2DOYsCRJvYrM7K9jxPXA7sz8+Wr9/cCPZuaHz2p3ADhQrb4V+HqfsW4Bvt1n33Fn7pPJ3CfTSrm/KTMv7dZxLXPoscK21/12yMx5YH4Nr9N+sYgjmTm71ucZR+Zu7pPG3PvLfS1TLseAyzrW3wh8aw3PJ0lag7UU9H8DdkTE5RFxIXADcGgwYUmSetX3lEtmvhwRHwb+gfZpi7dl5qMDi+z11jxtM8bMfTKZ+2TqO/e+D4pKktYXrxSVpEJY0CWpEOuuoEfE7oj4ekQ8FRE3rfD4xoi4vXr8/oiYGX2Uw1Ej91+LiMci4qGIuCci3tREnMPQLfeOdtdHREZEMae01ck9IvZW+/7RiPjbUcc4LDU+8z8UEfdGxAPV5/49TcQ5aBFxW0QsRcQjqzweEfGn1fvyUES8o9YTZ+a6+Uf74Oo3gDcDFwJfA3ae1eYXgT+vlm8Abm867hHmPgd8b7X8oUnKvWq3CbgPOAzMNh33CPf7DuAB4JJqfWvTcY8w93ngQ9XyTuDZpuMeUO4/AbwDeGSVx98DfJH29T67gPvrPO96G6HXuZ3AHuBgtfwZ4JqIWOkip3HTNffMvDcz/7taPUz73P8S1L2NxO8BfwS8NMrghqxO7r8A3JqZJwAyc2nEMQ5LndwT+L5q+fsp5FqXzLwP+M45muwBPpVth4HNEbGt2/Out4K+HfiPjvVj1bYV22Tmy8ALwA+MJLrhqpN7p/20f4OXoGvuEXEVcFlm3jXKwEagzn6/ArgiIr4UEYeru5yWoE7uvw28LyKOAV8Afnk0oTWu13oArL8vuKhzO4FatxwYQ7Xzioj3AbPATw41otE5Z+4RcR5wC/CBUQU0QnX2+wW0p11atP8q+5eIuDIzTw45tmGrk/uNwCcz808i4seAv65yf2X44TWqrzq33kbodW4n8GqbiLiA9p9h5/rTZVzUupVCRLwb+Cjw3sw8PaLYhq1b7puAK4HFiHiW9pzioUIOjNb9zN+ZmWcy8xnaN7jbMaL4hqlO7vuBOwAy88vARbRvXlW6vm6tst4Kep3bCRwC9lXL1wP/lNVRhDHXNfdq2uEvaBfzUuZRoUvumflCZm7JzJnMnKF9/OC9mXmkmXAHqs5n/vO0D4gTEVtoT8E8PdIoh6NO7s8B1wBExNtoF/T/HGmUzTgE/Fx1tssu4IXMPN61V9NHe1c5uvsE7aPfH622/S7t/8DQ3qF/BzwFfAV4c9MxjzD3fwSeBx6s/h1qOuZR5X5W20UKOcul5n4P4GPAY8DDwA1NxzzC3HcCX6J9BsyDwE81HfOA8v40cBw4Q3s0vh/4IPDBjn1+a/W+PFz38+6l/5JUiPU25SJJ6pMFXZIKYUGXpEJY0CWpEBZ0SSqEBV2SCmFBl6RC/B85GfLE8tnn+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Q0\n",
    "plt.subplot(2, 1, 1)\n",
    "pd.Series(noise).hist(bins = 100, alpha = 0.5)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "pd.Series(total).hist(bins = 100, alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.04672897196262"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "noise = proj.total_points_with_noise(grades)\n",
    "total = proj.total_points(grades)\n",
    "differences = (noise - total)\n",
    "# differences = np.array(total_points - rand_points) * 100 # Does the difference mean out of 100 score? If not then 100% will be within 0.01\n",
    "100 * np.count_nonzero(np.abs(differences) < 0.01) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 # Weird Ask!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "def bootstrap(sample, replications):\n",
    "    \n",
    "    \"\"\"Returns an array of bootstrapped sample medians:\n",
    "    original_sample: table containing the original sample\n",
    "    label: label of column containing the variable\n",
    "    replications: number of bootstrap samples\n",
    "    \"\"\"\n",
    "    \n",
    "    # just_one_column = original_sample[label]\n",
    "    differences = []\n",
    "    for i in range(replications):\n",
    "        bootstrap = proj.total_points_with_noise(grades)\n",
    "        resampled_stats = 100 * np.count_nonzero(np.abs(bootstrap - sample) < 0.01) / len(bootstrap) \n",
    "        differences.append(resampled_stats)\n",
    "        \n",
    "    return differences\n",
    "\n",
    "boot = bootstrap(total, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80.18691589, 86.35514019])"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(boot, [2.5, 97.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[77.00934579439253,\n",
       " 77.19626168224299,\n",
       " 77.38317757009345,\n",
       " 77.38317757009345,\n",
       " 77.38317757009345,\n",
       " 77.57009345794393,\n",
       " 77.75700934579439,\n",
       " 77.94392523364486,\n",
       " 77.94392523364486,\n",
       " 78.13084112149532,\n",
       " 78.3177570093458,\n",
       " 78.3177570093458,\n",
       " 78.3177570093458,\n",
       " 78.50467289719626,\n",
       " 78.50467289719626,\n",
       " 78.50467289719626,\n",
       " 78.50467289719626,\n",
       " 78.50467289719626,\n",
       " 78.69158878504673,\n",
       " 78.69158878504673,\n",
       " 78.69158878504673,\n",
       " 78.69158878504673,\n",
       " 78.69158878504673,\n",
       " 78.69158878504673,\n",
       " 78.69158878504673,\n",
       " 78.69158878504673,\n",
       " 78.69158878504673,\n",
       " 78.69158878504673,\n",
       " 78.69158878504673,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 78.8785046728972,\n",
       " 79.06542056074767,\n",
       " 79.06542056074767,\n",
       " 79.06542056074767,\n",
       " 79.06542056074767,\n",
       " 79.06542056074767,\n",
       " 79.06542056074767,\n",
       " 79.06542056074767,\n",
       " 79.06542056074767,\n",
       " 79.06542056074767,\n",
       " 79.06542056074767,\n",
       " 79.06542056074767,\n",
       " 79.06542056074767,\n",
       " 79.06542056074767,\n",
       " 79.06542056074767,\n",
       " 79.06542056074767,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.25233644859813,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.4392523364486,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.62616822429906,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 79.81308411214954,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.18691588785046,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.37383177570094,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.5607476635514,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.74766355140187,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 80.93457943925233,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.1214953271028,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " 81.30841121495327,\n",
       " ...]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot.sort()\n",
    "boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15514018691588785"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARcUlEQVR4nO3df4wcZ33H8fe3dpM4sYgdAlfXjnpGtWhDrj/IKU1LVa0JPwKhJFKDZBSBA0EnVKBpa6k4TaVUFZEcqpQfoj9kEYSRUC4hBcXCbcE12VIqJWCTFJOYYBPcYCe1i5K4vZBCr3z7x43hetnDezuzt7fPvV/SaXefeeaZ7zP2fjw3np2NzESSVJafGnQBkqTmGe6SVCDDXZIKZLhLUoEMd0kq0MpBFwBw4YUX5ujoaKNjPvvss5x33nmNjjlslvs+cP7Ov/T5Hzhw4LuZ+aJOy5ZEuI+OjrJ///5Gx2y327RarUbHHDbLfR84f+df+vwj4t/mW+ZpGUkqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKtCS+ISqdCaj2/cseJ1tY9Nc38N6cx3dcVXtMaTF5pG7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAKdMdwj4mMRcTIivj6r7c8j4hsR8bWI+ExErJm17KaIOBIRj0bEa/tVuCRpft0cuX8cuHJO217gksz8JeCbwE0AEXExsAV4WbXOX0XEisaqlSR15YzhnplfBJ6a0/b5zJyuXt4PbKieXw1MZub3M/PbwBHgsgbrlSR1oYm7Qr4duKt6vp6ZsD/tWNX2PBExAUwAjIyM0G63Gyjlx6amphofc9j0Yx8cPH6q0fG6tW1s4euMrJq5M2Rdw/r3aLm/B5b7/GuFe0TcDEwDnzzd1KFbdlo3M3cCOwHGx8ez1WrVKeV52u02TY85bPqxD5q4he5i2TY2ze0H6x+/HL2uVb+YAVju74HlPv+e/+ZHxFbgDcAVmXk6wI8BF83qtgF4ovfyJEm96OlSyIi4Engv8MbM/N6sRbuBLRFxdkRsBDYBX65fpiRpIc545B4RdwIt4MKIOAbcwszVMWcDeyMC4P7MfGdmPhwRdwOPMHO65l2Z+b/9Kl6S1NkZwz0z39yh+Y6f0P9W4NY6RUmS6vETqpJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFaiJG4dJRRsd0P10ju64aiDbVRk8cpekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAZwz3iPhYRJyMiK/ParsgIvZGxOHqcW3VHhHx4Yg4EhFfi4iX97N4SVJn3Ry5fxy4ck7bdmBfZm4C9lWvAV4HbKp+JoC/bqZMSdJCnDHcM/OLwFNzmq8GdlXPdwHXzGr/RM64H1gTEeuaKlaS1J3IzDN3ihgFPpuZl1Svn8nMNbOWP52ZayPis8COzPxS1b4PeG9m7u8w5gQzR/eMjIxcOjk52cB0fmxqaorVq1c3Ouaw6cc+OHj8VKPj9dPIKjjx3KCr6N3Y+vNrrb/c3wPLYf6bN28+kJnjnZY1/R2q0aGt478embkT2AkwPj6erVar0ULa7TZNjzls+rEPrh/Q94n2YtvYNLcfHN6vCT56XavW+sv9PbDc59/r1TInTp9uqR5PVu3HgItm9dsAPNF7eZKkXvQa7ruBrdXzrcC9s9rfWl01czlwKjOfrFmjJGmBzvg7a0TcCbSACyPiGHALsAO4OyJuAB4H3lR1/zvg9cAR4HvA2/pQsyTpDM4Y7pn55nkWXdGhbwLvqluUJKkeP6EqSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoFqhXtE/EFEPBwRX4+IOyPinIjYGBEPRMThiLgrIs5qqlhJUnd6DveIWA/8HjCemZcAK4AtwG3ABzJzE/A0cEMThUqSulf3tMxKYFVErATOBZ4EXgncUy3fBVxTcxuSpAWKzOx95YgbgVuB54DPAzcC92fmz1fLLwL+vjqyn7vuBDABMDIycunk5GTPdXQyNTXF6tWrGx1z2PRjHxw8fqrR8fppZBWceG7QVfRubP35tdZf7u+B5TD/zZs3H8jM8U7LVvY6aESsBa4GNgLPAJ8CXteha8d/PTJzJ7ATYHx8PFutVq+ldNRut2l6zGHTj31w/fY9jY7XT9vGprn9YM9/xQfu6HWtWusv9/fAcp9/ndMyrwK+nZn/kZn/A3wa+A1gTXWaBmAD8ETNGiVJC1Qn3B8HLo+IcyMigCuAR4D7gGurPluBe+uVKElaqJ5/Z83MByLiHuCrwDTwIDOnWfYAkxHxvqrtjiYK1Y+NdnlqZNvY9FCdRpHUnFonJDPzFuCWOc2PAZfVGVeSVI+fUJWkAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQLXCPSLWRMQ9EfGNiDgUEb8eERdExN6IOFw9rm2qWElSd+oeuX8I+IfM/AXgl4FDwHZgX2ZuAvZVryVJi6jncI+IFwC/BdwBkJk/yMxngKuBXVW3XcA1dYuUJC1MZGZvK0b8CrATeISZo/YDwI3A8cxcM6vf05n5vFMzETEBTACMjIxcOjk52VMd85mammL16tWNjrlUHDx+qqt+I6vgxHN9LmYJG/b5j60/v9b6Jb8HurEc5r958+YDmTneaVmdcB8H7gdekZkPRMSHgP8E3tNNuM82Pj6e+/fv76mO+bTbbVqtVqNjLhWj2/d01W/b2DS3H1zZ52qWrmGf/9EdV9Vav+T3QDeWw/wjYt5wr3PO/RhwLDMfqF7fA7wcOBER66oNrwNO1tiGJKkHPYd7Zv478J2IeGnVdAUzp2h2A1urtq3AvbUqlCQtWN3fWd8DfDIizgIeA97GzD8Yd0fEDcDjwJtqbkOStEC1wj0zHwI6ne+5os64kqR6/ISqJBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgo0vN9kIBWu2y9lmc+2sWmu72GMul8SoqXBI3dJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBaod7hGxIiIejIjPVq83RsQDEXE4Iu6KiLPqlylJWogmjtxvBA7Nen0b8IHM3AQ8DdzQwDYkSQtQK9wjYgNwFfDR6nUArwTuqbrsAq6psw1J0sLVPXL/IPBHwA+r1y8EnsnM6er1MWB9zW1Ikhao51v+RsQbgJOZeSAiWqebO3TNedafACYARkZGaLfbvZbS0dTUVONjLhXbxqbP3AkYWdV93xI5/97mX8r7puQM6Ead+7m/AnhjRLweOAd4ATNH8msiYmV19L4BeKLTypm5E9gJMD4+nq1Wq0Ypz9dut2l6zKWi23t0bxub5vaDy/eW/c6/t/kfva7VfDEDUHIGdKPn0zKZeVNmbsjMUWAL8IXMvA64D7i26rYVuLd2lZKkBenHde7vBf4wIo4wcw7+jj5sQ5L0EzTyO2tmtoF29fwx4LImxpUk9cZPqEpSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFauQ7VJer0e17Bl2CJHXkkbskFchwl6QCGe6SVCDDXZIK1HO4R8RFEXFfRByKiIcj4saq/YKI2BsRh6vHtc2VK0nqRp0j92lgW2b+InA58K6IuBjYDuzLzE3Avuq1JGkR9RzumflkZn61ev5fwCFgPXA1sKvqtgu4pm6RkqSFicysP0jEKPBF4BLg8cxcM2vZ05n5vFMzETEBTACMjIxcOjk5WbuO2aampli9enWjY8518Pipvo5f18gqOPHcoKsYHOff2/zH1p/ffDEDsBgZMGibN28+kJnjnZbVDveIWA38E3BrZn46Ip7pJtxnGx8fz/3799eqY652u02r1Wp0zLmW+oeYto1Nc/vB5fs5Neff2/yP7riqD9UsvsXIgEGLiHnDvdbVMhHx08DfAp/MzE9XzSciYl21fB1wss42JEkLV+dqmQDuAA5l5l/MWrQb2Fo93wrc23t5kqRe1Pmd9RXAW4CDEfFQ1fbHwA7g7oi4AXgceFO9EiVJC9VzuGfml4CYZ/EVvY4rSarPT6hKUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklSg5XvjDUkdDfKeSaXc12Yp8MhdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCDf117vNdk7ttbJrrl/h3nEpSv3jkLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgfp2nXtEXAl8CFgBfDQzd/RrW5LK0OS95BfyWZcS7yPfl3CPiBXAXwKvBo4BX4mI3Zn5SD+2J0l1lPgFJf06LXMZcCQzH8vMHwCTwNV92pYkaY7IzOYHjbgWuDIz31G9fgvwa5n57ll9JoCJ6uVLgUcbLuNC4LsNjzlslvs+cP7Ov/T5/1xmvqjTgn6dc48Obf/vX5HM3Ans7NP2iYj9mTner/GHwXLfB87f+S/n+ffrtMwx4KJZrzcAT/RpW5KkOfoV7l8BNkXExog4C9gC7O7TtiRJc/TltExmTkfEu4HPMXMp5Mcy8+F+bOsn6NspnyGy3PeB81/elvX8+/IfqpKkwfITqpJUIMNdkgo01OEeERdExN6IOFw9rp2n39aqz+GI2Fq1nRsReyLiGxHxcEQM3e0R6sy/ar81Ir4TEVOLV3V9EXFlRDwaEUciYnuH5WdHxF3V8gciYnTWspuq9kcj4rWLWXeTet0HEfHCiLgvIqYi4iOLXXdTasz/1RFxICIOVo+vXOzaF01mDu0P8H5ge/V8O3Bbhz4XAI9Vj2ur52uBc4HNVZ+zgH8GXjfoOS3W/KtllwPrgKlBz2UBc14BfAt4SfXn9q/AxXP6/C7wN9XzLcBd1fOLq/5nAxurcVYMek6LvA/OA34TeCfwkUHPZQDz/1XgZ6vnlwDHBz2ffv0M9ZE7M7c02FU93wVc06HPa4G9mflUZj4N7GXm07Pfy8z7AHLmFglfZeZ6/GHS8/wBMvP+zHxyUSptTje3tpi9X+4BroiIqNonM/P7mflt4Eg13rDpeR9k5rOZ+SXgvxev3MbVmf+DmXn6MzcPA+dExNmLUvUiG/ZwHzkdTtXjizv0WQ98Z9brY1Xbj0TEGuC3gX19qrNfGpn/kOlmPj/qk5nTwCnghV2uOwzq7IMSNDX/3wEezMzv96nOgerbLX+bEhH/CPxMh0U3dztEh7YfXf8ZESuBO4EPZ+ZjC6+wv/o9/yHUzXzm61PKvqizD0pQe/4R8TLgNuA1Dda1pCz5cM/MV823LCJORMS6zHwyItYBJzt0Owa0Zr3eALRnvd4JHM7MDzZQbuMWYf7DpptbW5zuc6z6x/t84Kku1x0GdfZBCWrNPyI2AJ8B3pqZ3+p/uYMx7KdldgOnr/7YCtzboc/ngNdExNrqapLXVG1ExPuY+UP//UWotR9qzX9IdXNri9n75VrgCznzP2i7gS3VlRQbgU3Alxep7ibV2Qcl6Hn+1SnYPcBNmfkvi1bxIAz6f3Tr/DBzDm0fcLh6vKBqH2fm259O93s7M/95dgR4W9W2gZlf0w4BD1U/7xj0nBZr/lX7+5k5wvlh9fing55Tl/N+PfBNZq6YuLlq+zPgjdXzc4BPVfP9MvCSWeveXK33KEN2dVSD++AoM0exU9Wf+8WLXf+g5g/8CfDsrPf8Q8CLBz2ffvx4+wFJKtCwn5aRJHVguEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QC/R+GYyIpZKBOugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = proj.total_points_with_noise(grades)\n",
    "total = proj.total_points(grades)\n",
    "diff = np.array(noise - total)\n",
    "(noise - total).hist()\n",
    "len(diff[(diff >= 0.01) | (diff <= -0.01)]) / len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap(total, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0691588785046729"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "noise = proj.total_points_with_noise(grades)\n",
    "letter_rand = noise.apply(score_to_grades)\n",
    "letter = total.apply(score_to_grades)\n",
    "np.count_nonzero(letter != letter_rand) / len(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4 # Ask!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations, you finished the project!\n",
    "\n",
    "### Before you submit:\n",
    "* Be sure you run the doctests on all your code in project01.py\n",
    "\n",
    "### To submit:\n",
    "* **Upload the .py file to gradescope**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
